# MUXI Framework - PostgreSQL & SQLite Guidelines

> These rules define best practices for working with PostgreSQL and SQLite databases within the MUXI Framework

## Database Selection

### When to Use PostgreSQL with pgvector
- For production deployments
- For multi-user applications
- When requiring horizontal scaling
- For high-throughput requirements
- When other PostgreSQL features are needed

### When to Use SQLite with sqlite-vec
- For local development
- For single-user applications
- For edge deployments
- For serverless functions
- When resource constraints apply
- When simplicity is preferred over scalability

## PostgreSQL Schema Design

### Table Design
- Use snake_case for table and column names
- Use singular names for tables (e.g., `user` not `users`)
- Include created_at and updated_at timestamps on all tables
- Be explicit about column nullability
- Use appropriate data types:
  - TEXT for variable length strings
  - CHAR(21) for nanoid primary keys
  - TIMESTAMP WITH TIME ZONE for timestamps
  - UUID for internal identifiers when appropriate
  - INTEGER for small numbers
  - BIGINT for counts that may exceed 2^31
  - BOOLEAN for true/false values
  - JSONB for schemaless data and metadata
  - BYTEA for binary data and vectors
- Use foreign keys to maintain referential integrity
- Include sensible default values where appropriate
- Use constraints to enforce business rules
- Avoid unnecessary columns
- Consider future schema evolution

### Indexing
- Create indexes for all columns used in WHERE, JOIN, and ORDER BY clauses
- Use appropriate index types:
  - B-tree for equality and range queries
  - GIN for full-text search and JSONB
  - GiST for geometric data and full-text search
  - SP-GiST for clustered data
  - BRIN for large tables with ordered data
  - IVFFlat for pgvector columns
- Create composite indexes for common query patterns
- Don't over-index small tables
- Monitor and maintain indexes regularly
- Consider partial indexes for filtered queries
- Consider index-only scans for performance

### Vector Storage with pgvector
- Use the pgvector extension for vector similarity search
- Create vector columns with appropriate dimensions:
  - 1536 for OpenAI embeddings
  - 768 for BERT embeddings
  - 1024 for Sentence Transformers
- Use appropriate indexes for vector columns:
  - HNSW for high recall and performance (pgvector 0.5.0+)
  - IVFFlat for balanced performance and memory usage
  - IVFFlat with lists=100 for tables < 1M rows
  - IVFFlat with lists=1000 for tables > 1M rows
- Use appropriate distance metrics:
  - L2 distance (squared_l2_distance) for Euclidean distance
  - Inner product (inner_product) for normalized vectors
  - Cosine distance (cosine_distance) for text embeddings
- Properly normalize vectors when using cosine similarity
- Use appropriate index parameters for your workload
- Benchmark different index configurations
- Monitor query performance with EXPLAIN ANALYZE

## SQLite Configuration

### Database Setup
- Use the sqlite-vec Python package for vector operations
- Ensure proper error handling with fallback to binary extensions
- Use appropriate version (3.38+ recommended)
- Set appropriate pragmas:
  - PRAGMA journal_mode = WAL;
  - PRAGMA synchronous = NORMAL;
  - PRAGMA cache_size = -64000;
  - PRAGMA foreign_keys = ON;
- Be aware of concurrency limitations
- Use appropriate file system for the database
- Implement backup strategies

### Vector Storage with sqlite-vec
- Use compatible schema between PostgreSQL and SQLite
- Use BLOB type for vector storage
- Test with the target SQLite version
- Ensure proper serialization of vectors (float32)
- Use the sqlite-vec Python functions:
  - sqlite_vec.load(conn)
  - sqlite_vec.serialize_float32() for lists
- Avoid complex indices for small datasets

## Query Design

### General Query Best Practices
- Use parameterized queries to prevent SQL injection
- Keep queries simple and readable
- Avoid SELECT * unless necessary
- Use appropriate joins for related data
- Use EXISTS instead of IN for subqueries
- Use window functions for analytical queries
- Use CTEs for complex queries
- Use LIMIT and OFFSET for pagination
- Use EXPLAIN and EXPLAIN ANALYZE for query tuning
- Use appropriate transaction isolation levels
- Handle NULL values explicitly
- Use server-side cursors for large result sets (PostgreSQL only)
- Implement query timeouts for long-running queries

### Vector Queries
- Use appropriate vector similarity functions:
  - vec_cosine_similarity for cosine distance
  - vec_l2_distance for Euclidean distance
  - vec_inner_product for inner product
- Use vector operators (PostgreSQL):
  - <-> for L2 distance
  - <=> for cosine distance
  - <#> for inner product
- Filter candidates before vector operations when possible
- Use k-nearest neighbors with appropriate k values
- Implement post-processing of vector search results
- Benchmark different similarity metrics
- Use proper vector normalization for cosine similarity

## Connection Management

### PostgreSQL Connection Management
- Use connection pooling (pgbouncer or application-level)
- Set appropriate pool sizes based on workload
- Set appropriate connection timeouts
- Handle connection errors gracefully
- Use prepared statements for repeated queries
- Implement retry logic for transient errors
- Monitor connection usage
- Close connections explicitly when done
- Use transactions properly
- Set appropriate client_encoding and search_path
- Use appropriate isolation levels for transactions

### SQLite Connection Management
- Be aware of connection locking behavior
- Use WAL mode for concurrent read/write
- Handle "database is locked" errors
- Keep transactions short
- Minimize connection creation
- Close connections explicitly
- Implement timeout and retry logic

## Performance Tuning

### PostgreSQL Performance
- Use appropriate PostgreSQL configuration for your workload
- Monitor and tune shared_buffers, work_mem, and maintenance_work_mem
- Use VACUUM and ANALYZE regularly
- Use partitioning for very large tables
- Use parallel queries for large analytical workloads
- Implement appropriate indexing strategy
- Monitor slow queries
- Use connection pooling
- Use appropriate hardware for database servers
- Implement query cancellation for long-running queries
- Consider read replicas for read-heavy workloads
- Benchmark different index types for vector columns

### SQLite Performance
- Use WAL journal mode
- Set appropriate PRAGMA settings
- Keep transactions short
- Minimize disk I/O
- Use appropriate indexing
- Run regular ANALYZE
- Minimize file system overhead
- Consider memory-mapped access for read-heavy workloads
- Test with realistic data volumes

## Error Handling
- Implement proper error handling for database operations
- Handle connection errors with exponential backoff
- Handle constraint violations appropriately
- Log database errors with context information
- Implement circuit breaker patterns for database access
- Handle deadlocks with retries
- Monitor database error rates
- Implement proper transaction management
- Validate inputs before database operations
- Handle database maintenance scenarios
- Implement proper connection cleanup

## Security
- Use parameterized queries to prevent SQL injection
- Implement proper authentication and authorization
- Use least privilege principles for database access
- Encrypt sensitive data
- Audit database access
- Implement row-level security for multi-tenant data
- Use secure connection settings
- Implement proper credential management
- Regularly review database security
- Monitor for unusual access patterns
- Implement proper backup and recovery procedures
- Use separate schemas or databases for better isolation
