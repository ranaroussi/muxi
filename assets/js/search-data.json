{"0": {
    "doc": "API Documentation",
    "title": "API Documentation",
    "content": "This page provides preliminary documentation for the MUXI Framework’s REST API endpoints. ",
    "url": "/muxi/reference/api",
    
    "relUrl": "/reference/api"
  },"1": {
    "doc": "API Documentation",
    "title": "Authentication",
    "content": "API endpoints require authentication. MUXI uses API key authentication. To authenticate requests, include an Authorization header with a Bearer token: . Authorization: Bearer &lt;token&gt; . You can set the token when starting a muxi server with the --api-key flag. ",
    "url": "/muxi/reference/api#authentication",
    
    "relUrl": "/reference/api#authentication"
  },"2": {
    "doc": "API Documentation",
    "title": "API Endpoints",
    "content": "Agent Endpoints . GET /agents . List all available agents. Response: . { \"agents\": [ { \"id\": \"assistant-1\", \"name\": \"General Assistant\", \"description\": \"A general-purpose AI assistant\" }, { \"id\": \"coder-1\", \"name\": \"Code Assistant\", \"description\": \"An AI assistant specialized in coding\" } ] } . POST /agents . Create a new agent. Request Body: . { \"id\": \"custom-agent-1\", \"name\": \"Custom Agent\", \"description\": \"A custom-tailored agent\", \"model\": { \"provider\": \"openai\", \"name\": \"gpt-4\", \"parameters\": { \"temperature\": 0.7, \"max_tokens\": 1024 } } } . Response: . { \"id\": \"custom-agent-1\", \"name\": \"Custom Agent\", \"description\": \"A custom-tailored agent\", \"status\": \"created\" } . GET /agents/{agent_id} . Get details about a specific agent. Response: . { \"id\": \"assistant-1\", \"name\": \"General Assistant\", \"description\": \"A general-purpose AI assistant\", \"model\": { \"provider\": \"openai\", \"name\": \"gpt-4\", \"parameters\": { \"temperature\": 0.7, \"max_tokens\": 1024 } } } . DELETE /agents/{agent_id} . Delete a specific agent. Response: . { \"status\": \"deleted\", \"id\": \"assistant-1\" } . Chat Endpoints . POST /chat/{agent_id} . Send a message to an agent. Request Body: . { \"message\": \"What's the weather like today?\", \"user_id\": \"user123\", \"session_id\": \"session456\", \"context\": { \"location\": \"New York\" } } . Response: . { \"id\": \"msg_123456\", \"content\": \"I don't have real-time weather data, but I can help you find weather information for New York.\", \"timestamp\": \"2023-09-21T14:32:01Z\", \"agent_id\": \"assistant-1\", \"session_id\": \"session456\" } . GET /chat/{agent_id}/history . Get chat history for a specific agent and user session. Parameters: . | user_id (required): The user’s ID | session_id (required): The session ID | limit (optional): Maximum number of messages to return (default: 50) | before (optional): Return messages before this timestamp | . Response: . { \"messages\": [ { \"id\": \"msg_123455\", \"role\": \"user\", \"content\": \"What's the weather like today?\", \"timestamp\": \"2023-09-21T14:31:45Z\" }, { \"id\": \"msg_123456\", \"role\": \"assistant\", \"content\": \"I don't have real-time weather data, but I can help you find weather information for New York.\", \"timestamp\": \"2023-09-21T14:32:01Z\" } ], \"has_more\": false } . Memory Endpoints . GET /memory/{agent_id} . Query an agent’s memory. Parameters: . | user_id (required): The user’s ID | query (required): The search query | limit (optional): Maximum number of memories to return (default: 10) | . Response: . { \"memories\": [ { \"id\": \"mem_123456\", \"content\": \"User lives in New York\", \"created_at\": \"2023-09-20T10:15:30Z\", \"relevance_score\": 0.95 }, { \"id\": \"mem_123457\", \"content\": \"User mentioned they like sunny weather\", \"created_at\": \"2023-09-19T11:20:15Z\", \"relevance_score\": 0.82 } ] } . POST /memory/{agent_id} . Add a memory for an agent. Request Body: . { \"user_id\": \"user123\", \"content\": \"User prefers vegetarian food\", \"metadata\": { \"source\": \"conversation\", \"importance\": \"high\" } } . Response: . { \"id\": \"mem_123458\", \"status\": \"created\", \"created_at\": \"2023-09-21T14:40:22Z\" } . ",
    "url": "/muxi/reference/api#api-endpoints",
    
    "relUrl": "/reference/api#api-endpoints"
  },"3": {
    "doc": "API Documentation",
    "title": "Error Responses",
    "content": "All API endpoints return standard HTTP status codes. In case of an error, the response body will contain additional information: . { \"error\": { \"code\": \"invalid_request\", \"message\": \"Missing required parameter: user_id\", \"details\": { \"param\": \"user_id\" } } } . Common error codes: . | invalid_request: The request is malformed or missing required parameters | authentication_error: Authentication failed | permission_denied: The authenticated user doesn’t have permission for this action | not_found: The requested resource doesn’t exist | rate_limit_exceeded: The rate limit for the API has been exceeded | internal_error: An internal server error occurred | . ",
    "url": "/muxi/reference/api#error-responses",
    
    "relUrl": "/reference/api#error-responses"
  },"4": {
    "doc": "API Documentation",
    "title": "Rate Limiting",
    "content": "API requests are subject to rate limiting. The current limits are: . | 60 requests per minute per user for most endpoints | 10 requests per minute per user for resource-intensive endpoints | . Rate limit information is included in the response headers: . | X-RateLimit-Limit: The rate limit ceiling | X-RateLimit-Remaining: The number of requests left for the time window | X-RateLimit-Reset: The remaining window before the rate limit resets in UTC epoch seconds | . ",
    "url": "/muxi/reference/api#rate-limiting",
    
    "relUrl": "/reference/api#rate-limiting"
  },"5": {
    "doc": "API Documentation",
    "title": "Pagination",
    "content": "Endpoints that return lists of resources support pagination using the following parameters: . | limit: Number of items to return per page (default: 50, max: 100) | offset: Number of items to skip (default: 0) | . Paginated responses include metadata: . { \"items\": [...], \"pagination\": { \"total\": 120, \"limit\": 50, \"offset\": 0, \"next_offset\": 50 } } . ",
    "url": "/muxi/reference/api#pagination",
    
    "relUrl": "/reference/api#pagination"
  },"6": {
    "doc": "API Documentation",
    "title": "Versioning",
    "content": "The API version is specified in the URL path: /api/v1/... When breaking changes are introduced, a new API version will be released. Previous versions will be maintained for a reasonable deprecation period. Note: This is preliminary API documentation. The complete API design will be finalized at a later stage of development. ",
    "url": "/muxi/reference/api#versioning",
    
    "relUrl": "/reference/api#versioning"
  },"7": {
    "doc": "Architecture",
    "title": "Architecture",
    "content": " ",
    "url": "/muxi/intro/architecture",
    
    "relUrl": "/intro/architecture"
  },"8": {
    "doc": "Architecture",
    "title": "What You’ll Learn",
    "content": ". | The architectural principles of the MUXI Framework | The modular package structure | The service-oriented approach | How the different components interact | . ",
    "url": "/muxi/intro/architecture#what-youll-learn",
    
    "relUrl": "/intro/architecture#what-youll-learn"
  },"9": {
    "doc": "Architecture",
    "title": "Prerequisites",
    "content": ". | Basic understanding of software architecture concepts | Familiarity with the Overview (recommended) | . ",
    "url": "/muxi/intro/architecture#prerequisites",
    
    "relUrl": "/intro/architecture#prerequisites"
  },"10": {
    "doc": "Architecture",
    "title": "Architecture Overview",
    "content": "MUXI is designed with a modular, extensible architecture that allows for flexibility in deployment and usage. The framework follows a service-oriented approach, allowing components to be deployed together or separately. ┌───────────────────┐ │ Clients │ │ (CLI/MCP/Web/SDK) │ └─────────┬─────────┘ │ │ (API/SSE/WS) │ ┌─────────│───────────────────────────────────────────┐ │ │ MUXI Server (Local/Remote) │ │ │ │ │ │ ┌───────────────┐ │ ┌──────────────────┐ │ └───────&gt;│ Orchestrator │----------------------│ Buffer/LT Memory │ │ └───────┬───────┘ │ └──────────────────┘ │ ┌────────────────┼────────────────┐ │ │ │ │ │ │ │ ┌──────▼──────┐ ┌──────▼──────┐ ┌──────▼──────┐ │ ┌──────────────────┐ │ │ Agent 1 │ │ Agent 2 │ │ Agent N │------│ Domain Knowledge │ │ └───┬─────↑───┘ └──────↑──────┘ └───↑─────┬───┘ │ └──────────────────┘ │ │ │ │ │ │ │ │ │ │ ↓ │ │ │ │ │ └─────────&gt; (A2A) &lt;─────────┘ │ │ │ │ │ │ │ │ ┌─────────────┐ │ │ │ └───────────&gt;│ MCP Handler │&lt;───────────┘ │ │ └──────┬──────┘ │ └──────────────────────────│──────────────────────────┘ │ │ (gRPC/HTTP/Command) │ ┌──────────────────────────▼──────────────────────────┐ │ MCP Servers │ │ ┌─────────────┐ ┌─────────────┐ ┌─────────────┐ │ │ │ Weather │ │ Web Search │ │ .... │ │ │ └─────────────┘ └─────────────┘ └─────────────┘ │ └─────────────────────────────────────────────────────┘ . ",
    "url": "/muxi/intro/architecture#architecture-overview",
    
    "relUrl": "/intro/architecture#architecture-overview"
  },"11": {
    "doc": "Architecture",
    "title": "Core Components",
    "content": "1. Server Layer . The Server layer is the entry point for all external communication with the framework: . | REST API: Endpoints for agent management, chat operations, and memory interactions | WebSocket Server: Real-time, bidirectional communication for streaming responses | Web App: Frontend interface for visual interaction | CLI: Command-line interface for text-based interaction | . 2. Orchestrator . The Orchestrator is the central coordinator that: . | Manages the lifecycle of all agents in the system | Routes messages to the appropriate agent | Handles agent creation, configuration, and removal | Provides a unified interface for all client applications | . 3. Agents . Agents are the intelligent entities that process information and produce responses: . | Integrate with a specific LLM provider | Maintain their own memory systems | Access MCP servers for extended capabilities | Process messages according to their system instructions | . 4. Model Context Protocol (MCP) . The MCP is a standardized communication layer between agents and external services: . | Provides a consistent interface for integrating external functionality | Handles specialized message formatting | Manages request/response parsing and serialization | Supports function execution and result handling | . 5. Memory Systems . MUXI includes a sophisticated memory architecture: . | Buffer Memory: Short-term contextual memory for conversation flow | Long-Term Memory: Persistent storage of important information . | PostgreSQL with pgvector: For production and multi-user applications | SQLite with sqlite-vec: For local development and single-user applications | . | Memobase: Multi-user aware memory system that partitions by user ID | . 6. MCP Servers . MCP Servers provide extended functionality to agents: . | Implement standardized MCP protocol | Can be deployed separately from the main application | Provide specialized services like weather data, web search, etc. | Can be implemented in any language that supports HTTP | . ",
    "url": "/muxi/intro/architecture#core-components",
    
    "relUrl": "/intro/architecture#core-components"
  },"12": {
    "doc": "Architecture",
    "title": "Modular Package Structure",
    "content": "The MUXI framework is organized into a modular monorepo structure with multiple packages: . muxi-framework/ ├── packages/ │ ├── core/ # Core components: agents, memory, MCP interface │ ├── server/ # REST API and WebSocket server │ ├── cli/ # Command-line interface │ ├── web/ # Web user interface │ └── muxi/ # Meta-package that integrates all components └── tests/ # Test suite for all components . Package Descriptions . Core Package (muxi-core) . The foundation of the framework: . | Contains Agent, Memory, and MCP implementations | Has minimal dependencies for lightweight usage | Provides MCP handler implementation for connecting to MCP servers | . Server Package (muxi-server) . Handles all communication with clients: . | Implements the REST API server for agent interaction | Includes WebSocket server for real-time communication | Handles request routing and middleware | Manages API authentication | . CLI Package (muxi-cli) . Command-line interface for the framework: . | Provides interactive terminal-based chat interface | Implements agent management and server commands | Includes utilities for generating MCP server templates | . Web Package (muxi-web) . The web interface for the framework: . | Contains the frontend user interface built with React | Implements WebSocket client for real-time communication | Provides agent configuration UI | . Meta Package (muxi) . Ties everything together: . | Integrates core, server, and CLI packages | Provides a unified API for the whole framework | Simplifies installation and usage | . ",
    "url": "/muxi/intro/architecture#modular-package-structure",
    
    "relUrl": "/intro/architecture#modular-package-structure"
  },"13": {
    "doc": "Architecture",
    "title": "Service-Oriented Approach",
    "content": "MUXI follows a service-oriented architecture that enables: . 1. Client-Server Model . | Separate client and server components | Local and remote operation with the same API | Flexible authentication mechanisms | Connection management utilities | . 2. Hybrid Communication Protocol . | HTTP for standard API requests | SSE (Server-Sent Events) for streaming responses . | Real-time token-by-token streaming | Automatic connection closure after response completion | . | WebSockets for advanced bi-directional capabilities . | Bi-directional communication for complex interactions | Available through app.open_socket() API | . | . 3. Authentication . | API key authentication | Auto-generated keys with one-time display | Environment variable configuration | . 4. Database Options . | PostgreSQL with pgvector for production and multi-user environments . | Scalable vector storage and retrieval | Advanced indexing for large datasets | Concurrent access handling | . | SQLite with sqlite-vec for development and single-user applications . | Simplified deployment with file-based storage | Cross-platform compatibility | Uses the sqlite-vec Python package for vector operations | . | . 5. MCP Server Integration . | All external functionality provided through standardized MCP servers | Consistent interface for interacting with external services | Service discovery mechanisms | Deployment utilities | . ",
    "url": "/muxi/intro/architecture#service-oriented-approach",
    
    "relUrl": "/intro/architecture#service-oriented-approach"
  },"14": {
    "doc": "Architecture",
    "title": "Usage Examples",
    "content": "Local Mode . # Local usage with unified API from muxi import muxi app = muxi() # Add an agent from a configuration file app.add_agent(\"weather\", \"agents/weather_agent.yaml\") # Chat with the agent response = app.chat(\"What's the weather in New York?\") print(response) . Server Mode . # Start in server mode from muxi import muxi app = muxi() app.add_agent(\"assistant\", \"agents/assistant.yaml\") app.run(host=\"0.0.0.0\", port=5050) . Client Mode . # Connect to a remote server from muxi.client import MuxiClient client = MuxiClient(url=\"http://my-server.com:5050\", api_key=\"your-api-key\") response = client.chat(\"What's the weather in New York?\") print(response) . ",
    "url": "/muxi/intro/architecture#usage-examples",
    
    "relUrl": "/intro/architecture#usage-examples"
  },"15": {
    "doc": "Architecture",
    "title": "Advanced Topics",
    "content": "For deeper exploration of the architecture: . | Orchestrator - Learn about the orchestration system | MCP Fundamentals - Understand the Model Context Protocol | Package Structure - Detailed package organization | . ",
    "url": "/muxi/intro/architecture#advanced-topics",
    
    "relUrl": "/intro/architecture#advanced-topics"
  },"16": {
    "doc": "Architecture",
    "title": "What’s Next",
    "content": ". | Installation - Install MUXI and set up your environment | Simple Agents - Create your first agent | Server Deployment - Deploy MUXI as a server | . ",
    "url": "/muxi/intro/architecture#whats-next",
    
    "relUrl": "/intro/architecture#whats-next"
  },"17": {
    "doc": "Buffer Memory",
    "title": "Buffer Memory",
    "content": "This page provides a technical deep dive into the Buffer Memory system in the MUXI Framework. ",
    "url": "/muxi/technical/memory/buffer",
    
    "relUrl": "/technical/memory/buffer"
  },"18": {
    "doc": "Buffer Memory",
    "title": "Overview",
    "content": "Buffer Memory is the short-term conversational memory system that maintains conversation context for agents. It stores a fixed window of recent messages and automatically processes them to provide relevant context for subsequent interactions. ",
    "url": "/muxi/technical/memory/buffer#overview",
    
    "relUrl": "/technical/memory/buffer#overview"
  },"19": {
    "doc": "Buffer Memory",
    "title": "Architecture",
    "content": "Buffer Memory is designed with the following components: . ┌──────────────────────┐ │ BufferMemory │ ├──────────────────────┤ │ - messages: List │ ┌──────────────────┐ │ - buffer_size: int │◄────►│ Message │ │ - summarizer: Opt │ ├──────────────────┤ └──────────┬───────────┘ │ - role: str │ │ │ - content: str │ ▼ │ - timestamp: dt │ ┌──────────────────────┐ │ - metadata: Dict │ │ MemorySummarizer │ └──────────────────┘ └──────────────────────┘ . The core components include: . | Message Store: An ordered list of messages with role (user/assistant), content, timestamp, and optional metadata | Size Management: Fixed-size buffer window with automatic truncation | Summarization: Optional component that creates memory summaries when the buffer overflows | Serialization: Methods for converting to/from JSON for persistence | . ",
    "url": "/muxi/technical/memory/buffer#architecture",
    
    "relUrl": "/technical/memory/buffer#architecture"
  },"20": {
    "doc": "Buffer Memory",
    "title": "Implementation Details",
    "content": "Buffer Management . Buffer Memory manages a fixed window of messages using a queue-like structure: . from muxi.core.memory.buffer import BufferMemory # Create a buffer with size 5 buffer = BufferMemory(buffer_size=5) # Add messages buffer.add_message(\"user\", \"Hello, my name is Alice.\") buffer.add_message(\"assistant\", \"Hello Alice! How can I help you today?\") # When buffer exceeds capacity, oldest messages are removed for i in range(10): buffer.add_message(\"user\", f\"Message {i}\") # Buffer now contains only the 5 most recent messages . The implementation uses a list with maintenance operations when new messages are added: . def add_message(self, role: str, content: str, metadata: Optional[Dict] = None) -&gt; None: \"\"\"Add a message to the buffer.\"\"\" message = { \"role\": role, \"content\": content, \"timestamp\": datetime.datetime.now().isoformat(), } if metadata: message[\"metadata\"] = metadata self.messages.append(message) # Maintain buffer size if len(self.messages) &gt; self.buffer_size: if self.summarizer: # Create summary of oldest messages to_summarize = self.messages[:(len(self.messages) - self.buffer_size)] summary = self.summarizer.summarize(to_summarize) self.summary = summary # Remove oldest messages self.messages = self.messages[-(self.buffer_size):] . Automatic Summarization . When messages exceed the buffer size, the oldest messages can be automatically summarized (if a summarizer is configured): . from muxi.core.memory.buffer import BufferMemory, MemorySummarizer from muxi.core.models.openai import OpenAIModel # Create summarizer with a model summarizer = MemorySummarizer( model=OpenAIModel(\"gpt-3.5-turbo\") ) # Create buffer with summarizer buffer = BufferMemory( buffer_size=5, summarizer=summarizer ) # When buffer overflows, oldest messages are summarized for i in range(10): buffer.add_message(\"user\", f\"Message {i}\") print(buffer.summary) # Contains summary of oldest messages . The summarizer uses an LLM to create concise summaries: . def summarize(self, messages: List[Dict]) -&gt; str: \"\"\"Summarize a list of messages.\"\"\" prompt = \"Summarize the following conversation concisely, focusing on key facts and important information:\\n\\n\" for msg in messages: prompt += f\"{msg['role'].title()}: {msg['content']}\\n\" response = self.model.generate(prompt) return response . Accessing Messages . The buffer provides methods to access and format messages: . # Get all messages all_messages = buffer.get_messages() # Get messages formatted for LLM consumption formatted_messages = buffer.get_formatted_messages() # Get messages with summary (if available) context_messages = buffer.get_context() . The formatting logic ensures messages are in the expected format for LLM APIs: . def get_formatted_messages(self) -&gt; List[Dict[str, str]]: \"\"\"Get messages formatted for LLM consumption.\"\"\" formatted = [] # Add summary if available if self.summary: formatted.append({ \"role\": \"system\", \"content\": f\"Previous conversation summary: {self.summary}\" }) # Add current messages for msg in self.messages: formatted.append({ \"role\": msg[\"role\"], \"content\": msg[\"content\"] }) return formatted . User-Specific Partitioning . Buffer Memory supports user-specific partitioning: . # Create buffer buffer = BufferMemory(buffer_size=5) # Add messages for different users buffer.add_message(\"user\", \"I'm Alice\", metadata={\"user_id\": \"user1\"}) buffer.add_message(\"assistant\", \"Hello Alice!\", metadata={\"user_id\": \"user1\"}) buffer.add_message(\"user\", \"I'm Bob\", metadata={\"user_id\": \"user2\"}) buffer.add_message(\"assistant\", \"Hello Bob!\", metadata={\"user_id\": \"user2\"}) # Get messages for a specific user alice_messages = buffer.get_messages(filter_metadata={\"user_id\": \"user1\"}) bob_messages = buffer.get_messages(filter_metadata={\"user_id\": \"user2\"}) . The filtering mechanism checks message metadata: . def get_messages(self, filter_metadata: Optional[Dict] = None) -&gt; List[Dict]: \"\"\"Get messages, optionally filtering by metadata.\"\"\" if not filter_metadata: return self.messages return [ msg for msg in self.messages if \"metadata\" in msg and all( msg[\"metadata\"].get(k) == v for k, v in filter_metadata.items() ) ] . Serialization and Persistence . Buffer Memory can be serialized to JSON for persistence: . # Serialize to JSON json_data = buffer.to_json() # Load from JSON new_buffer = BufferMemory.from_json(json_data) . The implementation handles conversion to and from JSON: . def to_json(self) -&gt; str: \"\"\"Serialize the buffer to JSON.\"\"\" data = { \"messages\": self.messages, \"buffer_size\": self.buffer_size, \"summary\": self.summary } return json.dumps(data) @classmethod def from_json(cls, json_data: str) -&gt; \"BufferMemory\": \"\"\"Create a buffer from JSON.\"\"\" data = json.loads(json_data) buffer = cls(buffer_size=data[\"buffer_size\"]) buffer.messages = data[\"messages\"] buffer.summary = data.get(\"summary\") return buffer . ",
    "url": "/muxi/technical/memory/buffer#implementation-details",
    
    "relUrl": "/technical/memory/buffer#implementation-details"
  },"21": {
    "doc": "Buffer Memory",
    "title": "Performance Considerations",
    "content": "The Buffer Memory system is designed for efficiency: . | Time Complexity: O(1) for common operations like adding messages and retrieving context | Space Complexity: O(n) where n is the buffer size | Memory Usage: Configurable through buffer_size parameter | . For larger buffer sizes, consider these factors: . | Context Window Limits: LLMs have context window limits, so very large buffers may not be fully usable | Summarization Cost: Frequent summarization increases API costs | Retrieval Efficiency: Smaller buffers with good summarization often outperform larger raw buffers | . ",
    "url": "/muxi/technical/memory/buffer#performance-considerations",
    
    "relUrl": "/technical/memory/buffer#performance-considerations"
  },"22": {
    "doc": "Buffer Memory",
    "title": "Integration with Agents",
    "content": "Agents automatically integrate with Buffer Memory: . from muxi.core.agent import Agent from muxi.core.models.openai import OpenAIModel from muxi.core.memory.buffer import BufferMemory # Create buffer buffer = BufferMemory(buffer_size=10) # Create agent with buffer agent = Agent( name=\"assistant\", model=OpenAIModel(\"gpt-4\"), system_message=\"You are a helpful assistant.\", buffer_memory=buffer ) # Each chat interaction automatically uses and updates the buffer agent.chat(\"Hello, my name is Charlie.\") agent.chat(\"What's my name?\") # Will include \"Charlie\" in response . ",
    "url": "/muxi/technical/memory/buffer#integration-with-agents",
    
    "relUrl": "/technical/memory/buffer#integration-with-agents"
  },"23": {
    "doc": "Buffer Memory",
    "title": "Best Practices",
    "content": ". | Size Configuration: Set buffer_size based on your application’s needs: . | Short, factual exchanges: 3-5 messages | Complex conversations: 8-12 messages | Technical discussions: 10-15 messages | . | Summarization: Enable summarization for longer conversations to maintain context while controlling token usage . | Metadata Usage: Use metadata to track important message attributes (user_id, session_id, etc.) . | User Partitioning: For multi-user scenarios, filter messages by user_id metadata | . ",
    "url": "/muxi/technical/memory/buffer#best-practices",
    
    "relUrl": "/technical/memory/buffer#best-practices"
  },"24": {
    "doc": "Buffer Memory",
    "title": "Related Topics",
    "content": ". | Long-Term Memory - Persistent memory storage | Multi-User Memory (Memobase) - User-specific memory partitioning | Domain Knowledge - Structured knowledge integration | . ",
    "url": "/muxi/technical/memory/buffer#related-topics",
    
    "relUrl": "/technical/memory/buffer#related-topics"
  },"25": {
    "doc": "Framework Comparisons",
    "title": "Framework Comparisons",
    "content": "This page provides a helpful overview of the MUXI Framework’s key features and how they address common challenges in AI agent development. ",
    "url": "/muxi/reference/comparisons",
    
    "relUrl": "/reference/comparisons"
  },"26": {
    "doc": "Framework Comparisons",
    "title": "Introduction to AI Agent Frameworks",
    "content": "The AI agent framework landscape offers many options for developers, each with different design philosophies and approaches: . | MUXI: Focuses on multi-agent orchestration, memory persistence, and standardized service integration | Other frameworks: May focus on different aspects like document processing, autonomous planning, or specific ecosystem integration | . ",
    "url": "/muxi/reference/comparisons#introduction-to-ai-agent-frameworks",
    
    "relUrl": "/reference/comparisons#introduction-to-ai-agent-frameworks"
  },"27": {
    "doc": "Framework Comparisons",
    "title": "MUXI’s Core Strengths",
    "content": "MUXI was designed with several core principles that address common challenges in AI agent development: . Multi-Agent Orchestration . | Built-in support for creating and managing multiple specialized agents | Intelligent message routing based on agent specializations | Collaborative problem-solving across agent boundaries | Shared memory and context between agents | . Comprehensive Memory Systems . | Automatic buffer memory for conversation context | Persistent long-term memory with vector search capabilities | Multi-user memory partitioning for personalized experiences | Automatic memory summarization for context window optimization | . Standardized External Service Integration . | Model Context Protocol (MCP) for consistent service access | Easy extension with custom capabilities via MCP servers | Built-in authentication and security features | Streaming support for real-time service integration | . Real-Time Communication . | WebSocket support for bi-directional communication | Server-Sent Events (SSE) for efficient one-way streaming | Real-time token streaming from language models | Support for multi-step interactions | . Multi-User Architecture . | Built-in user identification and authentication | User-specific memory partitioning | Personalized agent experiences | Efficient resource sharing between users | . Multi-Modal Support . | Process and generate text, images, and audio | Vision models for image understanding and analysis | Audio processing for speech-to-text and text-to-speech | Mixed-mode conversations with seamless transitions between modalities | . Declarative Configuration . | YAML and JSON configuration support | Environment variable substitution | Configuration validation and error reporting | Hot-reloading of configuration changes | . ",
    "url": "/muxi/reference/comparisons#muxis-core-strengths",
    
    "relUrl": "/reference/comparisons#muxis-core-strengths"
  },"28": {
    "doc": "Framework Comparisons",
    "title": "Architectural Design Philosophy",
    "content": "MUXI’s architecture reflects specific design choices that shape how applications are built: . Agent-Centric Design . | Agents are first-class citizens in the MUXI Framework | All functionality revolves around agent behavior and capabilities | Memory, tools, and services enhance agent abilities | Clear separation between agents and their environment | . Balancing Structure and Flexibility . | Provides structure for common patterns | Allows flexibility for custom implementations | Prefers convention over configuration | Embraces modern Python practices | . Standardized Interfaces . | Consistent API design across components | Clear separation of concerns | Well-defined integration points | Stable public interfaces with semantic versioning | . Modular Architecture . | Independent packages with specific responsibilities | Dependency minimization | Selective feature inclusion | Extensible plugin system | . ",
    "url": "/muxi/reference/comparisons#architectural-design-philosophy",
    
    "relUrl": "/reference/comparisons#architectural-design-philosophy"
  },"29": {
    "doc": "Framework Comparisons",
    "title": "Code Approaches",
    "content": "Different frameworks use different coding patterns. Here’s how MUXI approaches common tasks: . Agent Creation . MUXI emphasizes simplicity and declarative configuration: . from muxi import muxi app = muxi() app.add_agent_from_config(\"configs/assistant.yaml\") response = app.chat(\"What is the capital of France?\") print(response) . Memory Management . MUXI provides built-in memory systems: . from muxi.core.agent import Agent from muxi.core.models.openai import OpenAIModel from muxi.core.memory.long_term import LongTermMemory memory = LongTermMemory(connection_string=\"postgresql://user:pass@localhost/db\") agent = Agent( model=OpenAIModel(\"gpt-4o\"), system_message=\"You are a helpful assistant.\", long_term_memory=memory ) agent.chat(\"My favorite color is blue.\") response = agent.chat(\"What's my favorite color?\") print(response) # Will include \"blue\" . ",
    "url": "/muxi/reference/comparisons#code-approaches",
    
    "relUrl": "/reference/comparisons#code-approaches"
  },"30": {
    "doc": "Framework Comparisons",
    "title": "Use Case Recommendations",
    "content": "MUXI is particularly well-suited for: . Multi-Agent Systems . | Customer service platforms with specialized agents | Research assistants with domain-specific knowledge | Virtual team members with different roles | Complex problem-solving requiring multiple perspectives | . Interactive Applications . | Real-time chat interfaces | Voice assistants | Collaborative writing tools | Interactive educational applications | . Multi-User Platforms . | SaaS applications with user-specific experiences | Team collaboration tools | Customer support platforms | Personalized assistant applications | . Enterprise Integration . | Integration with existing business systems | Custom workflow automation | Knowledge management applications | Internal tool enhancement | . ",
    "url": "/muxi/reference/comparisons#use-case-recommendations",
    
    "relUrl": "/reference/comparisons#use-case-recommendations"
  },"31": {
    "doc": "Framework Comparisons",
    "title": "Migration Considerations",
    "content": "When considering migration to MUXI, keep these points in mind: . Key Benefits . | Simplified agent creation and management | Integrated memory systems | Standardized external service integration | Real-time communication capabilities | Multi-user support | . Migration Approach . | Start with a single agent functionality | Add memory systems | Convert external integrations to MCP servers | Expand to multi-agent orchestration | Implement real-time features | . ",
    "url": "/muxi/reference/comparisons#migration-considerations",
    
    "relUrl": "/reference/comparisons#migration-considerations"
  },"32": {
    "doc": "Framework Comparisons",
    "title": "Best Practices",
    "content": "Based on production experience, here are recommended approaches: . Agent Design . | Create specialized agents with focused responsibilities | Use clear system messages to define agent behavior | Leverage context knowledge for improved responses | Implement appropriate memory systems | . Memory Configuration . | Size buffer memory based on conversation complexity | Use summarization for longer conversations | Implement long-term memory for important facts | Consider user-specific memory partitioning | . Deployment . | Start with the Python library for simple applications | Use the CLI for scripting and automation | Deploy the server for multi-user applications | Use WebSockets for real-time interfaces | . ",
    "url": "/muxi/reference/comparisons#best-practices",
    
    "relUrl": "/reference/comparisons#best-practices"
  },"33": {
    "doc": "Framework Comparisons",
    "title": "Conclusion",
    "content": "MUXI offers a comprehensive approach to building AI agent systems with a focus on: . | Multi-agent orchestration | Integrated memory systems | Standardized service integration | Real-time communication | Multi-user support | Multi-modal capabilities | . The best framework for your project depends on your specific requirements, existing infrastructure, and use case. MUXI excels in interactive, stateful AI applications with multiple specialized agents, particularly when real-time communication and user-specific experiences are important. ",
    "url": "/muxi/reference/comparisons#conclusion",
    
    "relUrl": "/reference/comparisons#conclusion"
  },"34": {
    "doc": "Framework Comparisons",
    "title": "Related Topics",
    "content": ". | Why MUXI? - More on MUXI’s advantages | Architecture - Understand MUXI’s design | Quick Start Guide - Get started with MUXI | . ",
    "url": "/muxi/reference/comparisons#related-topics",
    
    "relUrl": "/reference/comparisons#related-topics"
  },"35": {
    "doc": "Configuration Options",
    "title": "Configuration Options",
    "content": "MUXI Framework offers extensive configuration options to customize its behavior. This reference documents all available configuration parameters. ",
    "url": "/muxi/reference/configuration",
    
    "relUrl": "/reference/configuration"
  },"36": {
    "doc": "Configuration Options",
    "title": "Configuration Format",
    "content": "MUXI supports configuration via: . | YAML files (default) | JSON files | Environment variables | Direct programmatic configuration | . The default configuration file is located at config.yaml in the project root. You can specify an alternative configuration file using the --config command-line option. ",
    "url": "/muxi/reference/configuration#configuration-format",
    
    "relUrl": "/reference/configuration#configuration-format"
  },"37": {
    "doc": "Configuration Options",
    "title": "Core Configuration",
    "content": "Application . | Parameter | Type | Default | Description | . | app.name | string | \"MUXI Framework\" | Application name | . | app.host | string | \"127.0.0.1\" | Host to bind the server to | . | app.port | integer | 8000 | Port to bind the server to | . | app.log_level | string | \"info\" | Logging level (debug, info, warning, error, critical) | . | app.environment | string | \"development\" | Environment (development, testing, production) | . | app.debug | boolean | false | Enable debug mode | . Security . | Parameter | Type | Default | Description | . | security.secret_key | string | N/A (Required) | Secret key for JWT tokens and encryption | . | security.token_expiry | integer | 3600 | JWT token expiry in seconds | . | security.cors_origins | list | [\"*\"] | List of allowed CORS origins | . | security.cors_methods | list | [\"*\"] | List of allowed CORS methods | . | security.cors_headers | list | [\"*\"] | List of allowed CORS headers | . | security.rate_limit.enabled | boolean | true | Enable rate limiting | . | security.rate_limit.limit | integer | 60 | Default rate limit per minute | . ",
    "url": "/muxi/reference/configuration#core-configuration",
    
    "relUrl": "/reference/configuration#core-configuration"
  },"38": {
    "doc": "Configuration Options",
    "title": "Database Configuration",
    "content": "PostgreSQL . | Parameter | Type | Default | Description | . | database.url | string | \"postgresql://postgres:postgres@localhost:5432/muxi\" | Database connection URL | . | database.pool_size | integer | 5 | Connection pool size | . | database.max_overflow | integer | 10 | Maximum number of connections that can be created beyond pool_size | . | database.pool_recycle | integer | 300 | Connection recycle time in seconds | . | database.echo | boolean | false | Echo SQL queries for debugging | . ",
    "url": "/muxi/reference/configuration#database-configuration",
    
    "relUrl": "/reference/configuration#database-configuration"
  },"39": {
    "doc": "Configuration Options",
    "title": "Memory Configuration",
    "content": "| Parameter | Type | Default | Description | . | memory.buffer_size | integer | 10 | Size of the buffer memory (number of messages) | . | memory.search_k | integer | 4 | Number of memories to retrieve in semantic search | . | memory.similarity_threshold | float | 0.7 | Minimum similarity score for memory matches | . | memory.chunk_size | integer | 1024 | Size of text chunks for embeddings | . | memory.chunk_overlap | integer | 200 | Overlap between text chunks | . | memory.embedding_model | string | \"text-embedding-ada-002\" | Model to use for text embeddings | . ",
    "url": "/muxi/reference/configuration#memory-configuration",
    
    "relUrl": "/reference/configuration#memory-configuration"
  },"40": {
    "doc": "Configuration Options",
    "title": "Models Configuration",
    "content": "OpenAI . | Parameter | Type | Default | Description | . | models.openai.api_key | string | N/A (Required) | OpenAI API key | . | models.openai.organization | string | null | OpenAI organization ID | . | models.openai.default_model | string | \"gpt-4\" | Default model to use | . | models.openai.temperature | float | 0.7 | Temperature for sampling | . | models.openai.max_tokens | integer | 1024 | Maximum tokens in completion | . | models.openai.timeout | integer | 120 | API timeout in seconds | . | models.openai.retry_attempts | integer | 3 | Number of retry attempts for API calls | . Anthropic . | Parameter | Type | Default | Description | . | models.anthropic.api_key | string | N/A (Required) | Anthropic API key | . | models.anthropic.default_model | string | \"claude-3-opus-20240229\" | Default model to use | . | models.anthropic.temperature | float | 0.7 | Temperature for sampling | . | models.anthropic.max_tokens | integer | 1024 | Maximum tokens in completion | . | models.anthropic.timeout | integer | 120 | API timeout in seconds | . ",
    "url": "/muxi/reference/configuration#models-configuration",
    
    "relUrl": "/reference/configuration#models-configuration"
  },"41": {
    "doc": "Configuration Options",
    "title": "MCP Configuration",
    "content": "| Parameter | Type | Default | Description | . | mcp.enabled | boolean | true | Enable MCP system | . | mcp.servers | list | [] | List of MCP servers | . | mcp.discovery.enabled | boolean | true | Enable MCP server discovery | . | mcp.discovery.interval | integer | 300 | Server discovery interval in seconds | . | mcp.timeout | integer | 30 | Timeout for MCP server calls in seconds | . | mcp.retry_attempts | integer | 2 | Number of retry attempts for MCP calls | . MCP Server Configuration Example . mcp: servers: - id: \"weather\" name: \"Weather Service\" url: \"https://api.example.com/mcp/weather\" auth: type: \"api_key\" key_name: \"X-API-Key\" key_value: \"${WEATHER_API_KEY}\" functions: - name: \"getCurrentWeather\" description: \"Get current weather for a location\" parameters: location: type: \"string\" description: \"City name or coordinates\" units: type: \"string\" enum: [\"metric\", \"imperial\"] default: \"metric\" . ",
    "url": "/muxi/reference/configuration#mcp-configuration",
    
    "relUrl": "/reference/configuration#mcp-configuration"
  },"42": {
    "doc": "Configuration Options",
    "title": "MCP Servers Configuration",
    "content": "| Option | Type | Default | Description | . | mcp_servers.enabled | boolean | true | Enable MCP servers system | . | mcp_servers.search.url | string | \"http://localhost:5001\" | URL for the search MCP server | . | mcp_servers.search.api_key | string | null | API key for the search MCP server | . | mcp_servers.weather.url | string | \"http://localhost:5002\" | URL for the weather MCP server | . | mcp_servers.weather.api_key | string | null | API key for the weather MCP server | . | mcp_servers.calculator.url | string | \"http://localhost:5003\" | URL for the calculator MCP server | . ",
    "url": "/muxi/reference/configuration#mcp-servers-configuration",
    
    "relUrl": "/reference/configuration#mcp-servers-configuration"
  },"43": {
    "doc": "Configuration Options",
    "title": "WebSocket Configuration",
    "content": "| Parameter | Type | Default | Description | . | websocket.enabled | boolean | true | Enable WebSocket interface | . | websocket.ping_interval | integer | 30 | WebSocket ping interval in seconds | . | websocket.ping_timeout | integer | 10 | WebSocket ping timeout in seconds | . | websocket.max_message_size | integer | 1048576 | Maximum WebSocket message size in bytes | . ",
    "url": "/muxi/reference/configuration#websocket-configuration",
    
    "relUrl": "/reference/configuration#websocket-configuration"
  },"44": {
    "doc": "Configuration Options",
    "title": "Environment Variables",
    "content": "All configuration options can be set via environment variables using the following format: . MUXI_[SECTION]_[PARAMETER] . For example: . | MUXI_APP_PORT=9000 | MUXI_SECURITY_SECRET_KEY=mysecretkey | MUXI_MODELS_OPENAI_API_KEY=sk-... | . Nested parameters use underscore as separator: . | MUXI_SECURITY_RATE_LIMIT_ENABLED=false | . ",
    "url": "/muxi/reference/configuration#environment-variables",
    
    "relUrl": "/reference/configuration#environment-variables"
  },"45": {
    "doc": "Configuration Options",
    "title": "Programmatic Configuration",
    "content": "When using MUXI programmatically, you can set configuration options during initialization: . from muxi.core import MuxiApp app = MuxiApp( config={ \"app\": { \"name\": \"My Custom MUXI App\", \"port\": 9000 }, \"models\": { \"openai\": { \"api_key\": \"sk-...\", \"default_model\": \"gpt-4\" } } } ) . ",
    "url": "/muxi/reference/configuration#programmatic-configuration",
    
    "relUrl": "/reference/configuration#programmatic-configuration"
  },"46": {
    "doc": "Configuration Options",
    "title": "Configuration Precedence",
    "content": "Configuration values are loaded in the following order, with later sources overriding earlier ones: . | Default values | Configuration file | Environment variables | Programmatic configuration | . ",
    "url": "/muxi/reference/configuration#configuration-precedence",
    
    "relUrl": "/reference/configuration#configuration-precedence"
  },"47": {
    "doc": "Configuration Options",
    "title": "Sensitive Configuration",
    "content": "For security reasons, sensitive values like API keys should be provided through environment variables rather than in configuration files, especially in production environments. When using a configuration file, you can reference environment variables using ${ENV_VAR} syntax: . models: openai: api_key: \"${OPENAI_API_KEY}\" . ",
    "url": "/muxi/reference/configuration#sensitive-configuration",
    
    "relUrl": "/reference/configuration#sensitive-configuration"
  },"48": {
    "doc": "Configuration Options",
    "title": "Validation",
    "content": "MUXI validates configuration options at startup and will raise errors for required values that are missing or invalid. If you see configuration validation errors, check that: . | All required values are provided | Values are of the correct type | Enum values are from the allowed set | Referenced files or directories exist and are readable | . ",
    "url": "/muxi/reference/configuration#validation",
    
    "relUrl": "/reference/configuration#validation"
  },"49": {
    "doc": "Agent Configuration",
    "title": "Agent Configuration",
    "content": "This guide covers the various configuration options available when creating MUXI agents. ",
    "url": "/muxi/agents/configuration",
    
    "relUrl": "/agents/configuration"
  },"50": {
    "doc": "Agent Configuration",
    "title": "Basic Configuration",
    "content": "Declarative way . configs/basic_agent.json . { \"agent_id\": \"assistant\", \"description\": \"A general-purpose assistant that can help with a wide range of tasks.\", \"model\": { \"provider\": \"openai\", \"api_key\": \"${OPENAI_API_KEY}\", \"model\": \"gpt-4o\" }, \"system_message\": \"You are a helpful assistant.\" } . app.py . from muxi import muxi from dotenv import load_dotenv import os # Load environment variables load_dotenv() # Initialize MUXI app = muxi() # Add agent from configuration app.add_agent(\"configs/basic_agent.json\") # Chat with the agent response = await app.chat(\"assistant\", \"Hello, can you help me?\") print(response) . Programmatic way . import os from muxi.core.orchestrator import Orchestrator from muxi.core.models.openai import OpenAIModel # Initialize components orchestrator = Orchestrator() model = OpenAIModel( api_key=os.getenv(\"OPENAI_API_KEY\"), model=\"gpt-4o\" ) # Create agent orchestrator.create_agent( agent_id=\"assistant\", description=\"A general-purpose assistant that can help with a wide range of tasks.\", model=model, system_message=\"You are a helpful assistant.\" ) # Chat with the agent response = orchestrator.chat(\"assistant\", \"Hello, can you help me?\") print(response) . ",
    "url": "/muxi/agents/configuration#basic-configuration",
    
    "relUrl": "/agents/configuration#basic-configuration"
  },"51": {
    "doc": "Agent Configuration",
    "title": "Required Configuration Parameters",
    "content": "| Parameter | Description | Example | . | agent_id | Unique identifier for the agent | \"assistant\" | . | description | Description of the agent’s purpose and capabilities | \"A helpful assistant for answering questions\" | . | model | Model configuration including provider and API key | {\"provider\": \"openai\", \"api_key\": \"${OPENAI_API_KEY}\", \"model\": \"gpt-4o\"} | . ",
    "url": "/muxi/agents/configuration#required-configuration-parameters",
    
    "relUrl": "/agents/configuration#required-configuration-parameters"
  },"52": {
    "doc": "Agent Configuration",
    "title": "Model Configuration",
    "content": "OpenAI Models . Declarative way (JSON) . configs/openai_model.json . { \"agent_id\": \"openai_assistant\", \"description\": \"An assistant powered by OpenAI models with custom parameters.\", \"model\": { \"provider\": \"openai\", \"api_key\": \"${OPENAI_API_KEY}\", \"model\": \"gpt-4o\", \"temperature\": 0.7, \"top_p\": 0.9, \"max_tokens\": 1000, \"presence_penalty\": 0.0, \"frequency_penalty\": 0.0 } } . Declarative way (YAML) . configs/openai_model.yaml . --- agent_id: openai_assistant description: An assistant powered by OpenAI models with custom parameters. model: provider: openai api_key: \"${OPENAI_API_KEY}\" model: gpt-4o temperature: 0.7 top_p: 0.9 max_tokens: 1000 presence_penalty: 0 frequency_penalty: 0 . Programmatic way . import os from muxi.core.orchestrator import Orchestrator from muxi.core.models.openai import OpenAIModel # Initialize orchestrator orchestrator = Orchestrator() # Create an OpenAI model with custom parameters model = OpenAIModel( api_key=os.getenv(\"OPENAI_API_KEY\"), model=\"gpt-4o\", temperature=0.7, top_p=0.9, max_tokens=1000, presence_penalty=0.0, frequency_penalty=0.0 ) # Create an agent with the configured model orchestrator.create_agent( agent_id=\"openai_assistant\", description=\"An assistant powered by OpenAI models with custom parameters.\", model=model ) # Chat with the OpenAI-powered agent response = orchestrator.chat(\"openai_assistant\", \"Tell me about machine learning.\") print(response) . Anthropic Models . Declarative way (JSON) . configs/anthropic_model.json . { \"agent_id\": \"claude_assistant\", \"description\": \"An assistant powered by Anthropic's Claude model.\", \"model\": { \"provider\": \"anthropic\", \"api_key\": \"${ANTHROPIC_API_KEY}\", \"model\": \"claude-3-opus-20240229\", \"temperature\": 0.7, \"max_tokens\": 1000 } } . Declarative way (YAML) . configs/anthropic_model.yaml . --- agent_id: claude_assistant description: An assistant powered by Anthropic's Claude model. model: provider: anthropic api_key: \"${ANTHROPIC_API_KEY}\" model: claude-3-opus-20240229 temperature: 0.7 max_tokens: 1000 . Programmatic way . import os from muxi.core.orchestrator import Orchestrator from muxi.core.models.anthropic import AnthropicModel # Initialize orchestrator orchestrator = Orchestrator() # Create an Anthropic model model = AnthropicModel( api_key=os.getenv(\"ANTHROPIC_API_KEY\"), model=\"claude-3-opus-20240229\", temperature=0.7, max_tokens=1000 ) # Create an agent with the Anthropic model orchestrator.create_agent( agent_id=\"claude_assistant\", description=\"An assistant powered by Anthropic's Claude model.\", model=model ) # Chat with the Claude-powered agent response = orchestrator.chat(\"claude_assistant\", \"Tell me about the history of AI.\") print(response) . Google Models . Declarative way . configs/google_model.json . { \"agent_id\": \"gemini_assistant\", \"description\": \"An assistant powered by Google's Gemini model.\", \"model\": { \"provider\": \"google\", \"api_key\": \"${GOOGLE_API_KEY}\", \"model\": \"gemini-1.5-pro\", \"temperature\": 0.7, \"max_tokens\": 1000 } } . Programmatic way . import os from muxi.core.orchestrator import Orchestrator from muxi.core.models.google import GoogleModel # Initialize orchestrator orchestrator = Orchestrator() # Create a Google model model = GoogleModel( api_key=os.getenv(\"GOOGLE_API_KEY\"), model=\"gemini-1.5-pro\", temperature=0.7, max_tokens=1000 ) # Create an agent with the Google model orchestrator.create_agent( agent_id=\"gemini_assistant\", description=\"An assistant powered by Google's Gemini model.\", model=model ) # Chat with the Gemini-powered agent response = orchestrator.chat(\"gemini_assistant\", \"Tell me about quantum computing.\") print(response) . Azure OpenAI Models . Declarative way . configs/azure_model.json . { \"agent_id\": \"azure_assistant\", \"description\": \"An assistant powered by Azure-hosted OpenAI models.\", \"model\": { \"provider\": \"azure_openai\", \"api_key\": \"${AZURE_OPENAI_API_KEY}\", \"api_base\": \"${AZURE_OPENAI_ENDPOINT}\", \"api_version\": \"2023-12-01-preview\", \"deployment_name\": \"gpt-4\" } } . Programmatic way . import os from muxi.core.orchestrator import Orchestrator from muxi.core.models.azure_openai import AzureOpenAIModel # Initialize orchestrator orchestrator = Orchestrator() # Create an Azure OpenAI model model = AzureOpenAIModel( api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"), api_base=os.getenv(\"AZURE_OPENAI_ENDPOINT\"), api_version=\"2023-12-01-preview\", deployment_name=\"gpt-4\" ) # Create an agent with the Azure model orchestrator.create_agent( agent_id=\"azure_assistant\", description=\"An assistant powered by Azure-hosted OpenAI models.\", model=model ) # Chat with the Azure-powered agent response = orchestrator.chat(\"azure_assistant\", \"What are the benefits of cloud computing?\") print(response) . Local Models . Declarative way . configs/local_model.json . { \"agent_id\": \"local_assistant\", \"description\": \"An assistant powered by a locally-hosted model.\", \"model\": { \"provider\": \"local\", \"model_path\": \"/path/to/model\", \"model_type\": \"llama2\" } } . Programmatic way . from muxi.core.orchestrator import Orchestrator from muxi.core.models.local import LocalModel # Initialize orchestrator orchestrator = Orchestrator() # Create a local model model = LocalModel( model_path=\"/path/to/model\", model_type=\"llama2\" ) # Create an agent with the local model orchestrator.create_agent( agent_id=\"local_assistant\", description=\"An assistant powered by a locally-hosted model.\", model=model ) # Chat with the locally-hosted agent response = orchestrator.chat(\"local_assistant\", \"Tell me about open-source AI.\") print(response) . ",
    "url": "/muxi/agents/configuration#model-configuration",
    
    "relUrl": "/agents/configuration#model-configuration"
  },"53": {
    "doc": "Agent Configuration",
    "title": "System Message Configuration",
    "content": "The system message provides instructions to the AI about its role and behavior. Declarative way . configs/system_message.json . { \"agent_id\": \"science_assistant\", \"description\": \"A specialized assistant for science and technology topics.\", \"model\": { \"provider\": \"openai\", \"api_key\": \"${OPENAI_API_KEY}\", \"model\": \"gpt-4o\" }, \"system_message\": \"You are a helpful assistant specialized in answering questions about science and technology. Keep your answers concise but informative.\" } . Programmatic way . import os from muxi.core.orchestrator import Orchestrator from muxi.core.models.openai import OpenAIModel # Initialize orchestrator orchestrator = Orchestrator() # Create a model model = OpenAIModel( api_key=os.getenv(\"OPENAI_API_KEY\"), model=\"gpt-4o\" ) # Create an agent with specialized system message orchestrator.create_agent( agent_id=\"science_assistant\", description=\"A specialized assistant for science and technology topics.\", model=model, system_message=\"You are a helpful assistant specialized in answering questions about science and technology. Keep your answers concise but informative.\" ) # Chat with the specialized agent response = orchestrator.chat(\"science_assistant\", \"Explain how nuclear fusion works.\") print(response) . Multi-line System Messages . Declarative way . configs/multiline_system_message.json . { \"agent_id\": \"python_assistant\", \"description\": \"A specialized assistant for Python programming.\", \"model\": { \"provider\": \"openai\", \"api_key\": \"${OPENAI_API_KEY}\", \"model\": \"gpt-4o\" }, \"system_message\": \"You are a Python coding assistant.\\n\\nYour role is to help users with Python programming questions.\\n\\nAlways provide explanations along with code examples.\\n\\nFocus on best practices and readability.\" } . Programmatic way . import os from muxi.core.orchestrator import Orchestrator from muxi.core.models.openai import OpenAIModel # Initialize orchestrator orchestrator = Orchestrator() # Create a model model = OpenAIModel( api_key=os.getenv(\"OPENAI_API_KEY\"), model=\"gpt-4o\" ) # Define a multi-line system message system_message = \"\"\"You are a Python coding assistant. Your role is to help users with Python programming questions. Always provide explanations along with code examples. Focus on best practices and readability.\"\"\" # Create an agent with the multi-line system message orchestrator.create_agent( agent_id=\"python_assistant\", description=\"A specialized assistant for Python programming.\", model=model, system_message=system_message ) # Chat with the specialized coding agent response = orchestrator.chat(\"python_assistant\", \"How do I read a CSV file in Python?\") print(response) . ",
    "url": "/muxi/agents/configuration#system-message-configuration",
    
    "relUrl": "/agents/configuration#system-message-configuration"
  },"54": {
    "doc": "Agent Configuration",
    "title": "Memory Configuration",
    "content": "Buffer Memory . Declarative way . configs/buffer_memory.json . { \"agent_id\": \"assistant\", \"description\": \"An assistant with buffer memory for maintaining conversation context.\", \"model\": { \"provider\": \"openai\", \"api_key\": \"${OPENAI_API_KEY}\", \"model\": \"gpt-4o\" }, \"buffer_memory\": { \"type\": \"buffer\", \"max_tokens\": 2000, \"include_system_messages\": true } } . Programmatic way . import os from muxi.core.orchestrator import Orchestrator from muxi.core.models.openai import OpenAIModel from muxi.core.memory.buffer import BufferMemory # Initialize components orchestrator = Orchestrator() model = OpenAIModel( api_key=os.getenv(\"OPENAI_API_KEY\"), model=\"gpt-4o\" ) # Create buffer memory with custom settings buffer = BufferMemory( max_tokens=2000, include_system_messages=True ) # Create an agent with buffer memory orchestrator.create_agent( agent_id=\"assistant\", description=\"An assistant with buffer memory for maintaining conversation context.\", model=model, buffer_memory=buffer ) # Have a conversation that requires context orchestrator.chat(\"assistant\", \"My name is Sam.\") response = orchestrator.chat(\"assistant\", \"Do you remember my name?\") print(response) # Should mention \"Sam\" . Long-Term Memory . Declarative way . configs/long_term_memory.json . { \"agent_id\": \"assistant\", \"description\": \"An assistant with long-term memory capabilities.\", \"model\": { \"provider\": \"openai\", \"api_key\": \"${OPENAI_API_KEY}\", \"model\": \"gpt-4o\" }, \"memory\": { \"buffer\": 15, \"long_term\": \"postgresql://user:password@localhost:5432/muxi\" } } . Programmatic way . import os from muxi.core.orchestrator import Orchestrator from muxi.core.models.openai import OpenAIModel from muxi.core.memory.long_term import LongTermMemory # Initialize components orchestrator = Orchestrator() model = OpenAIModel( api_key=os.getenv(\"OPENAI_API_KEY\"), model=\"gpt-4o\" ) # Configure long-term memory # Option 1: PostgreSQL - for production environments postgres_connection = \"postgresql://user:password@localhost:5432/muxi\" # Or use environment variable: # postgres_connection = os.getenv(\"POSTGRES_DATABASE_URL\") # Option 2: SQLite - for local development sqlite_connection = \"sqlite:///data/memory.db\" # Choose the connection string based on your needs connection_string = postgres_connection # or sqlite_connection long_term = LongTermMemory(connection_string=connection_string) # Create an agent with long-term memory orchestrator.create_agent( agent_id=\"assistant\", description=\"An assistant with long-term memory capabilities.\", model=model, long_term_memory=long_term ) # Store information in long-term memory orchestrator.chat(\"assistant\", \"Remember that I like to travel to Japan.\") # Clear buffer memory to simulate a new session agent = orchestrator.get_agent(\"assistant\") agent.buffer_memory.clear() # The agent should still remember the information response = orchestrator.chat(\"assistant\", \"Where do I like to travel?\") print(response) # Should mention \"Japan\" . ",
    "url": "/muxi/agents/configuration#memory-configuration",
    
    "relUrl": "/agents/configuration#memory-configuration"
  },"55": {
    "doc": "Agent Configuration",
    "title": "MCP Server Configuration",
    "content": "Agents can connect to MCP (Model Context Protocol) servers to access external tools and capabilities: . mcp_servers: - name: web_search url: http://localhost:5001 credentials: # Credentials are optional and can be omitted if not needed - id: search_api_key param_name: api_key required: false env_fallback: SEARCH_API_KEY - name: calculator command: npx -y @modelcontextprotocol/server-calculator # No credentials needed for this server, so the credentials section is omitted . MCP servers can use either: . | HTTP transport (specified with url parameter) | Command-line transport (specified with command parameter) | . Each MCP server can have optional credentials for authentication, though many servers don’t require any credentials at all. ",
    "url": "/muxi/agents/configuration#mcp-server-configuration",
    
    "relUrl": "/agents/configuration#mcp-server-configuration"
  },"56": {
    "doc": "Agent Configuration",
    "title": "Complete Configuration Example",
    "content": "Declarative way . configs/complete_configuration.yaml . { \"agent_id\": \"expert_assistant\", \"description\": \"A comprehensive AI assistant with multiple capabilities.\", \"model\": { \"provider\": \"openai\", \"api_key\": \"${OPENAI_API_KEY}\", \"model\": \"gpt-4o\", \"temperature\": 0.7, \"max_tokens\": 1000 }, \"system_message\": \"You are an expert assistant with broad knowledge and capabilities. You can help with research, writing, problem-solving, and many other tasks. Always be helpful, accurate, and concise.\", \"memory\": { \"buffer\": 20, \"long_term\": \"postgresql://user:password@localhost:5432/muxi\" }, \"mcp_servers\": [ { \"name\": \"web_search\", \"url\": \"http://localhost:5001\", \"credentials\": [ { \"id\": \"search_api_key\", \"param_name\": \"api_key\", \"required\": true, \"env_fallback\": \"SEARCH_API_KEY\" } ] }, { \"name\": \"calculator\", \"url\": \"http://localhost:5002\" }, { \"name\": \"weather\", \"url\": \"http://localhost:5003\", \"credentials\": [ { \"id\": \"weather_api_key\", \"param_name\": \"api_key\", \"required\": true, \"env_fallback\": \"WEATHER_API_KEY\" } ] } ] } . app.py . from muxi import muxi from dotenv import load_dotenv import os # Load environment variables load_dotenv() # Initialize MUXI app = muxi() # Add fully-configured agent app.add_agent(\"configs/complete_configuration.yaml\") # Chat with the comprehensive agent response = await app.chat(\"expert_assistant\", \"Tell me about recent advances in AI.\") print(response) . Programmatic way . import os from muxi.core.orchestrator import Orchestrator from muxi.core.models.openai import OpenAIModel from muxi.core.memory.buffer import BufferMemory from muxi.core.memory.long_term import LongTermMemory # Initialize the orchestrator orchestrator = Orchestrator() # Create model model = OpenAIModel( api_key=os.getenv(\"OPENAI_API_KEY\"), model=\"gpt-4o\", temperature=0.7, max_tokens=1000 ) # Configure memory buffer = BufferMemory(max_tokens=4000) long_term = LongTermMemory(connection_string=\"postgresql://user:password@localhost:5432/muxi\") # Create a fully-configured agent agent = orchestrator.create_agent( agent_id=\"expert_assistant\", description=\"A comprehensive AI assistant with multiple capabilities.\", model=model, system_message=\"You are an expert assistant with broad knowledge and capabilities. You can help with research, writing, problem-solving, and many other tasks. Always be helpful, accurate, and concise.\", buffer_memory=buffer, long_term_memory=long_term, ) # Connect to MCP servers await agent.connect_mcp_server( name=\"web_search\", url=\"http://localhost:5001\", credentials={\"api_key\": os.getenv(\"SEARCH_API_KEY\")} ) await agent.connect_mcp_server( name=\"calculator\", url=\"http://localhost:5002\" ) await agent.connect_mcp_server( name=\"weather\", url=\"http://localhost:5003\", credentials={\"api_key\": os.getenv(\"WEATHER_API_KEY\")} ) # Chat with the agent response = await orchestrator.chat(\"expert_assistant\", \"Tell me about recent advances in AI.\") print(response) . ",
    "url": "/muxi/agents/configuration#complete-configuration-example",
    
    "relUrl": "/agents/configuration#complete-configuration-example"
  },"57": {
    "doc": "Agent Configuration",
    "title": "Configuration Best Practices",
    "content": ". | Use Environment Variables for API Keys . | Always use environment variables for sensitive information like API keys | Example: \"api_key\": \"${OPENAI_API_KEY}\" | . | Set Appropriate Temperature . | Use lower values (0.0-0.3) for factual tasks | Use moderate values (0.3-0.7) for balanced responses | Use higher values (0.7-1.0) for creative tasks | . | Craft Detailed System Messages . | Be specific about the agent’s role, capabilities, and limitations | Include examples of desired behavior when possible | Structure long system messages with clear sections | . | Balance Memory Configuration . | Set appropriate token limits for buffer memory based on your model’s context window | Use long-term memory for important information that needs to persist | Use context knowledge for static information that doesn’t change | . | Use Descriptive Agent IDs . | Choose agent IDs that clearly reflect their purpose | Follow a consistent naming convention | . | . ",
    "url": "/muxi/agents/configuration#configuration-best-practices",
    
    "relUrl": "/agents/configuration#configuration-best-practices"
  },"58": {
    "doc": "Agent Configuration",
    "title": "Next Steps",
    "content": "Now that you’ve learned about agent configuration, you can: . | Add memory capabilities to your agent - see Adding Memory | Create multi-agent systems - see Multi-Agent Systems | Learn about advanced agent capabilities - see Advanced Features | . ",
    "url": "/muxi/agents/configuration#next-steps",
    
    "relUrl": "/agents/configuration#next-steps"
  },"59": {
    "doc": "Contributing to MUXI",
    "title": "Contributing to the MUXI Framework",
    "content": "Thank you for your interest in contributing to the MUXI Framework! This guide will help you start contributing to the project, whether you’re fixing bugs, adding new features, improving documentation, or reporting issues. ",
    "url": "/muxi/contributing#contributing-to-the-muxi-framework",
    
    "relUrl": "/contributing#contributing-to-the-muxi-framework"
  },"60": {
    "doc": "Contributing to MUXI",
    "title": "Table of Contents",
    "content": ". | Code of Conduct | Getting Started | Development Environment | Project Structure | Coding Guidelines | Pull Request Process | Issue Reporting | Feature Requests | Documentation | Testing | Community | Contributor License Agreement | . ",
    "url": "/muxi/contributing#table-of-contents",
    
    "relUrl": "/contributing#table-of-contents"
  },"61": {
    "doc": "Contributing to MUXI",
    "title": "Code of Conduct",
    "content": "By participating in this project, you agree to abide by our Code of Conduct. We expect all contributors to be respectful, inclusive, and considerate of others. Harassment or disrespectful behavior of any kind will not be tolerated. ",
    "url": "/muxi/contributing#code-of-conduct",
    
    "relUrl": "/contributing#code-of-conduct"
  },"62": {
    "doc": "Contributing to MUXI",
    "title": "Getting Started",
    "content": ". | Fork the repository on GitHub | Clone your fork locally: . git clone https://github.com/ranaroussi/muxi.git cd muxi . | Add the original repository as an upstream remote: . git remote add upstream https://github.com/ranaroussi/muxi.git . | Create a new branch for your changes: . git checkout -b feature/your-feature-name . | . ",
    "url": "/muxi/contributing#getting-started",
    
    "relUrl": "/contributing#getting-started"
  },"63": {
    "doc": "Contributing to MUXI",
    "title": "Development Environment",
    "content": ". | Install Python 3.9 or later | Set up a virtual environment: . python -m venv venv source venv/bin/activate # On Windows: venv\\Scripts\\activate . | Install the framework in development mode: . pip install -e . | Install development dependencies: . pip install -r requirements-dev.txt . | . For frontend development: . | Navigate to the web module directory: . cd packages/web/src/muxi/web/ui . | Install Node.js dependencies: . npm install . | Start the development server: . npm run dev . | . ",
    "url": "/muxi/contributing#development-environment",
    
    "relUrl": "/contributing#development-environment"
  },"64": {
    "doc": "Contributing to MUXI",
    "title": "Project Structure",
    "content": "The MUXI Framework follows a modular architecture: .github/ # GitHub configuration (workflows, templates) docs/ # Documentation files packages/ # Source code organized into modules └─ core/ # Core components (Agent, Orchestrator, MCP) └─ src/muxi/core/ # Core module source code └─ server/ # API and WebSocket server └─ src/muxi/server/ # Server module source code └─ cli/ # Command-line interface └─ src/muxi/cli/ # CLI module source code └─ web/ # Web dashboard └─ src/muxi/web/ # Web module source code └─ meta/ # Meta-package for MUXI distribution tests/ # Test files examples/ # Example usage └─ configs/ # Example configuration files scripts/ # Utility scripts . ",
    "url": "/muxi/contributing#project-structure",
    
    "relUrl": "/contributing#project-structure"
  },"65": {
    "doc": "Contributing to MUXI",
    "title": "Coding Guidelines",
    "content": "Python Guidelines . | Follow PEP 8 guidelines for code formatting | Use 4 spaces for indentation (no tabs) | Maximum line length of 88 characters (Black default) | Use Black for code formatting: black packages tests | Use isort for import sorting: isort packages tests | Use flake8 for linting: flake8 packages tests | Use type hints for all function signatures | Add docstrings in Google format for all functions, classes, and modules | . Code organization: . | Use descriptive variable names in snake_case | Use PascalCase for class names | Use UPPER_SNAKE_CASE for constants | Use _leading_underscore for private attributes/methods | . Import conventions: . from typing import Dict, List, Optional, Any # Import specific types import standard_library # Standard library imports first import third_party_library # Third party imports second from muxi.core.module import local_import # Local imports last . TypeScript/React Guidelines (Web UI) . | Use TypeScript for all frontend code | Follow consistent naming conventions: . | PascalCase for React components and interface names | camelCase for variables, functions, and methods | UPPER_SNAKE_CASE for constants | . | Use functional components with hooks | Use proper type annotations | Format code with prettier | . MCP (Model Context Protocol) Guidelines . When working with the Model Context Protocol: . | Follow the official MCP specification | Implement proper tool call handling | Properly format messages for different language model providers | Validate all inputs for security | Test all tool integrations thoroughly | . ",
    "url": "/muxi/contributing#coding-guidelines",
    
    "relUrl": "/contributing#coding-guidelines"
  },"66": {
    "doc": "Contributing to MUXI",
    "title": "Pull Request Process",
    "content": ". | Ensure your code meets the project’s coding guidelines | Run the tests to make sure your changes don’t break existing functionality: . python -m pytest . | Update the documentation if you’re changing any user-facing features | Make sure your commit messages are clear and follow conventional commit format: . type(scope): description body [optional footer] . Types include: feat, fix, docs, style, refactor, test, chore . | Push your changes to your fork: . git push origin feature/your-feature-name . | Submit a pull request to the main repository | Address any feedback from reviewers | . Pull requests require at least one approval from a maintainer before being merged. ",
    "url": "/muxi/contributing#pull-request-process",
    
    "relUrl": "/contributing#pull-request-process"
  },"67": {
    "doc": "Contributing to MUXI",
    "title": "Issue Reporting",
    "content": "When reporting issues, please include as much information as possible: . | Steps to reproduce the issue | Expected behavior | Actual behavior | Screenshots (if applicable) | Environment details (OS, Python version, etc.) | Any relevant logs or error messages | . Use the issue templates provided in the repository when available. ",
    "url": "/muxi/contributing#issue-reporting",
    
    "relUrl": "/contributing#issue-reporting"
  },"68": {
    "doc": "Contributing to MUXI",
    "title": "Feature Requests",
    "content": "Feature requests are welcome. To submit a feature request: . | Check existing issues and pull requests to avoid duplicates | Use the feature request template if available | Clearly describe the problem your feature would solve | Provide examples of how the feature would be used | Indicate if you’re willing to contribute the implementation | . ",
    "url": "/muxi/contributing#feature-requests",
    
    "relUrl": "/contributing#feature-requests"
  },"69": {
    "doc": "Contributing to MUXI",
    "title": "Documentation",
    "content": "Documentation is critical to the success of the project. When contributing: . | Update relevant documentation for any code changes | Follow the existing style and formatting | Use clear language and provide examples where possible | Document both API usage and implementation details | Add docstrings for new functions, methods, and classes | . ",
    "url": "/muxi/contributing#documentation",
    
    "relUrl": "/contributing#documentation"
  },"70": {
    "doc": "Contributing to MUXI",
    "title": "Testing",
    "content": ". | Write unit tests for all new functionality | Use pytest as the testing framework | Run the existing test suite before submitting a PR: . python -m pytest . | Aim for high test coverage, especially for business logic | Test both happy paths and error cases | . ",
    "url": "/muxi/contributing#testing",
    
    "relUrl": "/contributing#testing"
  },"71": {
    "doc": "Contributing to MUXI",
    "title": "Contributor License Agreement",
    "content": "That we do not have any potential problems later, it is sadly necessary to sign a Contributor License Agreement. That can be done literally with the push of a button. Once a pull request is opened, an automated bot will promptly leave a comment requesting the agreement to be signed. The pull request can only be merged once the signature is obtained. Thank you for contributing to the MUXI Framework! Your efforts help make this project better for everyone. ",
    "url": "/muxi/contributing#contributor-license-agreement",
    
    "relUrl": "/contributing#contributor-license-agreement"
  },"72": {
    "doc": "Contributing to MUXI",
    "title": "Contributing to MUXI",
    "content": " ",
    "url": "/muxi/contributing",
    
    "relUrl": "/contributing"
  },"73": {
    "doc": "Examples Library",
    "title": "Examples Library",
    "content": "This page provides a collection of practical code examples to help you understand how to use the MUXI Framework for common tasks. ",
    "url": "/muxi/reference/examples",
    
    "relUrl": "/reference/examples"
  },"74": {
    "doc": "Examples Library",
    "title": "Basic Usage",
    "content": "Creating a Simple Agent . from muxi.core.agent import Agent from muxi.core.models.openai import OpenAIModel # Create a simple agent with OpenAI model agent = Agent( name=\"assistant\", model=OpenAIModel( model=\"gpt-4o\", api_key=\"your-openai-api-key\" ), system_message=\"You are a helpful assistant that provides concise answers.\" ) # Chat with the agent response = agent.chat(\"What is the capital of France?\") print(response) # \"The capital of France is Paris.\" . Using Configuration Files . from muxi import muxi # Initialize MUXI app app = muxi() # Add an agent from a YAML configuration file app.add_agent(\"weather\", \"configs/weather_agent.yaml\") # Chat with the agent response = app.chat(\"What's the weather like in New York?\", agent_name=\"weather\") print(response) . Example YAML configuration (configs/weather_agent.yaml): . name: weather_assistant description: \"Specialized in providing weather forecasts and current conditions.\" system_message: You are a helpful assistant that can check the weather. model: provider: openai api_key: \"${OPENAI_API_KEY}\" model: gpt-4o temperature: 0.7 mcp_servers: - name: weather_api url: \"http://localhost:5001\" api_key: \"${WEATHER_API_KEY}\" . ",
    "url": "/muxi/reference/examples#basic-usage",
    
    "relUrl": "/reference/examples#basic-usage"
  },"75": {
    "doc": "Examples Library",
    "title": "Memory Systems",
    "content": "Using Buffer Memory . from muxi.core.agent import Agent from muxi.core.models.openai import OpenAIModel from muxi.core.memory.buffer import BufferMemory # Create buffer memory with a window size of 5 messages buffer = BufferMemory(buffer_size=5) # Create an orchestrator with buffer memory orchestrator = Orchestrator( buffer_memory=buffer ) # Create an agent agent = Agent( name=\"assistant\", model=OpenAIModel(\"gpt-4o\"), system_message=\"You are a helpful assistant.\" ) # Add the agent to the orchestrator orchestrator.add_agent(agent) # First message response1 = orchestrator.chat(\"assistant\", \"My name is Alice.\") print(response1) # Second message (agent will remember the user's name) response2 = orchestrator.chat(\"assistant\", \"What's my name?\") print(response2) # Will include \"Alice\" . Using Long-Term Memory . from muxi.core.agent import Agent from muxi.core.models.openai import OpenAIModel from muxi.core.memory.long_term import LongTermMemory # Create long-term memory with database connection long_term_memory = LongTermMemory( connection_string=\"postgresql://user:pass@localhost/db\" ) # Create an orchestrator with buffer memory orchestrator = Orchestrator( long_term_memory=long_term_memory ) # Create an agent with long-term memory agent = Agent( name=\"assistant\", model=OpenAIModel(\"gpt-4o\"), system_message=\"You are a helpful assistant.\" ) # Add the agent to the orchestrator orchestrator.add_agent(agent) # Store important information response1 = orchestrator.chat(\"assistant\", \"Remember that my favorite color is blue.\") print(response1) # Later conversation (even after restarting the application) response2 = orchestrator.chat(\"assistant\", \"What's my favorite color?\") print(response2) # Will include \"blue\" . Multi-User Memory with Memobase . from muxi.core.agent import Agent from muxi.core.models.openai import OpenAIModel from muxi.core.memory.memobase import Memobase # Create Memobase for multi-user memory memobase = Memobase( connection_string=\"postgresql://user:pass@localhost/db\" ) # Create an orchestrator with buffer memory orchestrator = Orchestrator( long_term_memory=memobase ) # Create an agent with Memobase agent = Agent( name=\"assistant\", model=OpenAIModel(\"gpt-4o\"), system_message=\"You are a helpful assistant.\" ) # Add the agent to the orchestrator orchestrator.add_agent(agent) # Chat with user-specific context response1 = orchestrator.chat(\"assistant\", \"My name is Alice.\", user_id=\"user1\") response2 = orchestrator.chat(\"assistant\", \"My name is Bob.\", user_id=\"user2\") # Later conversations with separate contexts response3 = orchestrator.chat(\"assistant\", \"What's my name?\", user_id=\"user1\") print(response3) # Will include \"Alice\" response4 = orchestrator.chat(\"assistant\", \"What's my name?\", user_id=\"user2\") print(response4) # Will include \"Bob\" . ",
    "url": "/muxi/reference/examples#memory-systems",
    
    "relUrl": "/reference/examples#memory-systems"
  },"76": {
    "doc": "Examples Library",
    "title": "MCP Servers",
    "content": "Using an MCP Server . from muxi.core.agent import Agent from muxi.core.models.openai import OpenAIModel from muxi.core.mcp import MCPHandler # Create MCP handler for weather service weather_mcp = MCPHandler( name=\"weather_api\", url=\"http://localhost:5001\", api_key=\"your-weather-api-key\" ) # Create an agent with MCP handler agent = Agent( name=\"weather_assistant\", model=OpenAIModel(\"gpt-4o\"), system_message=\"You are a helpful assistant that can check the weather.\", mcp_handlers=[weather_mcp] ) # Chat with the agent (will use weather MCP when needed) response = agent.chat(\"What's the weather like in New York?\") print(response) . Creating a Custom MCP Server . from fastapi import FastAPI, Depends, HTTPException from pydantic import BaseModel from typing import Dict, Any app = FastAPI() class MCPRequest(BaseModel): function: str parameters: Dict[str, Any] class MCPResponse(BaseModel): result: Dict[str, Any] status: str = \"success\" @app.post(\"/\") async def handle_mcp_request(request: MCPRequest): if request.function == \"getCurrentWeather\": # Implement weather functionality location = request.parameters.get(\"location\", \"\") units = request.parameters.get(\"units\", \"metric\") # In a real implementation, you would call a weather API here weather_data = { \"temperature\": 75, \"conditions\": \"sunny\", \"humidity\": 45, \"wind_speed\": 10 } return MCPResponse(result=weather_data) else: raise HTTPException(status_code=400, detail=f\"Unknown function: {request.function}\") if __name__ == \"__main__\": import uvicorn uvicorn.run(app, host=\"0.0.0.0\", port=5001) . ",
    "url": "/muxi/reference/examples#mcp-servers",
    
    "relUrl": "/reference/examples#mcp-servers"
  },"77": {
    "doc": "Examples Library",
    "title": "Orchestration",
    "content": "Multi-Agent System . from muxi.core.orchestrator import Orchestrator from muxi.core.agent import Agent from muxi.core.models.openai import OpenAIModel # Create orchestrator orchestrator = Orchestrator() # Add specialized agents orchestrator.add_agent( Agent( name=\"weather_agent\", model=OpenAIModel(\"gpt-4o\"), system_message=\"You specialize in providing weather information and forecasts.\" ) ) orchestrator.add_agent( Agent( name=\"finance_agent\", model=OpenAIModel(\"gpt-4o\"), system_message=\"You specialize in financial advice and market analysis.\" ) ) # Automatic routing to the appropriate agent response1 = orchestrator.chat(\"What's the weather like in New York?\") print(response1) # Handled by weather_agent response2 = orchestrator.chat(\"How are the stock markets doing today?\") print(response2) # Handled by finance_agent . ",
    "url": "/muxi/reference/examples#orchestration",
    
    "relUrl": "/reference/examples#orchestration"
  },"78": {
    "doc": "Examples Library",
    "title": "Domain Knowledge",
    "content": "Adding Structured Knowledge . from muxi.core.agent import Agent from muxi.core.models.openai import OpenAIModel from muxi.core.memory.context_memory import ContextMemory # Create an agent agent = Agent( name=\"assistant\", model=OpenAIModel(\"gpt-4o\"), system_message=\"You are a helpful assistant.\" ) # Agent can use this knowledge response = agent.chat(\"What products does the company sell?\") print(response) # Will include widgets, gadgets, and tools . Adding Document Knowledge . from muxi.core.agent import Agent from muxi.core.models.openai import OpenAIModel # Create an agent agent = Agent( name=\"assistant\", model=OpenAIModel(\"gpt-4o\"), system_message=\"You are a helpful assistant.\" ) # Agent can use this knowledge response = agent.chat(\"What is the company's mission statement?\") print(response) # Will include information from the document . ",
    "url": "/muxi/reference/examples#domain-knowledge",
    
    "relUrl": "/reference/examples#domain-knowledge"
  },"79": {
    "doc": "Examples Library",
    "title": "Communication Interfaces",
    "content": "REST API Server . from muxi import muxi # Initialize MUXI app app = muxi() # Add agents app.add_agent(\"assistant\", \"configs/assistant.yaml\") app.add_agent(\"coder\", \"configs/coder.yaml\") # Start the server app.run(host=\"0.0.0.0\", port=5050) . WebSocket Client . import asyncio import websockets import json async def chat_with_agent(): async with websockets.connect(\"ws://localhost:5050/ws\") as websocket: # Send a message await websocket.send(json.dumps({ \"type\": \"message\", \"content\": \"What is the capital of France?\", \"agent\": \"assistant\", \"user_id\": \"user123\" })) # Receive streaming response while True: response = await websocket.recv() response_data = json.loads(response) if response_data[\"type\"] == \"chunk\": # Process streaming chunk print(response_data[\"content\"], end=\"\") elif response_data[\"type\"] == \"done\": # Response complete break asyncio.run(chat_with_agent()) . ",
    "url": "/muxi/reference/examples#communication-interfaces",
    
    "relUrl": "/reference/examples#communication-interfaces"
  },"80": {
    "doc": "Examples Library",
    "title": "CLI Applications",
    "content": "Interactive CLI . from muxi.cli import cli if __name__ == \"__main__\": # Start the CLI with interactive mode cli() . Programmatic CLI . from muxi.cli.commands import chat_command if __name__ == \"__main__\": # Send a message and print the response response = chat_command( message=\"What is the capital of France?\", agent=\"assistant\", user_id=\"user123\" ) print(response) . ",
    "url": "/muxi/reference/examples#cli-applications",
    
    "relUrl": "/reference/examples#cli-applications"
  },"81": {
    "doc": "Examples Library",
    "title": "Advanced Examples",
    "content": "Streaming Responses . from muxi.core.agent import Agent from muxi.core.models.openai import OpenAIModel # Create an agent agent = Agent( name=\"assistant\", model=OpenAIModel(\"gpt-4o\"), system_message=\"You are a helpful assistant.\" ) # Stream response chunks for chunk in agent.chat_stream(\"Tell me a short story about a robot.\"): print(chunk, end=\"\", flush=True) print() # Final newline . Custom Tools . from muxi.core.agent import Agent from muxi.core.models.openai import OpenAIModel from muxi.core.tools import BaseTool # Define a custom tool class CalculatorTool(BaseTool): name = \"calculator\" description = \"Perform mathematical calculations\" def execute(self, expression: str) -&gt; str: try: result = eval(expression) return str(result) except Exception as e: return f\"Error: {str(e)}\" # Create an agent with the custom tool agent = Agent( name=\"math_assistant\", model=OpenAIModel(\"gpt-4o\"), system_message=\"You are a helpful math assistant.\", tools=[CalculatorTool()] ) # Agent can use the calculator tool response = agent.chat(\"What is 123 * 456?\") print(response) # Will include correct calculation . Fine-Tuned Models . from muxi.core.agent import Agent from muxi.core.models.openai import OpenAIModel # Create an agent with a fine-tuned model agent = Agent( name=\"specialized_assistant\", model=OpenAIModel( model=\"ft:gpt-3.5-turbo-0613:my-org:my-custom-model:1234\", api_key=\"your-openai-api-key\" ), system_message=\"You are a specialized assistant.\" ) # Chat with the agent response = agent.chat(\"Can you help me with my query?\") print(response) . ",
    "url": "/muxi/reference/examples#advanced-examples",
    
    "relUrl": "/reference/examples#advanced-examples"
  },"82": {
    "doc": "Examples Library",
    "title": "Complete Applications",
    "content": "Q&amp;A System with Web Search . from muxi import muxi from muxi.core.mcp import MCPHandler # Initialize MUXI app app = muxi() # Create a web search MCP handler web_search_mcp = MCPHandler( name=\"web_search\", url=\"http://localhost:5002\", api_key=\"your-search-api-key\" ) # Create a research agent with web search capability app.add_agent( name=\"researcher\", system_message=\"\"\"You are a research assistant that can search the web for information. Always use the web_search tool when asked about current events or facts you're uncertain about.\"\"\", model=\"gpt-4o\", mcp_handlers=[web_search_mcp] ) # Start the CLI print(\"Research Assistant (type 'exit' to quit)\") print(\"----------------------------------------\") while True: query = input(\"\\nQuestion: \") if query.lower() == \"exit\": break response = app.chat(query, agent_name=\"researcher\") print(f\"\\nAnswer: {response}\") . Customer Support Bot . from muxi import muxi from muxi.core.memory.memobase import Memobase # Initialize MUXI app app = muxi() # Create multi-user memory memobase = Memobase( connection_string=\"postgresql://user:pass@localhost/db\" ) # Create a customer support agent app.add_agent( name=\"support\", system_message=\"\"\"You are a customer support agent for Acme Corp. Be polite, helpful, and concise in your responses. Reference customer information when available.\"\"\", model=\"gpt-4o\", long_term_memory=memobase ) # Add company knowledge base app.add_domain_knowledge_from_file(\"company_faq.txt\") app.add_domain_knowledge_from_file(\"product_information.txt\") app.add_domain_knowledge_from_file(\"return_policy.txt\") # Start server app.run(host=\"0.0.0.0\", port=5050) . ",
    "url": "/muxi/reference/examples#complete-applications",
    
    "relUrl": "/reference/examples#complete-applications"
  },"83": {
    "doc": "Examples Library",
    "title": "Related Topics",
    "content": ". | Simple Agents - Learn more about creating basic agents | Multi-Agent Systems - Explore multi-agent orchestration | Adding Memory - Understand memory systems in depth | Using MCP Servers - Connect agents to external services | . ",
    "url": "/muxi/reference/examples#related-topics",
    
    "relUrl": "/reference/examples#related-topics"
  },"84": {
    "doc": "Interfaces & Clients",
    "title": "Interfaces &amp; Clients",
    "content": "The Interfaces &amp; Clients section covers the different ways to interact with your MUXI agents, from command-line interfaces to web dashboards and WebSocket connections. ",
    "url": "/muxi/clients#interfaces--clients",
    
    "relUrl": "/clients#interfaces--clients"
  },"85": {
    "doc": "Interfaces & Clients",
    "title": "About This Section",
    "content": "MUXI provides multiple interfaces for interacting with your agents, allowing you to choose the best approach for your specific use case. This section explores the different client options, from simple command-line tools to sophisticated web dashboards and real-time WebSocket connections. ",
    "url": "/muxi/clients#about-this-section",
    
    "relUrl": "/clients#about-this-section"
  },"86": {
    "doc": "Interfaces & Clients",
    "title": "What’s In This Section",
    "content": ". | Command-Line Interface - Interact with agents through the terminal | Server Deployment - Deploy MUXI as a server for API access | Web Dashboard - Use the visual web interface | WebSocket Communication - Implement real-time, streaming communication | . ",
    "url": "/muxi/clients#whats-in-this-section",
    
    "relUrl": "/clients#whats-in-this-section"
  },"87": {
    "doc": "Interfaces & Clients",
    "title": "Prerequisites",
    "content": "Before diving into this section, we recommend: . | Completing the Introduction section | Understanding how to build basic agents | Having MUXI installed (see Installation) | . ",
    "url": "/muxi/clients#prerequisites",
    
    "relUrl": "/clients#prerequisites"
  },"88": {
    "doc": "Interfaces & Clients",
    "title": "Getting Started",
    "content": "If you’re looking for a simple way to interact with your agents, start with the Command-Line Interface guide. For deploying MUXI as a service, check out the Server Deployment guide. ",
    "url": "/muxi/clients#getting-started",
    
    "relUrl": "/clients#getting-started"
  },"89": {
    "doc": "Interfaces & Clients",
    "title": "Next Steps After Interfaces &amp; Clients",
    "content": "Once you’re familiar with the different interfaces, you might want to: . | Explore the Technical Deep Dives for a deeper understanding of the framework | Learn about extending agent capabilities with MCP servers | Contribute to the project by following the Development guides | . ",
    "url": "/muxi/clients#next-steps-after-interfaces--clients",
    
    "relUrl": "/clients#next-steps-after-interfaces--clients"
  },"90": {
    "doc": "Interfaces & Clients",
    "title": "Interfaces & Clients",
    "content": " ",
    "url": "/muxi/clients",
    
    "relUrl": "/clients"
  },"91": {
    "doc": "Introduction",
    "title": "Introduction to MUXI",
    "content": "Welcome to the MUXI Framework, a powerful, modular system for building AI agents with memory persistence, MCP server integration, and real-time communication capabilities. ",
    "url": "/muxi/intro#introduction-to-muxi",
    
    "relUrl": "/intro#introduction-to-muxi"
  },"92": {
    "doc": "Introduction",
    "title": "About This Section",
    "content": "The Introduction section provides a comprehensive overview of the MUXI Framework, its core concepts, architecture, and how to get started. Whether you’re a newcomer looking to build your first agent or an experienced developer evaluating MUXI for your next project, this section will give you the foundation you need. ",
    "url": "/muxi/intro#about-this-section",
    
    "relUrl": "/intro#about-this-section"
  },"93": {
    "doc": "Introduction",
    "title": "What’s In This Section",
    "content": ". | Overview &amp; Key Concepts - Learn about the main components of MUXI and how they work together | Why MUXI? - Discover the advantages of MUXI compared to other frameworks | Quick Start Guide - Get up and running with MUXI in minutes | Architecture - Understand the architectural principles behind MUXI | Installation - Detailed instructions for installing and configuring MUXI | . ",
    "url": "/muxi/intro#whats-in-this-section",
    
    "relUrl": "/intro#whats-in-this-section"
  },"94": {
    "doc": "Introduction",
    "title": "Getting Started",
    "content": "If you’re new to MUXI, we recommend starting with the Overview to understand the core concepts, followed by the Quick Start Guide to build your first application. If you’re evaluating MUXI against other frameworks, check out Why MUXI? to understand its unique advantages. For a deeper dive into how MUXI works, explore the Architecture page. When you’re ready to install, the Installation guide will walk you through the process step by step. ",
    "url": "/muxi/intro#getting-started",
    
    "relUrl": "/intro#getting-started"
  },"95": {
    "doc": "Introduction",
    "title": "Next Steps After Introduction",
    "content": "Once you’ve completed this section, you’ll be ready to explore: . | Building Agents - Learn to create and configure agents for different purposes | Extending Capabilities - Enhance your agents with MCP servers and context knowledge | Interfaces &amp; Clients - Discover the different ways to interact with MUXI | . Let’s get started with the Overview &amp; Key Concepts! . ",
    "url": "/muxi/intro#next-steps-after-introduction",
    
    "relUrl": "/intro#next-steps-after-introduction"
  },"96": {
    "doc": "Introduction",
    "title": "Introduction",
    "content": " ",
    "url": "/muxi/intro",
    
    "relUrl": "/intro"
  },"97": {
    "doc": "Reference",
    "title": "Reference",
    "content": "The Reference section provides detailed technical specifications, API documentation, and example code for the MUXI Framework. ",
    "url": "/muxi/reference",
    
    "relUrl": "/reference"
  },"98": {
    "doc": "Reference",
    "title": "About This Section",
    "content": "This section serves as a comprehensive reference for developers working with MUXI. Here you’ll find detailed API documentation, configuration options, package structure information, and practical examples to help you build advanced applications. ",
    "url": "/muxi/reference#about-this-section",
    
    "relUrl": "/reference#about-this-section"
  },"99": {
    "doc": "Reference",
    "title": "What’s In This Section",
    "content": ". | API Documentation - Detailed documentation of all API endpoints | Configuration Options - Complete reference for configuration parameters | Package Structure - Detailed explanation of the package organization | Examples Library - Practical code examples for common use cases | Framework Comparisons - How MUXI compares to other AI frameworks | . ",
    "url": "/muxi/reference#whats-in-this-section",
    
    "relUrl": "/reference#whats-in-this-section"
  },"100": {
    "doc": "Reference",
    "title": "When to Use This Section",
    "content": "Reference this section when you need: . | Specific details about API endpoints and parameters | Complete list of configuration options | Information about the codebase organization | Practical code examples for specific tasks | Comparison with other frameworks for evaluation | . ",
    "url": "/muxi/reference#when-to-use-this-section",
    
    "relUrl": "/reference#when-to-use-this-section"
  },"101": {
    "doc": "Reference",
    "title": "How to Use This Section",
    "content": "Unlike the tutorial-style sections of the documentation, the Reference section is designed for looking up specific information. Use the navigation to find the topic you’re interested in, or use the search functionality to find specific terms or parameters. The API Documentation and Configuration Options pages are particularly useful when you need to check the exact parameters for a function or configuration file. The Examples Library provides practical code snippets that you can adapt for your own projects. ",
    "url": "/muxi/reference#how-to-use-this-section",
    
    "relUrl": "/reference#how-to-use-this-section"
  },"102": {
    "doc": "Reference",
    "title": "Related Topics",
    "content": "For more detailed explanations of concepts and components, refer to the Technical Deep Dives section. For step-by-step guides on common tasks, see the Building Agents and Extending Capabilities sections. ",
    "url": "/muxi/reference#related-topics",
    
    "relUrl": "/reference#related-topics"
  },"103": {
    "doc": "MCP System",
    "title": "MCP System",
    "content": "This section provides technical deep dives into the Model Context Protocol (MCP) system of the MUXI Framework. ",
    "url": "/muxi/technical/mcp",
    
    "relUrl": "/technical/mcp"
  },"104": {
    "doc": "MCP System",
    "title": "About This Section",
    "content": "The Model Context Protocol (MCP) is the standardized communication layer that enables agents to access external services and functionality. This section explores the technical details of the MCP system, how to create MCP servers, and best practices for security. ",
    "url": "/muxi/technical/mcp#about-this-section",
    
    "relUrl": "/technical/mcp#about-this-section"
  },"105": {
    "doc": "MCP System",
    "title": "What’s In This Section",
    "content": ". | MCP Fundamentals - The core concepts and architecture of the MCP system | Creating MCP Servers - Technical details for building custom MCP servers | Security Considerations - Best practices for secure MCP server implementation | . ",
    "url": "/muxi/technical/mcp#whats-in-this-section",
    
    "relUrl": "/technical/mcp#whats-in-this-section"
  },"106": {
    "doc": "MCP System",
    "title": "Prerequisites",
    "content": "Before diving into this section, we recommend: . | Understanding the basics of using MCP servers | Familiarity with RESTful API design | Knowledge of web server frameworks like FastAPI or Flask | Understanding of JSON request/response formats | . ",
    "url": "/muxi/technical/mcp#prerequisites",
    
    "relUrl": "/technical/mcp#prerequisites"
  },"107": {
    "doc": "MCP System",
    "title": "Implementation Details",
    "content": "The MCP system includes several key technical features: . | Standardized request/response format | Function calling and parameter serialization | Result parsing and error handling | Authentication and security mechanisms | Service discovery and registration | . ",
    "url": "/muxi/technical/mcp#implementation-details",
    
    "relUrl": "/technical/mcp#implementation-details"
  },"108": {
    "doc": "MCP System",
    "title": "Related Topics",
    "content": "These topics are closely related to the MCP system: . | Agent Fundamentals - How agents use MCP servers | Creating Custom MCP Servers - A practical guide to creating MCP servers | WebSocket Interface - Real-time streaming with MCP servers | . ",
    "url": "/muxi/technical/mcp#related-topics",
    
    "relUrl": "/technical/mcp#related-topics"
  },"109": {
    "doc": "Memory System",
    "title": "Memory System",
    "content": "This section provides technical deep dives into the memory architecture of the MUXI Framework. ",
    "url": "/muxi/technical/memory",
    
    "relUrl": "/technical/memory"
  },"110": {
    "doc": "Memory System",
    "title": "About This Section",
    "content": "The memory system is a key component that enables agents to maintain context over time and store important information. This section explores the different memory subsystems, their internal implementations, and how they work together to provide a comprehensive memory solution. ",
    "url": "/muxi/technical/memory#about-this-section",
    
    "relUrl": "/technical/memory#about-this-section"
  },"111": {
    "doc": "Memory System",
    "title": "What’s In This Section",
    "content": ". | Buffer Memory - Short-term contextual memory for conversations | Long-Term Memory - Persistent storage of important information | Multi-User Memory (Memobase) - Partitioning memory by user | Domain Knowledge - Structured knowledge integration | . ",
    "url": "/muxi/technical/memory#whats-in-this-section",
    
    "relUrl": "/technical/memory#whats-in-this-section"
  },"112": {
    "doc": "Memory System",
    "title": "Prerequisites",
    "content": "Before diving into this section, we recommend: . | Understanding the basics of agent memory | Familiarity with vector embeddings and vector databases | Knowledge of PostgreSQL and the pgvector extension | Understanding of semantic search concepts | . ",
    "url": "/muxi/technical/memory#prerequisites",
    
    "relUrl": "/technical/memory#prerequisites"
  },"113": {
    "doc": "Memory System",
    "title": "Implementation Details",
    "content": "MUXI’s memory system includes several key technical features: . | Vector embeddings for semantic search | Automatic text chunking and processing | PostgreSQL with pgvector for long-term storage | Efficient buffer management with automatic summarization | Memory partitioning for multi-user scenarios | . ",
    "url": "/muxi/technical/memory#implementation-details",
    
    "relUrl": "/technical/memory#implementation-details"
  },"114": {
    "doc": "Memory System",
    "title": "Related Topics",
    "content": "These topics are closely related to the memory system: . | Agent Fundamentals - How agents use memory | MCP Fundamentals - How MCP servers can access memory | REST API - How to interact with memory through the API | . ",
    "url": "/muxi/technical/memory#related-topics",
    
    "relUrl": "/technical/memory#related-topics"
  },"115": {
    "doc": "Communication",
    "title": "Communication",
    "content": "This section provides technical deep dives into the communication systems of the MUXI Framework. ",
    "url": "/muxi/technical/communication",
    
    "relUrl": "/technical/communication"
  },"116": {
    "doc": "Communication",
    "title": "About This Section",
    "content": "The communication layer is how users and applications interact with the MUXI Framework. This section explores the technical details of the various communication interfaces, including the REST API, WebSocket interface, command-line interface, and web UI. ",
    "url": "/muxi/technical/communication#about-this-section",
    
    "relUrl": "/technical/communication#about-this-section"
  },"117": {
    "doc": "Communication",
    "title": "What’s In This Section",
    "content": ". | REST API - The HTTP API for interacting with MUXI | WebSocket Interface - Real-time, bi-directional communication | CLI - Command-line interface implementation details | Web UI - Web dashboard architecture and implementation | . ",
    "url": "/muxi/technical/communication#whats-in-this-section",
    
    "relUrl": "/technical/communication#whats-in-this-section"
  },"118": {
    "doc": "Communication",
    "title": "Prerequisites",
    "content": "Before diving into this section, we recommend: . | Understanding the basics of interfaces and clients | Familiarity with HTTP, REST, and WebSocket protocols | Knowledge of authentication and security practices | Experience with client-server architectures | . ",
    "url": "/muxi/technical/communication#prerequisites",
    
    "relUrl": "/technical/communication#prerequisites"
  },"119": {
    "doc": "Communication",
    "title": "Implementation Details",
    "content": "The communication system includes several key technical features: . | JSON-based API for standardized communication | WebSocket streaming for real-time updates | Server-Sent Events (SSE) for one-way streaming | Authentication and authorization mechanisms | Cross-Origin Resource Sharing (CORS) support | Error handling and status codes | . ",
    "url": "/muxi/technical/communication#implementation-details",
    
    "relUrl": "/technical/communication#implementation-details"
  },"120": {
    "doc": "Communication",
    "title": "Related Topics",
    "content": "These topics are closely related to the communication system: . | Server Deployment - How to deploy the server | MCP Fundamentals - How MCP servers communicate | Agent Fundamentals - How agents process incoming messages | . ",
    "url": "/muxi/technical/communication#related-topics",
    
    "relUrl": "/technical/communication#related-topics"
  },"121": {
    "doc": "Agents & Models",
    "title": "Agents &amp; Models",
    "content": "This section provides technical deep dives into the agent architecture and language model integration within the MUXI Framework. ",
    "url": "/muxi/technical/agents#agents--models",
    
    "relUrl": "/technical/agents#agents--models"
  },"122": {
    "doc": "Agents & Models",
    "title": "About This Section",
    "content": "The Agents &amp; Models subsystem is the core of the MUXI Framework. This section explores the technical details of agent implementation, language model integration, multi-modal support, and orchestration mechanics. ",
    "url": "/muxi/technical/agents#about-this-section",
    
    "relUrl": "/technical/agents#about-this-section"
  },"123": {
    "doc": "Agents & Models",
    "title": "What’s In This Section",
    "content": ". | Agent Fundamentals - Core agent architecture and implementation | Language Models - Model integration and provider interfaces | Multi-Modal Support - Handling images, audio, and other modalities | Orchestration - Multi-agent coordination and message routing | . ",
    "url": "/muxi/technical/agents#whats-in-this-section",
    
    "relUrl": "/technical/agents#whats-in-this-section"
  },"124": {
    "doc": "Agents & Models",
    "title": "Prerequisites",
    "content": "Before diving into this section, we recommend: . | Understanding the basics of building agents | Familiarity with language models like GPT-4, Claude, etc. | Basic knowledge of Python programming | Understanding of prompt engineering concepts | . ",
    "url": "/muxi/technical/agents#prerequisites",
    
    "relUrl": "/technical/agents#prerequisites"
  },"125": {
    "doc": "Agents & Models",
    "title": "Implementation Details",
    "content": "The agent system includes several key technical features: . | Agent lifecycle management | Message handling and processing | Memory integration | Tool and function calling | Model provider abstraction | Multi-agent orchestration | . ",
    "url": "/muxi/technical/agents#implementation-details",
    
    "relUrl": "/technical/agents#implementation-details"
  },"126": {
    "doc": "Agents & Models",
    "title": "Related Topics",
    "content": "These topics are closely related to the agent system: . | MCP Fundamentals - How agents use external services | Buffer Memory - Short-term agent memory | REST API - API endpoints for agent management | . ",
    "url": "/muxi/technical/agents#related-topics",
    
    "relUrl": "/technical/agents#related-topics"
  },"127": {
    "doc": "Agents & Models",
    "title": "Agents & Models",
    "content": " ",
    "url": "/muxi/technical/agents",
    
    "relUrl": "/technical/agents"
  },"128": {
    "doc": "Technical Deep Dives",
    "title": "Technical Deep Dives",
    "content": "The Technical Deep Dives section provides detailed, technical explanations of the MUXI Framework’s components and subsystems. ",
    "url": "/muxi/technical",
    
    "relUrl": "/technical"
  },"129": {
    "doc": "Technical Deep Dives",
    "title": "About This Section",
    "content": "This section is intended for developers who want to understand the internal workings of MUXI or who want to extend or modify the framework itself. Here you’ll find in-depth explanations of the core components, detailed architecture diagrams, and technical discussions of implementation choices. ",
    "url": "/muxi/technical#about-this-section",
    
    "relUrl": "/technical#about-this-section"
  },"130": {
    "doc": "Technical Deep Dives",
    "title": "What’s In This Section",
    "content": ". | Agents &amp; Models . | Agent Fundamentals | Language Models | Multi-Modal Support | Orchestration | . | Memory System . | Buffer Memory | Long-Term Memory | Multi-User Memory (Memobase) | Domain Knowledge | . | MCP System . | MCP Fundamentals | Creating MCP Servers | Security Considerations | . | Communication . | REST API | WebSocket Interface | CLI | Web UI | . | . ",
    "url": "/muxi/technical#whats-in-this-section",
    
    "relUrl": "/technical#whats-in-this-section"
  },"131": {
    "doc": "Technical Deep Dives",
    "title": "Prerequisites",
    "content": "Before diving into this section, we recommend: . | Completing the Introduction section | Having experience building and using MUXI agents | Familiarity with advanced Python concepts | Understanding of LLM and AI agent architectures | . ",
    "url": "/muxi/technical#prerequisites",
    
    "relUrl": "/technical#prerequisites"
  },"132": {
    "doc": "Technical Deep Dives",
    "title": "Getting Started",
    "content": "The subsections can be read in any order depending on your interests. If you’re looking to understand how agents work internally, start with Agent Fundamentals. If you’re interested in memory systems, check out Buffer Memory first. ",
    "url": "/muxi/technical#getting-started",
    
    "relUrl": "/technical#getting-started"
  },"133": {
    "doc": "Technical Deep Dives",
    "title": "Next Steps After Technical Deep Dives",
    "content": "After exploring the technical details, you might want to: . | Contribute to the project by following the Development guides | Reference the API Documentation for detailed interface specifications | Explore advanced examples that demonstrate sophisticated use cases | . ",
    "url": "/muxi/technical#next-steps-after-technical-deep-dives",
    
    "relUrl": "/technical#next-steps-after-technical-deep-dives"
  },"134": {
    "doc": "Development",
    "title": "Development",
    "content": "Welcome to the development section of the MUXI Framework documentation. This section is designed for contributors and developers who want to understand how the framework is built and how to contribute to its development. ",
    "url": "/muxi/development",
    
    "relUrl": "/development"
  },"135": {
    "doc": "Development",
    "title": "Architecture Migration",
    "content": "The MUXI Framework has successfully completed its migration to a modular, package-based architecture. This transition involved: . | Reorganizing from a monolithic structure to a modular, package-based architecture | Migrating imports from src.* to muxi.core.*, muxi.cli.*, etc. | Creating independent packages that can be installed separately | Establishing clear boundaries between subsystems | . The modular design enhances maintainability and facilitates future development by: . | Allowing independent versioning of components | Providing clearer boundaries between subsystems | Enabling more focused testing | Supporting separate deployments when needed | . ",
    "url": "/muxi/development#architecture-migration",
    
    "relUrl": "/development#architecture-migration"
  },"136": {
    "doc": "Development",
    "title": "Contributing",
    "content": "We welcome contributions to the MUXI Framework! Whether you’re fixing bugs, adding features, or improving documentation, your help is appreciated. Before contributing, please read our Contributing Guidelines to understand our development process, coding standards, and how to submit pull requests. ",
    "url": "/muxi/development#contributing",
    
    "relUrl": "/development#contributing"
  },"137": {
    "doc": "Development",
    "title": "Codebase Organization",
    "content": "The MUXI Framework is organized into several packages: . | core: Core functionality including models, memory, tools, and orchestration | cli: Command-line interface for using MUXI | server: REST API and WebSocket server | web: Web interface for interacting with MUXI | clients: Client libraries for various languages | . For more details, see our Codebase Organization page. ",
    "url": "/muxi/development#codebase-organization",
    
    "relUrl": "/development#codebase-organization"
  },"138": {
    "doc": "Development",
    "title": "Testing",
    "content": "Testing is crucial for maintaining the stability and reliability of the MUXI Framework. We use a combination of unit tests, integration tests, and end-to-end tests. For more information on our testing approach, see our Testing Strategies page. ",
    "url": "/muxi/development#testing",
    
    "relUrl": "/development#testing"
  },"139": {
    "doc": "Development",
    "title": "Changelog",
    "content": "For a detailed list of changes made to the MUXI Framework, see our Changelog. ",
    "url": "/muxi/development#changelog",
    
    "relUrl": "/development#changelog"
  },"140": {
    "doc": "Development",
    "title": "About This Section",
    "content": "The Development section provides guidelines, best practices, and resources for developers who want to contribute to MUXI. It covers everything from setting up a development environment to understanding the codebase structure and contributing code. ",
    "url": "/muxi/development#about-this-section",
    
    "relUrl": "/development#about-this-section"
  },"141": {
    "doc": "Development",
    "title": "What’s In This Section",
    "content": ". | Contributing Guidelines - How to contribute to the project | Testing Strategies - Testing approach and best practices | Codebase Organization - Detailed insight into the codebase structure | Changelog - Record of changes and versions | . ",
    "url": "/muxi/development#whats-in-this-section",
    
    "relUrl": "/development#whats-in-this-section"
  },"142": {
    "doc": "Development",
    "title": "Prerequisites",
    "content": "Before diving into development, it’s recommended that you: . | Have a good understanding of the MUXI Framework’s core concepts | Be familiar with Python, FastAPI, and modern web development | Understand basic Git workflow and GitHub collaboration | Have experience with testing frameworks like pytest | . ",
    "url": "/muxi/development#prerequisites",
    
    "relUrl": "/development#prerequisites"
  },"143": {
    "doc": "Development",
    "title": "Getting Started with Development",
    "content": ". | Set up your development environment following the Contributing Guidelines | Understand the Codebase Organization | Learn the Testing Strategies to ensure your contributions maintain quality | Check the Changelog to understand recent changes | . ",
    "url": "/muxi/development#getting-started-with-development",
    
    "relUrl": "/development#getting-started-with-development"
  },"144": {
    "doc": "Development",
    "title": "Key Development Principles",
    "content": "MUXI development follows these core principles: . | Modularity: Components should be loosely coupled and highly cohesive | Testability: All code should be testable and tested | Documentation: Code should be well-documented with docstrings and comments | Backward Compatibility: Breaking changes should be minimized and clearly documented | Performance: Code should be efficient and scalable | . ",
    "url": "/muxi/development#key-development-principles",
    
    "relUrl": "/development#key-development-principles"
  },"145": {
    "doc": "Development",
    "title": "Related Resources",
    "content": "For API documentation and technical details, refer to the Reference section. For deep dives into the technical architecture, see the Technical Deep Dives section. ",
    "url": "/muxi/development#related-resources",
    
    "relUrl": "/development#related-resources"
  },"146": {
    "doc": "Extending Capabilities",
    "title": "Extending Capabilities",
    "content": "The Extending Capabilities section covers ways to enhance your agents with external services, context knowledge, and advanced features. By connecting agents to external servers, integrating specialized knowledge, and supporting multi-modal interactions, you can create more powerful and versatile agents. ",
    "url": "/muxi/extend",
    
    "relUrl": "/extend"
  },"147": {
    "doc": "Extending Capabilities",
    "title": "About This Section",
    "content": "While basic agents are powerful on their own, MUXI really shines when you extend their capabilities. This section explores how to connect agents to external services through MCP servers, integrate domain-specific knowledge, and support multi-modal interactions. ",
    "url": "/muxi/extend#about-this-section",
    
    "relUrl": "/extend#about-this-section"
  },"148": {
    "doc": "Extending Capabilities",
    "title": "What’s In This Section",
    "content": ". | Using MCP Servers - Connect your agents to existing MCP servers | Domain Knowledge Integration - Add specialized knowledge to your agents | Multi-Modal Support - Work with images, audio, and other non-text formats | . ",
    "url": "/muxi/extend#whats-in-this-section",
    
    "relUrl": "/extend#whats-in-this-section"
  },"149": {
    "doc": "Extending Capabilities",
    "title": "Prerequisites",
    "content": "Before diving into this section, we recommend: . | Completing the Introduction section | Understanding how to build basic agents | Familiarity with the MCP system (for creating custom servers) | . ",
    "url": "/muxi/extend#prerequisites",
    
    "relUrl": "/extend#prerequisites"
  },"150": {
    "doc": "Extending Capabilities",
    "title": "Next Steps After Extending Capabilities",
    "content": "Once you’ve extended your agents’ capabilities, you might want to: . | Build multi-agent systems that combine different capabilities | Explore client interfaces to interact with your enhanced agents | Learn about advanced memory techniques to improve contextual understanding | . ",
    "url": "/muxi/extend#next-steps-after-extending-capabilities",
    
    "relUrl": "/extend#next-steps-after-extending-capabilities"
  },"151": {
    "doc": "Building Agents",
    "title": "Building Agents with MUXI",
    "content": "This section explains how to build AI agents using the MUXI Framework. Agents are the fundamental building blocks of MUXI applications, providing natural language capabilities powered by large language models. ",
    "url": "/muxi/agents#building-agents-with-muxi",
    
    "relUrl": "/agents#building-agents-with-muxi"
  },"152": {
    "doc": "Building Agents",
    "title": "What is an Agent?",
    "content": "In MUXI, an agent is an AI entity that: . | Is powered by a language model (like OpenAI’s GPT-4, Anthropic’s Claude, etc.) | Can understand and generate natural language | Has optional memory capabilities to remember conversations | Can be configured with a specific personality and knowledge domain | Can be customized to suit different tasks | . ",
    "url": "/muxi/agents#what-is-an-agent",
    
    "relUrl": "/agents#what-is-an-agent"
  },"153": {
    "doc": "Building Agents",
    "title": "Creating Your First Agent",
    "content": "Declarative way . # configs/assistant.yaml --- agent_id: assistant description: \"A helpful general-purpose assistant that can answer questions and provide information.\" model: provider: openai api_key: \"${OPENAI_API_KEY}\" model: gpt-4o system_message: \"You are a helpful AI assistant that provides clear and accurate information.\" . # app.py from muxi import muxi from dotenv import load_dotenv # Load environment variables load_dotenv() # Initialize MUXI app = muxi() # Add an agent from a configuration file app.add_agent(\"assistant\", \"configs/assistant.yaml\") # Chat with the agent response = await app.chat(\"Hello, who are you?\") print(response) . Programmatic way . import os from muxi.core.orchestrator import Orchestrator from muxi.core.models.openai import OpenAIModel # Initialize components orchestrator = Orchestrator() # Create a model model = OpenAIModel( api_key=os.getenv(\"OPENAI_API_KEY\"), model=\"gpt-4o\" ) # Create an agent orchestrator.create_agent( agent_id=\"assistant\", description=\"A helpful general-purpose assistant that can answer questions and provide information.\", model=model, system_message=\"You are a helpful AI assistant that provides clear and accurate information.\" ) # Chat with the agent response = orchestrator.chat(\"assistant\", \"Hello, what can you help me with?\") print(response) . ",
    "url": "/muxi/agents#creating-your-first-agent",
    
    "relUrl": "/agents#creating-your-first-agent"
  },"154": {
    "doc": "Building Agents",
    "title": "Agent Capabilities",
    "content": "MUXI agents support a wide range of capabilities: . | Natural Language Conversation: Engage in human-like dialogue | Memory Systems: Remember previous interactions and important information | Multi-Modal Inputs: Process text, images, and other data types | Personality Customization: Tailor the agent’s tone, style, and behavior | Domain Knowledge: Specialize in particular topics or knowledge areas | Multi-Agent Collaboration: Work together with other agents for complex tasks | . ",
    "url": "/muxi/agents#agent-capabilities",
    
    "relUrl": "/agents#agent-capabilities"
  },"155": {
    "doc": "Building Agents",
    "title": "Agent Configuration Options",
    "content": "Agents can be configured with various options: . | Model Selection: Choose from multiple LLM providers and models | System Messages: Define the agent’s role and behavior | Memory Settings: Configure short-term and long-term memory | Temperature Control: Adjust creativity vs. determinism | Response Length: Control maximum output length | Domain-Specific Knowledge: Add specialized information | . ",
    "url": "/muxi/agents#agent-configuration-options",
    
    "relUrl": "/agents#agent-configuration-options"
  },"156": {
    "doc": "Building Agents",
    "title": "Guides in this Section",
    "content": "Each guide focuses on a specific aspect of building agents: . | Simple Agent: Create a basic agent and understand fundamental concepts | Agent Configuration: Learn about all available configuration options | Adding Memory: Enhance agents with memory capabilities | Multi-Agent Systems: Build systems with multiple collaborating agents | . ",
    "url": "/muxi/agents#guides-in-this-section",
    
    "relUrl": "/agents#guides-in-this-section"
  },"157": {
    "doc": "Building Agents",
    "title": "Example: Creating a Specialized Agent",
    "content": "Declarative way . configs/science_tutor.json . { \"agent_id\": \"science_tutor\", \"description\": \"A specialized science tutor that can explain concepts clearly and answer related questions.\", \"model\": { \"provider\": \"openai\", \"api_key\": \"${OPENAI_API_KEY}\", \"model\": \"gpt-4o\", \"temperature\": 0.3, \"max_tokens\": 1000 }, \"system_message\": \"You are a helpful science tutor. Your goal is to explain scientific concepts clearly and accurately, using examples and analogies when appropriate. You should be patient and encouraging, and adapt your explanations to different levels of understanding.\" } . # app.py from muxi import muxi from dotenv import load_dotenv # Load environment variables load_dotenv() # Initialize MUXI app = muxi() # Add an agent from a configuration file app.add_agent(\"science_tutor\", \"configs/science_tutor.json\") # Chat with the agent response = await app.chat(\"Hello, who are you?\") print(response) . Programmatic way . import os from muxi.core.orchestrator import Orchestrator from muxi.core.models.openai import OpenAIModel # Initialize components orchestrator = Orchestrator() # Create a model model = OpenAIModel( api_key=os.getenv(\"OPENAI_API_KEY\"), model=\"gpt-4o\", temperature=0.3, max_tokens=1000 ) # Create a specialized science tutor agent orchestrator.create_agent( agent_id=\"science_tutor\", description=\"A specialized science tutor that can explain concepts clearly and answer related questions.\", model=model, system_message=\"You are a helpful science tutor. Your goal is to explain scientific concepts clearly and accurately, using examples and analogies when appropriate. You should be patient and encouraging, and adapt your explanations to different levels of understanding.\" ) # Chat with the tutor response = orchestrator.chat(\"science_tutor\", \"Can you explain photosynthesis in simple terms?\") print(response) . Ready to build your own agent? Start with the Simple Agent guide. ",
    "url": "/muxi/agents#example-creating-a-specialized-agent",
    
    "relUrl": "/agents#example-creating-a-specialized-agent"
  },"158": {
    "doc": "Building Agents",
    "title": "Building Agents",
    "content": " ",
    "url": "/muxi/agents",
    
    "relUrl": "/agents"
  },"159": {
    "doc": "Home",
    "title": "MUXI Framework Documentation",
    "content": "Welcome to the official documentation for MUXI, an extensible framework for building AI agents with real-time communication capabilities, memory persistence, and MCP server integration. This project is a work in progress and is not yet ready for production use. The framework is actively being developed with new features being added regularly. Please refer to the roadmap for information about the current state of the project and where it’s headed. ",
    "url": "/muxi/#muxi-framework-documentation",
    
    "relUrl": "/#muxi-framework-documentation"
  },"160": {
    "doc": "Home",
    "title": "Documentation Structure",
    "content": "Our documentation is organized to serve both newcomers and experienced developers: . Introduction . Start here to understand the MUXI Framework, its core concepts, and how to get started: . | Overview &amp; Key Concepts | Why MUXI? | Quick Start Guide | Architecture | Installation | . Building Agents . Learn how to create and configure agents for different purposes: . | Simple Agents | Multi-Agent Systems | Adding Memory | Agent Configuration | . Extending Capabilities . Enhance your agents with external services and context knowledge: . | Using MCP Servers | Creating Custom MCP Servers | Context Knowledge Integration | Multi-Modal Support | . Interfaces &amp; Clients . Discover the different ways to interact with MUXI: . | Command-Line Interface | Server Deployment | Web Dashboard | WebSocket Communication | . Technical Deep Dives . Detailed information for developers who want to understand the framework at a deeper level: . | Agents &amp; Models | Memory System | MCP System | Communication | . Reference . Detailed reference material: . | API Documentation | Configuration Options | Package Structure | Examples Library | . Development . Information for contributors and developers: . | Contributing Guidelines | Testing Strategies | Codebase Organization | Changelog | . ",
    "url": "/muxi/#documentation-structure",
    
    "relUrl": "/#documentation-structure"
  },"161": {
    "doc": "Home",
    "title": "Key Features",
    "content": ". | Multi-Agent Orchestration: Create and manage multiple AI agents with different capabilities | Intelligent Message Routing: Automatically select the most appropriate agent based on message content | Model Context Protocol (MCP): Connect to external services via standardized MCP servers | Memory Systems: Short-term buffer memory and long-term persistent memory | Multi-User Support: Memobase provides user-specific memory partitioning | Context Knowledge: Store and retrieve structured information to personalize agent responses | Real-Time Communication: WebSocket support for streaming responses | Flexible Configuration: Define agents using YAML or JSON with minimal code | . ",
    "url": "/muxi/#key-features",
    
    "relUrl": "/#key-features"
  },"162": {
    "doc": "Home",
    "title": "Getting Started",
    "content": "The fastest way to get started with MUXI is to follow our Quick Start Guide. ",
    "url": "/muxi/#getting-started",
    
    "relUrl": "/#getting-started"
  },"163": {
    "doc": "Home",
    "title": "Community &amp; Support",
    "content": ". | GitHub Repository | Issue Tracker | . ",
    "url": "/muxi/#community--support",
    
    "relUrl": "/#community--support"
  },"164": {
    "doc": "Home",
    "title": "License",
    "content": "This project is licensed under a dual licensing model to balance open-source collaboration with sustainable business practices. During the development phase, the software is licensed under the Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 (CC BY-NC-ND 4.0) license. ",
    "url": "/muxi/#license",
    
    "relUrl": "/#license"
  },"165": {
    "doc": "Home",
    "title": "Home",
    "content": " ",
    "url": "/muxi/",
    
    "relUrl": "/"
  },"166": {
    "doc": "Installation",
    "title": "Installation",
    "content": " ",
    "url": "/muxi/intro/installation",
    
    "relUrl": "/intro/installation"
  },"167": {
    "doc": "Installation",
    "title": "What You’ll Learn",
    "content": ". | How to install MUXI using different methods | How to set up your development environment | How to configure MUXI with environment variables | Different installation options for various usage scenarios | . ",
    "url": "/muxi/intro/installation#what-youll-learn",
    
    "relUrl": "/intro/installation#what-youll-learn"
  },"168": {
    "doc": "Installation",
    "title": "Prerequisites",
    "content": ". | Python 3.10 or later | pip (Python package manager) | A basic understanding of Python environments (recommended) | . ",
    "url": "/muxi/intro/installation#prerequisites",
    
    "relUrl": "/intro/installation#prerequisites"
  },"169": {
    "doc": "Installation",
    "title": "Installation Options",
    "content": "MUXI provides several installation options depending on your needs. Standard Installation . For most users, the standard installation includes everything you need to get started: . pip install muxi . This installs the main muxi package, which includes: . | Core functionality (agents, memory, MCP) | Server components (API, WebSocket) | Command-line interface | . CLI Installation . If you only need the CLI functionality to interact with a remote server: . pip install muxi-cli . Web UI Installation . To use the web interface: . pip install muxi-web . Development Installation . For contributors or developers who want to modify the framework: . git clone https://github.com/yourusername/muxi-framework.git cd muxi-framework ./install_dev.sh . The development installation: . | Installs all packages in editable mode | Sets up pre-commit hooks | Prepares the development environment | . ",
    "url": "/muxi/intro/installation#installation-options",
    
    "relUrl": "/intro/installation#installation-options"
  },"170": {
    "doc": "Installation",
    "title": "Environment Setup",
    "content": "Environment Variables . Create a .env file in your project root with the following variables: . # Required for most functionality OPENAI_API_KEY=your-openai-api-key # Optional but recommended for persistence POSTGRES_DATABASE_URL=postgresql://user:password@localhost:5432/muxi # Optional for specific MCP servers WEATHER_API_KEY=your-weather-api-key SERPER_API_KEY=your-serper-api-key # Server configuration (optional) MUXI_HOST=0.0.0.0 MUXI_PORT=5050 MUXI_API_KEY=your-custom-api-key # Memory configuration (optional) MUXI_BUFFER_SIZE=10 MUXI_ENABLE_LONG_TERM=true . Loading Environment Variables . In your Python code: . from dotenv import load_dotenv # Load variables from .env file load_dotenv() # Now you can use MUXI from muxi import muxi app = muxi() . ",
    "url": "/muxi/intro/installation#environment-setup",
    
    "relUrl": "/intro/installation#environment-setup"
  },"171": {
    "doc": "Installation",
    "title": "Database Setup",
    "content": "For long-term memory functionality, MUXI requires a PostgreSQL database with the pgvector extension. Local PostgreSQL Setup . | Install PostgreSQL (version 14 or higher recommended) . | Install the pgvector extension: . | . # On Ubuntu/Debian sudo apt-get install postgresql-14-pgvector # On macOS with Homebrew brew install pgvector . | Create a database and enable the extension: | . CREATE DATABASE muxi; CREATE EXTENSION IF NOT EXISTS pgvector; . | Set the POSTGRES_DATABASE_URL environment variable: | . POSTGRES_DATABASE_URL=postgresql://username:password@localhost:5432/muxi . Using Docker . You can also use Docker to run PostgreSQL with pgvector: . docker run -d \\ --name muxi-postgres \\ -e POSTGRES_PASSWORD=password \\ -e POSTGRES_USER=user \\ -e POSTGRES_DB=muxi \\ -p 5432:5432 \\ pgvector/pgvector:pg14 . Then set your POSTGRES_DATABASE_URL: . POSTGRES_DATABASE_URL=postgresql://user:password@localhost:5432/muxi . ",
    "url": "/muxi/intro/installation#database-setup",
    
    "relUrl": "/intro/installation#database-setup"
  },"172": {
    "doc": "Installation",
    "title": "Verifying Installation",
    "content": "To verify that MUXI was installed correctly: . # Check the installed version muxi --version # Start the interactive CLI muxi chat # Run a simple test muxi send \"Hello, world!\" . ",
    "url": "/muxi/intro/installation#verifying-installation",
    
    "relUrl": "/intro/installation#verifying-installation"
  },"173": {
    "doc": "Installation",
    "title": "Package Structure",
    "content": "After installation, the MUXI framework will have the following structure: . muxi/ ├── core/ # Core components ├── server/ # Server implementation ├── cli/ # Command-line interface └── __init__.py # Main entry point . ",
    "url": "/muxi/intro/installation#package-structure",
    
    "relUrl": "/intro/installation#package-structure"
  },"174": {
    "doc": "Installation",
    "title": "Troubleshooting",
    "content": "Common Issues . Missing API Key: . Error: OpenAI API key not found . Solution: Set the OPENAI_API_KEY environment variable. Database Connection Error: . Error: Could not connect to database . Solution: Verify your POSTGRES_DATABASE_URL and ensure PostgreSQL is running. Port Already in Use: . Error: Address already in use . Solution: Change the port using MUXI_PORT environment variable or the port parameter in app.run(). Getting Help . If you encounter issues not covered here: . | Check the GitHub Issues for known problems | Join the Discord community for real-time help | Visit the Troubleshooting Guide for detailed solutions | . ",
    "url": "/muxi/intro/installation#troubleshooting",
    
    "relUrl": "/intro/installation#troubleshooting"
  },"175": {
    "doc": "Installation",
    "title": "Advanced Installation",
    "content": "Installing Specific Versions . pip install muxi==0.1.0 . Installing from Source . pip install git+https://github.com/yourusername/muxi-framework.git . Virtual Environments . It’s recommended to use virtual environments: . python -m venv venv source venv/bin/activate # On Windows: venv\\Scripts\\activate pip install muxi . ",
    "url": "/muxi/intro/installation#advanced-installation",
    
    "relUrl": "/intro/installation#advanced-installation"
  },"176": {
    "doc": "Installation",
    "title": "What’s Next",
    "content": ". | Quick Start Guide - Build your first MUXI application | Simple Agents - Learn how to create agents | Using MCP Servers - Extend your agents with external capabilities | . ",
    "url": "/muxi/intro/installation#whats-next",
    
    "relUrl": "/intro/installation#whats-next"
  },"177": {
    "doc": "Installation",
    "title": "Installation",
    "content": "The MUXI Framework can be installed through pip: . pip install muxi . For the latest development version: . pip install git+https://github.com/microsoft/muxi.git . ",
    "url": "/muxi/getting-started/installation.html",
    
    "relUrl": "/getting-started/installation.html"
  },"178": {
    "doc": "Installation",
    "title": "Dependencies",
    "content": "MUXI requires: . | Python 3.8+ | An LLM provider (OpenAI, Azure OpenAI, Anthropic, etc.) | API keys for the chosen providers | . ",
    "url": "/muxi/getting-started/installation.html#dependencies",
    
    "relUrl": "/getting-started/installation.html#dependencies"
  },"179": {
    "doc": "Installation",
    "title": "Development Setup",
    "content": "To set up a development environment: . | Clone the repository: git clone https://github.com/microsoft/muxi.git cd muxi . | Create a virtual environment: python -m venv venv source venv/bin/activate # On Windows: venv\\Scripts\\activate . | Install dependencies: pip install -e \".[dev]\" . | Set up environment variables: # For OpenAI export OPENAI_API_KEY=your_api_key # For Azure OpenAI export AZURE_OPENAI_API_KEY=your_api_key export AZURE_OPENAI_ENDPOINT=your_endpoint . | . ",
    "url": "/muxi/getting-started/installation.html#development-setup",
    
    "relUrl": "/getting-started/installation.html#development-setup"
  },"180": {
    "doc": "Installation",
    "title": "Configuration",
    "content": "Create a basic configuration file for your application: . # configs/muxi_config.yaml orchestrator: memory: buffer_size: 10 long_term: type: \"sqlite\" connection_string: \"memory.db\" agents: - name: \"assistant\" model: type: \"openai\" model_name: \"gpt-4\" temperature: 0.7 instructions: \"You are a helpful assistant.\" . ",
    "url": "/muxi/getting-started/installation.html#configuration",
    
    "relUrl": "/getting-started/installation.html#configuration"
  },"181": {
    "doc": "Installation",
    "title": "Running Tests",
    "content": "To run the test suite: . pytest . ",
    "url": "/muxi/getting-started/installation.html#running-tests",
    
    "relUrl": "/getting-started/installation.html#running-tests"
  },"182": {
    "doc": "Installation",
    "title": "Next Steps",
    "content": "After installation, proceed to the Quick Start Guide to create your first agent application. ",
    "url": "/muxi/getting-started/installation.html#next-steps",
    
    "relUrl": "/getting-started/installation.html#next-steps"
  },"183": {
    "doc": "Context Knowledge",
    "title": "Context Knowledge",
    "content": "This guide explains how to enhance your MUXI agents with context knowledge, allowing them to access and utilize information from external sources when responding to user queries. ",
    "url": "/muxi/extend/knowledge",
    
    "relUrl": "/extend/knowledge"
  },"184": {
    "doc": "Context Knowledge",
    "title": "Understanding Context Knowledge",
    "content": "Context knowledge in MUXI represents static information that agents can reference during conversations, providing them with: . | Factual information from documents, files, and other sources | Context-specific data for specialized applications | Up-to-date information without relying solely on model training data | . Unlike memory which tracks conversation history, context knowledge provides agents with external information they can search and reference. ",
    "url": "/muxi/extend/knowledge#understanding-context-knowledge",
    
    "relUrl": "/extend/knowledge#understanding-context-knowledge"
  },"185": {
    "doc": "Context Knowledge",
    "title": "Knowledge Types in MUXI",
    "content": "Currently, MUXI supports the following knowledge source types: . | File Knowledge: Text-based documents containing domain-specific information | . ",
    "url": "/muxi/extend/knowledge#knowledge-types-in-muxi",
    
    "relUrl": "/extend/knowledge#knowledge-types-in-muxi"
  },"186": {
    "doc": "Context Knowledge",
    "title": "Adding Knowledge to Agents",
    "content": "You can enhance agents with knowledge sources in both declarative and programmatic ways. Basic Knowledge Example . Declarative way . configs/knowledge_agent.yaml . --- agent_id: product_assistant description: A helpful assistant with knowledge about our products. model: provider: openai api_key: \"${OPENAI_API_KEY}\" model: gpt-4o knowledge: - path: \"knowledge/products.txt\" description: \"Information about our product catalog\" - path: \"knowledge/pricing.txt\" description: \"Pricing information for our products\" - path: \"knowledge/faq.txt\" description: \"Frequently asked questions about our products\" . app.py . from muxi import muxi from dotenv import load_dotenv import os import asyncio # Load environment variables load_dotenv() # Initialize MUXI app = muxi() # Add agent with knowledge from configuration app.add_agent(\"configs/knowledge_agent.yaml\") async def main(): # The agent can now answer questions based on the knowledge sources response = await app.chat(\"What products do you offer?\") print(response) # The agent will use relevant knowledge to answer specific questions response = await app.chat(\"What is the price of the Premium Plan?\") print(response) if __name__ == \"__main__\": asyncio.run(main()) . Programmatic way . import os import asyncio from muxi.core.orchestrator import Orchestrator from muxi.core.models.openai import OpenAIModel from muxi.knowledge.base import FileKnowledge async def main(): # Initialize components orchestrator = Orchestrator() model = OpenAIModel( api_key=os.getenv(\"OPENAI_API_KEY\"), model=\"gpt-4o\" ) # Create an agent agent = orchestrator.create_agent( agent_id=\"product_assistant\", description=\"A helpful assistant with knowledge about our products.\", model=model ) # Add knowledge sources to the agent product_knowledge = FileKnowledge( path=\"knowledge/products.txt\", description=\"Information about our product catalog\" ) pricing_knowledge = FileKnowledge( path=\"knowledge/pricing.txt\", description=\"Pricing information for our products\" ) faq_knowledge = FileKnowledge( path=\"knowledge/faq.txt\", description=\"Frequently asked questions about our products\" ) # Add knowledge sources to the agent await agent.add_knowledge(product_knowledge) await agent.add_knowledge(pricing_knowledge) await agent.add_knowledge(faq_knowledge) # The agent can now answer questions based on the knowledge sources response = await orchestrator.chat(\"product_assistant\", \"What products do you offer?\") print(response) # The agent will use relevant knowledge to answer specific questions response = await orchestrator.chat(\"product_assistant\", \"What is the price of the Premium Plan?\") print(response) if __name__ == \"__main__\": asyncio.run(main()) . ",
    "url": "/muxi/extend/knowledge#adding-knowledge-to-agents",
    
    "relUrl": "/extend/knowledge#adding-knowledge-to-agents"
  },"187": {
    "doc": "Context Knowledge",
    "title": "Searching Knowledge Explicitly",
    "content": "You can explicitly search an agent’s knowledge base to retrieve relevant information: . Declarative way . # app.py from muxi import muxi from dotenv import load_dotenv import asyncio # Load environment variables load_dotenv() # Initialize MUXI app = muxi() # Add agent with knowledge app.add_agent(\"configs/knowledge_agent.yaml\") async def main(): # Get the agent instance to access knowledge methods agent = app.get_agent(\"product_assistant\") # Search the knowledge base explicitly results = await agent.search_knowledge( query=\"Premium Plan features\", top_k=3, # Return top 3 most relevant results threshold=0.7 # Minimum relevance score (0-1) ) # Display search results print(\"Knowledge search results:\") for result in results: print(f\"Content: {result['content']}\") print(f\"Source: {result['source']}\") print(f\"Relevance: {result['relevance']:.2f}\") print(\"---\") if __name__ == \"__main__\": asyncio.run(main()) . Programmatic way . import os import asyncio from muxi.core.orchestrator import Orchestrator from muxi.core.models.openai import OpenAIModel from muxi.knowledge.base import FileKnowledge async def main(): # Initialize orchestrator orchestrator = Orchestrator() model = OpenAIModel( api_key=os.getenv(\"OPENAI_API_KEY\"), model=\"gpt-4o\" ) # Create an agent agent = orchestrator.create_agent( agent_id=\"product_assistant\", description=\"A helpful assistant with knowledge about our products.\", model=model ) # Add knowledge sources product_knowledge = FileKnowledge( path=\"knowledge/products.txt\", description=\"Information about our product catalog\" ) await agent.add_knowledge(product_knowledge) # Search the knowledge base explicitly results = await agent.search_knowledge( query=\"Premium Plan features\", top_k=3, # Return top 3 most relevant results threshold=0.7 # Minimum relevance score (0-1) ) # Display search results print(\"Knowledge search results:\") for result in results: print(f\"Content: {result['content']}\") print(f\"Source: {result['source']}\") print(f\"Relevance: {result['relevance']:.2f}\") print(\"---\") if __name__ == \"__main__\": asyncio.run(main()) . ",
    "url": "/muxi/extend/knowledge#searching-knowledge-explicitly",
    
    "relUrl": "/extend/knowledge#searching-knowledge-explicitly"
  },"188": {
    "doc": "Context Knowledge",
    "title": "Managing Knowledge Sources",
    "content": "You can add, remove, and list knowledge sources dynamically: . Adding Knowledge Sources . Programmatic way . # Add a new knowledge source to an existing agent new_knowledge = FileKnowledge( path=\"knowledge/new_products.txt\", description=\"Information about newly launched products\" ) await agent.add_knowledge(new_knowledge) . Removing Knowledge Sources . Programmatic way . # Remove a knowledge source by file path success = await agent.remove_knowledge(\"knowledge/outdated_products.txt\") if success: print(\"Knowledge source removed successfully\") else: print(\"Failed to remove knowledge source or file not found\") . Listing Knowledge Sources . Programmatic way . # Get a list of all knowledge sources sources = agent.get_knowledge_sources() print(\"Current knowledge sources:\") for source in sources: print(f\"- {source}\") . ",
    "url": "/muxi/extend/knowledge#managing-knowledge-sources",
    
    "relUrl": "/extend/knowledge#managing-knowledge-sources"
  },"189": {
    "doc": "Context Knowledge",
    "title": "Knowledge Embedding and Retrieval",
    "content": "Behind the scenes, MUXI: . | Processes knowledge sources: Documents are loaded and split into chunks | Generates embeddings: Text chunks are converted to vector embeddings | Builds vector index: Embeddings are stored in a FAISS index for fast retrieval | Implements semantic search: Relevance-based retrieval of information | . MUXI automatically determines the appropriate embedding dimension based on the agent’s model. ",
    "url": "/muxi/extend/knowledge#knowledge-embedding-and-retrieval",
    
    "relUrl": "/extend/knowledge#knowledge-embedding-and-retrieval"
  },"190": {
    "doc": "Context Knowledge",
    "title": "Knowledge Caching",
    "content": "For efficiency, MUXI caches knowledge embeddings: . | Embeddings are stored in .cache/knowledge_embeddings directory | Cached embeddings are reused when the same knowledge source is added again | Embeddings are regenerated when the source file is modified | . ",
    "url": "/muxi/extend/knowledge#knowledge-caching",
    
    "relUrl": "/extend/knowledge#knowledge-caching"
  },"191": {
    "doc": "Context Knowledge",
    "title": "Best Practices for Context Knowledge",
    "content": ". | Focus on Quality: Include high-quality, relevant information in knowledge sources | Right-Size Documents: Break large documents into smaller, topic-focused files | Descriptive Metadata: Provide clear descriptions for knowledge sources | Regular Updates: Keep knowledge sources up-to-date with the latest information | Knowledge vs. Memory: Use context knowledge for static information, memory for conversation context | Strategic Search: Set appropriate threshold and top_k values for your use case | . ",
    "url": "/muxi/extend/knowledge#best-practices-for-context-knowledge",
    
    "relUrl": "/extend/knowledge#best-practices-for-context-knowledge"
  },"192": {
    "doc": "Context Knowledge",
    "title": "Next Steps",
    "content": "Now that you’ve added context knowledge to your agents, you might want to: . | Combine context knowledge with memory - see User Context Memory | Create multi-agent systems with specialized knowledge - see Multi-Agent Systems | Configure your agents with specific settings - see Agent Configuration | . ",
    "url": "/muxi/extend/knowledge#next-steps",
    
    "relUrl": "/extend/knowledge#next-steps"
  },"193": {
    "doc": "MCP Server Integration",
    "title": "MCP Server Integration",
    "content": "Model Context Protocol (MCP) is a standardized protocol that allows AI applications to access specialized capabilities, share context with language models, and expose tools to AI systems. This guide explains how to integrate external MCP servers with your MUXI agents. ",
    "url": "/muxi/extend/mcp",
    
    "relUrl": "/extend/mcp"
  },"194": {
    "doc": "MCP Server Integration",
    "title": "Introduction to MCP",
    "content": "MCP enables your agents to leverage external tools and capabilities through a standardized interface. The MCP handler in MUXI manages the connections to MCP servers, abstracting the complexities of the transport layer from your application code. Key features of the MUXI MCP implementation include: . | Support for multiple transport types (HTTP+SSE and Command-line) | Robust reconnection with exponential backoff | Cancellation support for long-running operations | Comprehensive error handling and diagnostic information | Integration with the official MCP Python SDK | . ",
    "url": "/muxi/extend/mcp#introduction-to-mcp",
    
    "relUrl": "/extend/mcp#introduction-to-mcp"
  },"195": {
    "doc": "MCP Server Integration",
    "title": "Connecting to MCP Servers",
    "content": "There are two ways to connect your agents to MCP servers: . 1. Using Configuration Files . The simplest approach is to define MCP servers in your agent configuration: . name: my_assistant system_message: You are a helpful assistant with access to external tools. model: provider: openai api_key: \"${OPENAI_API_KEY}\" model: gpt-4o temperature: 0.7 mcp_servers: - name: web_search url: http://localhost:5001 credentials: - id: search_api_key param_name: api_key required: true env_fallback: SEARCH_API_KEY - name: calculator command: npx -y @modelcontextprotocol/server-calculator . 2. Programmatically . You can also connect to MCP servers programmatically: . from muxi import muxi # Initialize MUXI app = muxi() # Add an agent await app.add_agent(\"assistant\", \"configs/assistant.yaml\") # Connect to an HTTP-based MCP server await app.get_agent(\"assistant\").connect_mcp_server( name=\"weather\", url=\"http://localhost:5001\", credentials={\"api_key\": \"your_weather_api_key\"} ) # Connect to a command-line MCP server await app.get_agent(\"assistant\").connect_mcp_server( name=\"calculator\", command=\"npx -y @modelcontextprotocol/server-calculator\" ) . ",
    "url": "/muxi/extend/mcp#connecting-to-mcp-servers",
    
    "relUrl": "/extend/mcp#connecting-to-mcp-servers"
  },"196": {
    "doc": "MCP Server Integration",
    "title": "Transport Types",
    "content": "MUXI supports two transport types for MCP servers, automatically selected based on the parameters you provide: . HTTP+SSE Transport . This transport type is used for web-based MCP servers that follow the HTTP+SSE protocol. It’s automatically selected when you provide a url parameter: . | Client → Server messages go through HTTP POST requests | Server → Client messages go through Server-Sent Events (SSE) | Requires maintaining long-lived connections | . await agent.connect_mcp_server( name=\"web_search\", url=\"http://localhost:5001\", credentials={\"api_key\": \"your_api_key\"} ) . Command-line Transport . This transport type is used for local MCP servers that run as executable processes. It’s automatically selected when you provide a command parameter: . | Servers are started via command-line | Communication happens via standard input/output | Suitable for local development and testing | . await agent.connect_mcp_server( name=\"calculator\", command=\"npx -y @modelcontextprotocol/server-calculator\", credentials={\"api_key\": \"your_api_key\"} ) . ",
    "url": "/muxi/extend/mcp#transport-types",
    
    "relUrl": "/extend/mcp#transport-types"
  },"197": {
    "doc": "MCP Server Integration",
    "title": "MCP Server Credentials",
    "content": "MCP servers may require credentials for authentication, though many servers don’t need any authentication. Credentials are completely optional: . mcp_servers: - name: web_search url: http://localhost:5001 credentials: # Optional: can be omitted if no authentication is required - id: search_api_key param_name: api_key required: true env_fallback: SEARCH_API_KEY . Or programmatically: . # With credentials await agent.connect_mcp_server( name=\"web_search\", url=\"http://localhost:5001\", credentials={\"api_key\": \"your_api_key\"} ) # Without credentials (passing None or omitting the parameter are both valid) await agent.connect_mcp_server( name=\"calculator\", url=\"http://localhost:5002\" ) . ",
    "url": "/muxi/extend/mcp#mcp-server-credentials",
    
    "relUrl": "/extend/mcp#mcp-server-credentials"
  },"198": {
    "doc": "MCP Server Integration",
    "title": "Using MCP Servers in Agents",
    "content": "Once an MCP server is connected to an agent, the agent can automatically use it when needed. The LLM will receive information about available tools from MCP servers and can call them as needed. # Agent will automatically use connected MCP servers when appropriate response = await app.chat( \"What's the weather in New York? Also, what's 123 * 456?\" ) print(response.content) . ",
    "url": "/muxi/extend/mcp#using-mcp-servers-in-agents",
    
    "relUrl": "/extend/mcp#using-mcp-servers-in-agents"
  },"199": {
    "doc": "MCP Server Integration",
    "title": "Handling Disconnections",
    "content": "The MCP handler automatically manages reconnections using an exponential backoff strategy, but you can also manually disconnect and reconnect: . # Disconnect from an MCP server await agent.disconnect_mcp_server(\"web_search\") # Reconnect to the MCP server await agent.connect_mcp_server( name=\"web_search\", url=\"http://localhost:5001\", credentials={\"api_key\": \"your_api_key\"} ) . ",
    "url": "/muxi/extend/mcp#handling-disconnections",
    
    "relUrl": "/extend/mcp#handling-disconnections"
  },"200": {
    "doc": "MCP Server Integration",
    "title": "Cancellation Support",
    "content": "You can cancel long-running MCP operations if needed: . from muxi.core.mcp_handler import CancellationToken # Create a cancellation token token = CancellationToken() # Execute a potentially long-running operation task = agent.execute_tool(\"web_search\", {\"query\": \"complex research topic\"}, token) # Cancel the operation if needed token.cancel() . ",
    "url": "/muxi/extend/mcp#cancellation-support",
    
    "relUrl": "/extend/mcp#cancellation-support"
  },"201": {
    "doc": "MCP Server Integration",
    "title": "Error Handling",
    "content": "The MCP handler provides comprehensive error handling with specific exception types: . | MCPError: Base exception for all MCP-related errors | MCPConnectionError: For connection-related errors | MCPRequestError: For errors when making requests | MCPTimeoutError: For timeout errors | MCPCancelledError: For canceled operations | . from muxi.core.mcp_handler import MCPError, MCPConnectionError try: await agent.connect_mcp_server( name=\"web_search\", url=\"http://non-existent-server.com\", credentials={} ) except MCPConnectionError as e: print(f\"Failed to connect: {e}\") except MCPError as e: print(f\"General MCP error: {e}\") . ",
    "url": "/muxi/extend/mcp#error-handling",
    
    "relUrl": "/extend/mcp#error-handling"
  },"202": {
    "doc": "MCP Server Integration",
    "title": "Diagnostics",
    "content": "You can get detailed diagnostic information about MCP server connections: . # Get connection statistics for all MCP servers stats = agent.mcp_handler.get_connection_stats() print(stats) # Output example: # { # \"active_connections\": 2, # \"registered_tools\": 5, # \"active_operations\": 0, # \"current_time\": \"2023-07-15T10:30:45.123456\", # \"connections\": { # \"web_search\": { # \"connected\": true, # \"url\": \"http://localhost:5001\", # \"command\": null, # \"session_id\": \"abc123\", # \"connect_time\": \"2023-07-15T10:25:30.123456\", # \"connection_age_s\": 315.0, # \"last_activity\": \"2023-07-15T10:28:45.123456\", # \"idle_time_s\": 120.0 # }, # \"calculator\": { # \"connected\": true, # \"url\": null, # \"command\": \"npx -y @modelcontextprotocol/server-calculator\", # \"pid\": 12345 # } # } # } . ",
    "url": "/muxi/extend/mcp#diagnostics",
    
    "relUrl": "/extend/mcp#diagnostics"
  },"203": {
    "doc": "MCP Server Integration",
    "title": "Best Practices",
    "content": ". | Use Standard MCP Servers: Prefer well-tested, community-maintained MCP servers when possible | Handle Credentials Securely: Use environment variables for sensitive credentials | Implement Proper Error Handling: Catch and handle MCP-related exceptions appropriately | Monitor Connection Health: Periodically check connection statistics for potential issues | Set Appropriate Timeouts: Configure request timeouts based on expected operation duration | . ",
    "url": "/muxi/extend/mcp#best-practices",
    
    "relUrl": "/extend/mcp#best-practices"
  },"204": {
    "doc": "MCP Server Integration",
    "title": "Available MCP Servers",
    "content": "While MUXI doesn’t include built-in MCP servers, it has been tested with the following external MCP servers: . | Web Search: MCP servers that provide web search capabilities | Weather: MCP servers for weather information | Calculator: Basic calculator functionality | Brave Search: Integration with Brave search engine | . To use these servers, you’ll need to install and configure them separately according to their documentation. ",
    "url": "/muxi/extend/mcp#available-mcp-servers",
    
    "relUrl": "/extend/mcp#available-mcp-servers"
  },"205": {
    "doc": "MCP Server Integration",
    "title": "Advanced Configuration",
    "content": "For advanced scenarios, you can configure additional parameters: . await agent.connect_mcp_server( name=\"web_search\", url=\"http://localhost:5001\", credentials={\"api_key\": \"your_api_key\"}, request_timeout=120 # Timeout in seconds ) . ",
    "url": "/muxi/extend/mcp#advanced-configuration",
    
    "relUrl": "/extend/mcp#advanced-configuration"
  },"206": {
    "doc": "MCP Server Integration",
    "title": "Conclusion",
    "content": "MCP server integration enables your MUXI agents to leverage external capabilities through a standardized protocol. By following this guide, you can connect your agents to various MCP servers and enhance their capabilities. ",
    "url": "/muxi/extend/mcp#conclusion",
    
    "relUrl": "/extend/mcp#conclusion"
  },"207": {
    "doc": "Context Memory",
    "title": "Context Memory",
    "content": "This guide explains how to enhance your MUXI agents with user-level memory capabilities, allowing them to remember previous interactions with users, maintain chat context, and store important information across conversations. ",
    "url": "/muxi/agents/memory",
    
    "relUrl": "/agents/memory"
  },"208": {
    "doc": "Context Memory",
    "title": "Memory Types in MUXI",
    "content": "MUXI provides several memory systems: . | Buffer Memory: Short-term memory for recent conversations | Long-Term Memory: Persistent storage for important information | Memobase: User-specific memory management for multi-user applications | . ",
    "url": "/muxi/agents/memory#memory-types-in-muxi",
    
    "relUrl": "/agents/memory#memory-types-in-muxi"
  },"209": {
    "doc": "Context Memory",
    "title": "Buffer Memory",
    "content": "Buffer memory is a short-term memory system that stores recent conversation history, enabling agents to maintain context within a single session. Buffer memory is turned on by default (with a buffer size of 5). If you want to turn it off, set the buffer to zero. Basic Buffer Memory Example . Declarative way . configs/muxi_config.json . { \"agent_id\": \"assistant\", \"description\": \"A helpful assistant with short-term memory for conversations.\", \"model\": { \"provider\": \"openai\", \"api_key\": \"${OPENAI_API_KEY}\", \"model\": \"gpt-4o\" } } . app.py . from muxi import muxi from dotenv import load_dotenv # Load environment variables load_dotenv() # Initialize MUXI with buffer memory app = muxi( buffer_memory=20, config_file=\"configs/muxi_config.json\" ) # The agent will remember the conversation context response1 = await app.chat(\"assistant\", \"My name is Alice.\") print(response1) # The agent acknowledges and remembers the name response2 = await app.chat(\"assistant\", \"What's my name?\") print(response2) # The agent should respond with \"Alice\" . Programmatic way . import os from muxi.core.orchestrator import Orchestrator from muxi.core.agent import Agent from muxi.models.providers.openai import OpenAIModel from muxi.server.memory.buffer import BufferMemory # Initialize components model = OpenAIModel( api_key=os.getenv(\"OPENAI_API_KEY\"), model=\"gpt-4o\" ) buffer = BufferMemory(15) # Initialize orchestrator with buffer memory orchestrator = Orchestrator( buffer_memory=buffer ) # Create an agent that will use the orchestrator's memory orchestrator.create_agent( agent_id=\"assistant\", description=\"A helpful assistant with short-term memory for conversations.\", model=model ) # The agent will remember the conversation context response1 = orchestrator.chat(\"assistant\", \"My name is Alice.\") print(response1) # The agent acknowledges and remembers the name response2 = orchestrator.chat(\"assistant\", \"What's my name?\") print(response2) # The agent should respond with \"Alice\" . ",
    "url": "/muxi/agents/memory#buffer-memory",
    
    "relUrl": "/agents/memory#buffer-memory"
  },"210": {
    "doc": "Context Memory",
    "title": "Long-Term Memory",
    "content": "Long-term memory provides persistent storage for important information across sessions. MUXI supports two database options for long-term memory: . | PostgreSQL with pgvector: Recommended for production and multi-user deployments | SQLite with sqlite-vec: Ideal for local development and single-user deployments | . Long-term memory requires a database. MUXI makes it easy to use either PostgreSQL or SQLite based on your needs. When to Use Each Database Option . Choose SQLite with sqlite-vec for: . | Local development and testing | Single-user applications | Edge computing and resource-constrained environments | Situations where a simple file-based database is preferred | Rapid prototyping and proof-of-concept projects | . Choose PostgreSQL with pgvector for: . | Production environments | Multi-user applications | High-throughput systems | Enterprise deployments with high availability requirements | Scenarios requiring horizontal scaling | . PostgreSQL Configuration Example . Declarative way . # configs/muxi_config.yaml --- agents: - agent_id: assistant description: A helpful assistant with PostgreSQL-based long-term memory. model: provider: openai api_key: \"${OPENAI_API_KEY}\" model: gpt-4o . # app.py from muxi import muxi from dotenv import load_dotenv import os # Load environment variables load_dotenv() # Initialize MUXI with both buffer and PostgreSQL long-term memory app = muxi( buffer_memory=15, long_term_memory=\"postgresql://user:pass@localhost/db\", config_file=\"configs/muxi_config.yaml\" ) # The agent will store important information in long-term memory await app.chat(\"assistant\", \"Remember that my favorite color is blue.\") . SQLite Configuration Example . Declarative way . # configs/muxi_config.yaml --- agents: - agent_id: assistant description: A helpful assistant with SQLite-based long-term memory. model: provider: openai api_key: \"${OPENAI_API_KEY}\" model: gpt-4o . You can also use long_term_memory=True to use a default SQLite database named “muxi.db” in your application’s root directory. # app.py from muxi import muxi from dotenv import load_dotenv import os # Load environment variables load_dotenv() # Initialize MUXI with both buffer and SQLite long-term memory app = muxi( buffer_memory=15, long_term_memory=\"sqlite:///data/memory.db\", config_file=\"configs/muxi_config.yaml\" ) # The agent will store important information in long-term memory await app.chat(\"assistant\", \"Remember that my favorite color is blue.\") . Programmatic way . import os from muxi.core.orchestrator import Orchestrator from muxi.core.agent import Agent from muxi.models.providers.openai import OpenAIModel from muxi.server.memory.buffer import BufferMemory from muxi.server.memory.long_term import LongTermMemory # Initialize components model = OpenAIModel( api_key=os.getenv(\"OPENAI_API_KEY\"), model=\"gpt-4o\" ) buffer = BufferMemory(15) # Option 1: PostgreSQL long-term memory (for production/multi-user deployments) postgres_connection = \"postgresql://user:password@localhost:5432/muxi\" # Or use environment variable: # postgres_connection = os.getenv(\"POSTGRES_DATABASE_URL\") # Option 2: SQLite long-term memory (for local/single-user deployments) sqlite_connection = \"sqlite:///data/memory.db\" # Choose the memory system based on your needs connection_string = sqlite_connection # or postgres_connection long_term_memory = LongTermMemory(connection_string=connection_string) # Initialize orchestrator with both buffer and long-term memory orchestrator = Orchestrator( buffer_memory=buffer, long_term_memory=long_term_memory ) # Create an agent that will use the orchestrator's memory orchestrator.create_agent( agent_id=\"assistant\", description=\"A helpful assistant with both short-term and long-term memory capabilities.\", model=model ) # The agent will store important information in long-term memory orchestrator.chat(\"assistant\", \"Remember that my favorite color is blue.\") . Searching Long-Term Memory . You can explicitly search memory, regardless of whether you’re using PostgreSQL or SQLite: . Declarative way . # Search the memory explicitly search_results = await app.orchestrator.search_memory( query=\"What do I like?\", agent_id=\"assistant\", # Optional: filter by agent_id k=3, # Return top 3 results threshold=0.7 # Minimum similarity threshold (0-1) ) print(\"Memory search results:\") for result in search_results: print(f\"Memory: {result['content']}\") print(f\"Relevance: {result['similarity']}\") print(\"---\") . Programmatic way . # Search the orchestrator's memory for relevant information results = orchestrator.search_memory( query=\"What do I like?\", agent_id=\"assistant\", # Optional: filter by agent_id k=3, # Return top 3 results threshold=0.7 # Minimum similarity threshold (0-1) ) print(\"Memory search results:\") for result in results: print(f\"Memory: {result['content']}\") print(f\"Relevance: {result['similarity']}\") print(\"---\") . ",
    "url": "/muxi/agents/memory#long-term-memory",
    
    "relUrl": "/agents/memory#long-term-memory"
  },"211": {
    "doc": "Context Memory",
    "title": "Multi-User Memory with Memobase",
    "content": "For applications serving multiple users, MUXI provides the Memobase system, which partitions memory by user ID. For multi-user applications, we recommend using PostgreSQL with pgvector due to its better concurrency handling and scalability. Setting Up Memobase . Declarative way . # app.py from muxi import muxi from dotenv import load_dotenv import os # Load environment variables load_dotenv() # Initialize MUXI with multi-user memory app = muxi( buffer_memory=15, long_term_memory=\"postgresql://user:pass@localhost/db\", config_file=\"configs/muxi_config.yaml\" ) # Chat with the agent as different users user_1_response = await app.chat( message=\"My name is Bob and I like hiking.\", agent_name=\"assistant\", user_id=\"user_1\" ) user_2_response = await app.chat( message=\"My name is Carol and I like painting.\", agent_name=\"assistant\", user_id=\"user_2\" ) # Later, the agent will remember each user's specific information user_1_question = await app.chat( message=\"What hobby do I enjoy?\", agent_name=\"assistant\", user_id=\"user_1\" ) print(f\"User 1 response: {user_1_question}\") # Should mention hiking user_2_question = await app.chat( message=\"What hobby do I enjoy?\", agent_name=\"assistant\", user_id=\"user_2\" ) print(f\"User 2 response: {user_2_question}\") # Should mention painting . Programmatic way . # Initialize orchestrator with multi-user memory support from muxi.server.memory.memobase import Memobase # Create Memobase for multi-user support long_term_memory = LongTermMemory(connection_string=\"postgresql://user:pass@localhost/db\") memobase = Memobase(long_term_memory=long_term_memory) # Initialize orchestrator with multi-user memory orchestrator = Orchestrator( buffer_memory=buffer, long_term_memory=memobase ) # Create an agent orchestrator.create_agent( agent_id=\"assistant\", description=\"A helpful assistant with multi-user memory.\", model=model ) # Chat with the agent as different users user_1_response = orchestrator.chat( \"assistant\", \"My name is Bob and I like hiking.\", user_id=\"user_1\" ) user_2_response = orchestrator.chat( \"assistant\", \"My name is Carol and I like painting.\", user_id=\"user_2\" ) # Later, the agent will remember each user's specific information user_1_question = orchestrator.chat( \"assistant\", \"What hobby do I enjoy?\", user_id=\"user_1\" ) print(f\"User 1 response: {user_1_question}\") # Should mention hiking user_2_question = orchestrator.chat( \"assistant\", \"What hobby do I enjoy?\", user_id=\"user_2\" ) print(f\"User 2 response: {user_2_question}\") # Should mention painting . ",
    "url": "/muxi/agents/memory#multi-user-memory-with-memobase",
    
    "relUrl": "/agents/memory#multi-user-memory-with-memobase"
  },"212": {
    "doc": "Context Memory",
    "title": "Database Technical Details",
    "content": "SQLite with sqlite-vec . MUXI uses the sqlite-vec Python package for vector operations in SQLite. This provides several advantages: . | Simplified installation: No need to manage binary extensions | Cross-platform compatibility: Works consistently across operating systems | Simple deployment: Single file database easy to back up and manage | Suitable for edge computing: Runs well in resource-constrained environments | . PostgreSQL with pgvector . For production and multi-user deployments, MUXI supports PostgreSQL with the pgvector extension: . | Horizontal scaling: Supports larger deployments with multiple users | Advanced indexing: Better performance for large vector datasets | Concurrency: Handles multiple simultaneous connections efficiently | Enterprise features: Replication, backup, and monitoring options | . ",
    "url": "/muxi/agents/memory#database-technical-details",
    
    "relUrl": "/agents/memory#database-technical-details"
  },"213": {
    "doc": "Context Memory",
    "title": "Best Practices for Memory Management",
    "content": ". | Balance Buffer Size: Keep buffer memory large enough for context but not too large for model context limits | Prioritize Important Information: Store only significant information in long-term memory | Use Context Knowledge for Static Information: Context knowledge is perfect for unchanging facts | Separate Concerns with Memobase: Always use Memobase for multi-user applications | Choose the Right Database: . | Use SQLite for development, single-user, and resource-constrained environments | Use PostgreSQL for production, multi-user, and high-scalability needs | . | Regular Memory Maintenance: Implement policies to clear or archive old memories | Security and Privacy: Be mindful of what information you store and for how long | . ",
    "url": "/muxi/agents/memory#best-practices-for-memory-management",
    
    "relUrl": "/agents/memory#best-practices-for-memory-management"
  },"214": {
    "doc": "Context Memory",
    "title": "Next Steps",
    "content": "Now that you’ve added memory to your agents, you might want to: . | Learn how to create multi-agent systems - see Multi-Agent Systems | Configure your agents with specific settings - see Agent Configuration | Explore deep dives into memory architecture - see Memory System | . ",
    "url": "/muxi/agents/memory#next-steps",
    
    "relUrl": "/agents/memory#next-steps"
  },"215": {
    "doc": "Multi-Agent Systems",
    "title": "Multi-Agent Systems",
    "content": "This guide explores how to create multi-agent systems with the MUXI Framework, where multiple specialized agents work together to handle complex tasks. ",
    "url": "/muxi/agents/multi-agent",
    
    "relUrl": "/agents/multi-agent"
  },"216": {
    "doc": "Multi-Agent Systems",
    "title": "Why Use Multiple Agents?",
    "content": "Multi-agent systems offer several advantages: . | Specialization: Create agents with different expertise and capabilities | Division of Labor: Distribute complex tasks among specialized agents | Scalability: Handle more requests by distributing them across agents | Redundancy: Provide fallback options if one agent cannot handle a task | . ",
    "url": "/muxi/agents/multi-agent#why-use-multiple-agents",
    
    "relUrl": "/agents/multi-agent#why-use-multiple-agents"
  },"217": {
    "doc": "Multi-Agent Systems",
    "title": "Setting Up a Multi-Agent System",
    "content": "Basic Multi-Agent Setup . The Orchestrator class makes it easy to create and manage multiple agents: . Declarative way . # configs/general_assistant.yaml --- agent_id: general_assistant description: A helpful assistant for general questions about various topics. model: provider: openai api_key: \"${OPENAI_API_KEY}\" model: gpt-3.5-turbo system_message: You are a helpful assistant that can answer general questions. # configs/code_assistant.yaml --- agent_id: code_assistant description: A specialized coding assistant that can help with programming tasks and code examples. model: provider: openai api_key: \"${OPENAI_API_KEY}\" model: gpt-4o system_message: You are a specialized coding assistant with expertise in Python, JavaScript, and other popular languages. Provide code examples and explanations. # configs/data_science_assistant.yaml --- agent_id: data_science_assistant description: A specialized assistant for data science, statistics, and machine learning topics. model: provider: openai api_key: \"${OPENAI_API_KEY}\" model: gpt-4o system_message: You are a specialized data science assistant with expertise in statistics, machine learning, and data analysis. Provide detailed technical advice. # app.py from muxi import muxi from dotenv import load_dotenv import asyncio # Load environment variables load_dotenv() # Initialize MUXI app = muxi() # Add agents from individual configuration files app.add_agent(\"configs/general_assistant.yaml\") app.add_agent(\"configs/code_assistant.yaml\") app.add_agent(\"configs/data_science_assistant.yaml\") async def main(): # Chat with specific agents general_response = await app.chat(\"general_assistant\", \"What is climate change?\") print(f\"General Assistant: {general_response}\") code_response = await app.chat(\"code_assistant\", \"How do I implement a binary search in Python?\") print(f\"Code Assistant: {code_response}\") data_response = await app.chat(\"data_science_assistant\", \"Explain the difference between precision and recall.\") print(f\"Data Science Assistant: {data_response}\") if __name__ == \"__main__\": asyncio.run(main()) . Programmatic way . # multi_agent_setup.py import os import asyncio from muxi.core.orchestrator import Orchestrator from muxi.core.models.openai import OpenAIModel from dotenv import load_dotenv async def main(): # Load environment variables load_dotenv() # Initialize the orchestrator orchestrator = Orchestrator() # Create models for different agents general_model = OpenAIModel( api_key=os.getenv(\"OPENAI_API_KEY\"), model=\"gpt-3.5-turbo\" ) expert_model = OpenAIModel( api_key=os.getenv(\"OPENAI_API_KEY\"), model=\"gpt-4o\" ) # Create a general assistant orchestrator.create_agent( agent_id=\"general_assistant\", description=\"A helpful assistant for general questions about various topics.\", model=general_model, system_message=\"You are a helpful assistant that can answer general questions.\" ) # Create a coding assistant orchestrator.create_agent( agent_id=\"code_assistant\", description=\"A specialized coding assistant that can help with programming tasks and code examples.\", model=expert_model, system_message=\"You are a specialized coding assistant with expertise in Python, JavaScript, and other popular languages. Provide code examples and explanations.\" ) # Create a data science assistant orchestrator.create_agent( agent_id=\"data_science_assistant\", description=\"A specialized assistant for data science, statistics, and machine learning topics.\", model=expert_model, system_message=\"You are a specialized data science assistant with expertise in statistics, machine learning, and data analysis. Provide detailed technical advice.\" ) # Chat with specific agents general_response = await orchestrator.chat(\"general_assistant\", \"What is climate change?\") print(f\"General Assistant: {general_response}\") code_response = await orchestrator.chat(\"code_assistant\", \"How do I implement a binary search in Python?\") print(f\"Code Assistant: {code_response}\") data_response = await orchestrator.chat(\"data_science_assistant\", \"Explain the difference between precision and recall.\") print(f\"Data Science Assistant: {data_response}\") if __name__ == \"__main__\": asyncio.run(main()) . ",
    "url": "/muxi/agents/multi-agent#setting-up-a-multi-agent-system",
    
    "relUrl": "/agents/multi-agent#setting-up-a-multi-agent-system"
  },"218": {
    "doc": "Multi-Agent Systems",
    "title": "Intelligent Message Routing",
    "content": "MUXI provides intelligent routing to direct messages to the most appropriate agent based on content: . Declarative way . # configs/multi_agent_system.yaml --- routing: provider: openai api_key: \"${OPENAI_API_KEY}\" model: gpt-4o . # routing_app.py from muxi import muxi from dotenv import load_dotenv import asyncio # Load environment variables load_dotenv() # Initialize MUXI app = muxi() # Add agents from individual configuration files app.add_agent(\"configs/general_assistant.yaml\") app.add_agent(\"configs/code_assistant.yaml\") app.add_agent(\"configs/creative_assistant.yaml\") # Configure routing from file app.configure_routing(\"configs/multi_agent_system.yaml\") async def main(): # The system will automatically route messages to the appropriate agent response1 = await app.chat(\"How do I implement binary search in Python?\") print(f\"Response (likely from coding agent): {response1}\") response2 = await app.chat(\"Tell me about the history of Rome.\") print(f\"Response (likely from general agent): {response2}\") response3 = await app.chat(\"Write a short poem about autumn.\") print(f\"Response (likely from creative agent): {response3}\") if __name__ == \"__main__\": asyncio.run(main()) . Programmatic way . # intelligent_routing.py import os import asyncio from muxi.core.orchestrator import Orchestrator from muxi.core.models.openai import OpenAIModel from muxi.core.routing import Routing from dotenv import load_dotenv async def main(): # Load environment variables load_dotenv() # Initialize the orchestrator orchestrator = Orchestrator() # Create models for different agents general_model = OpenAIModel( api_key=os.getenv(\"OPENAI_API_KEY\"), model=\"gpt-3.5-turbo\" ) expert_model = OpenAIModel( api_key=os.getenv(\"OPENAI_API_KEY\"), model=\"gpt-4o\" ) # Create a general assistant orchestrator.create_agent( agent_id=\"general_assistant\", description=\"A helpful assistant for general questions about various topics.\", model=general_model, system_message=\"You are a helpful assistant that can answer general questions.\" ) # Create a coding assistant orchestrator.create_agent( agent_id=\"code_assistant\", description=\"A specialized coding assistant that can help with programming tasks and code examples.\", model=expert_model, system_message=\"You are a specialized coding assistant with expertise in Python, JavaScript, and other popular languages. Provide code examples and explanations.\" ) # Create a creative assistant orchestrator.create_agent( agent_id=\"creative_assistant\", description=\"A creative assistant that specializes in writing and creative content generation.\", model=expert_model, system_message=\"You are a creative assistant that specializes in writing stories, poems, and generating creative content.\" ) # Configure routing routing_model = OpenAIModel( api_key=os.getenv(\"OPENAI_API_KEY\"), model=\"gpt-4o\" ) orchestrator.set_routing(Routing(model=routing_model)) # The orchestrator will automatically route the message to the most appropriate agent response1 = await orchestrator.chat(message=\"How do I implement binary search in Python?\") print(f\"Response (likely from coding agent): {response1}\") response2 = await orchestrator.chat(message=\"Tell me about the history of Rome.\") print(f\"Response (likely from general agent): {response2}\") response3 = await orchestrator.chat(message=\"Write a short poem about autumn.\") print(f\"Response (likely from creative agent): {response3}\") if __name__ == \"__main__\": asyncio.run(main()) . ",
    "url": "/muxi/agents/multi-agent#intelligent-message-routing",
    
    "relUrl": "/agents/multi-agent#intelligent-message-routing"
  },"219": {
    "doc": "Multi-Agent Systems",
    "title": "Agent Collaboration",
    "content": "You can implement collaboration between agents by passing information between them: . Declarative way . # configs/research_team/researcher.yaml --- agent_id: researcher description: An agent specialized in gathering and analyzing information on various topics. model: provider: openai api_key: \"${OPENAI_API_KEY}\" model: gpt-4o system_message: You are a research specialist. Your role is to gather comprehensive information on requested topics, providing well-researched, factual analysis. # configs/research_team/writer.yaml --- agent_id: writer description: An agent specialized in creating well-structured, engaging content based on information. model: provider: openai api_key: \"${OPENAI_API_KEY}\" model: gpt-4o system_message: You are a professional content writer. Your role is to take information and transform it into engaging, well-structured articles or reports. # configs/research_team/critic.yaml --- agent_id: critic description: An agent specialized in evaluating and improving content quality, accuracy, and clarity. model: provider: openai api_key: \"${OPENAI_API_KEY}\" model: gpt-4o system_message: You are a content critic and editor. Your role is to review content for accuracy, clarity, and quality, providing constructive feedback and suggested improvements. # collaborative_agents.py from muxi import muxi from dotenv import load_dotenv import asyncio # Load environment variables load_dotenv() # Initialize MUXI app = muxi() # Add research team agents app.add_agent(\"configs/research_team/researcher.yaml\") app.add_agent(\"configs/research_team/writer.yaml\") app.add_agent(\"configs/research_team/critic.yaml\") async def collaborative_workflow(): # Use the researcher for gathering information research_response = await app.chat(\"researcher\", \"What are the latest developments in renewable energy?\") print(f\"Research findings: {research_response}\") # Use the writer to create content based on research writing_response = await app.chat(\"writer\", f\"Create an article about renewable energy based on this research: {research_response}\") print(f\"Draft article: {writing_response}\") # Use the critic to review the article critique_response = await app.chat(\"critic\", f\"Review this article for accuracy and quality: {writing_response}\") print(f\"Critique: {critique_response}\") # Optionally, have the writer revise based on feedback revised_article = await app.chat(\"writer\", f\"Revise this article based on the following critique: {critique_response}\\n\\nOriginal article: {writing_response}\") print(f\"Revised article: {revised_article}\") if __name__ == \"__main__\": asyncio.run(collaborative_workflow()) . Programmatic way . # collaborative_research_team.py import os import asyncio from muxi.core.orchestrator import Orchestrator from muxi.core.models.openai import OpenAIModel from dotenv import load_dotenv async def main(): # Load environment variables load_dotenv() # Initialize the orchestrator orchestrator = Orchestrator() # Create model for all agents expert_model = OpenAIModel( api_key=os.getenv(\"OPENAI_API_KEY\"), model=\"gpt-4o\" ) # Create the research team agents orchestrator.create_agent( agent_id=\"researcher\", description=\"An agent specialized in gathering and analyzing information on various topics.\", model=expert_model, system_message=\"You are a research specialist. Your role is to gather comprehensive information on requested topics, providing well-researched, factual analysis.\" ) orchestrator.create_agent( agent_id=\"writer\", description=\"An agent specialized in creating well-structured, engaging content based on information.\", model=expert_model, system_message=\"You are a professional content writer. Your role is to take information and transform it into engaging, well-structured articles or reports.\" ) orchestrator.create_agent( agent_id=\"critic\", description=\"An agent specialized in evaluating and improving content quality, accuracy, and clarity.\", model=expert_model, system_message=\"You are a content critic and editor. Your role is to review content for accuracy, clarity, and quality, providing constructive feedback and suggested improvements.\" ) # Execute a collaborative research and writing workflow research_response = await orchestrator.chat(\"researcher\", \"What are the latest developments in renewable energy?\") print(f\"Research findings: {research_response}\") writing_response = await orchestrator.chat(\"writer\", f\"Create an article about renewable energy based on this research: {research_response}\") print(f\"Draft article: {writing_response}\") critique_response = await orchestrator.chat(\"critic\", f\"Review this article for accuracy and quality: {writing_response}\") print(f\"Critique: {critique_response}\") # Optionally, have the writer revise based on feedback revised_article = await orchestrator.chat(\"writer\", f\"Revise this article based on the following critique: {critique_response}\\n\\nOriginal article: {writing_response}\") print(f\"Revised article: {revised_article}\") if __name__ == \"__main__\": asyncio.run(main()) . ",
    "url": "/muxi/agents/multi-agent#agent-collaboration",
    
    "relUrl": "/agents/multi-agent#agent-collaboration"
  },"220": {
    "doc": "Multi-Agent Systems",
    "title": "Best Practices for Multi-Agent Systems",
    "content": ". | Clear Specialization: Define clear roles and expertise for each agent | Consistent System Messages: Make system messages detailed and non-overlapping | Appropriate Model Selection: Use more powerful models for complex tasks | Memory Management: Consider whether agents should share memory or maintain separate contexts | Error Handling: Implement fallback mechanisms if routing fails | Observability: Add logging to track which agent handles which messages | . ",
    "url": "/muxi/agents/multi-agent#best-practices-for-multi-agent-systems",
    
    "relUrl": "/agents/multi-agent#best-practices-for-multi-agent-systems"
  },"221": {
    "doc": "Multi-Agent Systems",
    "title": "Next Steps",
    "content": "Now that you’ve set up a multi-agent system, you might want to: . | Add memory to your agents - see Adding Memory | Configure your agents with specific settings - see Agent Configuration | Explore how to connect your agents to external services - see Using MCP Servers | . ",
    "url": "/muxi/agents/multi-agent#next-steps",
    
    "relUrl": "/agents/multi-agent#next-steps"
  },"222": {
    "doc": "Overview & Key Concepts",
    "title": "Overview &amp; Key Concepts",
    "content": " ",
    "url": "/muxi/intro/overview#overview--key-concepts",
    
    "relUrl": "/intro/overview#overview--key-concepts"
  },"223": {
    "doc": "Overview & Key Concepts",
    "title": "What You’ll Learn",
    "content": ". | What the MUXI Framework is and what problems it solves | The key components of the framework | How these components work together | Core architectural principles | . ",
    "url": "/muxi/intro/overview#what-youll-learn",
    
    "relUrl": "/intro/overview#what-youll-learn"
  },"224": {
    "doc": "Overview & Key Concepts",
    "title": "Prerequisites",
    "content": ". | None - this is a starting point for all users | . ",
    "url": "/muxi/intro/overview#prerequisites",
    
    "relUrl": "/intro/overview#prerequisites"
  },"225": {
    "doc": "Overview & Key Concepts",
    "title": "MUXI Framework Overview",
    "content": "MUXI is an extensible framework for building AI agents with real-time communication capabilities, memory persistence, and MCP server integration. It simplifies the process of creating sophisticated AI systems by providing a modular, well-structured foundation. This project is a work in progress and is not yet ready for production use. The framework is actively being developed with new features being added regularly. Please refer to the roadmap for information about the current state of the project and where it’s headed. ",
    "url": "/muxi/intro/overview#muxi-framework-overview",
    
    "relUrl": "/intro/overview#muxi-framework-overview"
  },"226": {
    "doc": "Overview & Key Concepts",
    "title": "Key Features",
    "content": ". | Multi-Agent Orchestration: Create and manage multiple AI agents with different capabilities | Intelligent Message Routing: Automatically select the most appropriate agent based on message content | Model Context Protocol (MCP): Connect to external services via standardized MCP servers | Standardized LLM Communication: Use a consistent protocol across different LLM providers | Memory Systems: Short-term buffer memory and long-term persistent memory | Multi-User Support: Memobase provides user-specific memory partitioning for multi-tenant applications | Domain Knowledge: Store and retrieve structured information to personalize agent responses | Real-Time Communication: WebSocket support for instant messaging | REST API: Comprehensive API for managing agents, MCP servers, and conversations | Command Line Interface: Rich terminal-based interface for creating and interacting with agents | Flexible Configuration: Define agents using YAML or JSON with minimal code | . ",
    "url": "/muxi/intro/overview#key-features",
    
    "relUrl": "/intro/overview#key-features"
  },"227": {
    "doc": "Overview & Key Concepts",
    "title": "Core Architecture",
    "content": "MUXI follows a modular design where specialized components work together to enable complex agent behaviors: . ┌───────────────────┐ │ Clients │ │ (CLI/Web/SDK) │ └─────────┬─────────┘ │ │ (API/SSE/WS) │ ┌─────────│───────────────────────────────────────────┐ │ │ MUXI Server (Local/Remote) │ │ │ │ │ │ ┌───────────────┐ │ │ └───────&gt;│ Orchestrator │ │ │ └───────┬───────┘ │ │ ┌────────────────┼────────────────┐ │ │ │ │ │ │ │ ▼ ▼ ▼ │ │ ┌─────────────┐ ┌─────────────┐ ┌─────────────┐ │ ┌───────────┐ │ │ Agent 1 │ │ Agent 2 │ │ Agent N │-------│ Knowledge │ │ └──────┬──────┘ └──────┬──────┘ └──────┬──────┘ │ └───────────┘ │ ↓ ↓ ↓ │ │ └────────┬───────┴────────┬───────┘ │ │ ↓ : │ │ ┌──────┴──────┐ ┌──────┴──────┐ │ │ │ MCP Handler │ │ Memory │ │ │ └──────┬──────┘ └─────────────┘ │ └──────────────────│──────────────────────────────────┘ │ │ (HTTP) ▼ ┌─────────────────────────────────────────────────────┐ │ MCP Servers (via Command/SSE) │ │ ┌─────────────┐ ┌─────────────┐ ┌─────────────┐ │ │ │ Weather │ │ Web Search │ │ .... │ │ │ └─────────────┘ └─────────────┘ └─────────────┘ │ └─────────────────────────────────────────────────────┘ . ",
    "url": "/muxi/intro/overview#core-architecture",
    
    "relUrl": "/intro/overview#core-architecture"
  },"228": {
    "doc": "Overview & Key Concepts",
    "title": "Key Components",
    "content": "1. Server Layer . The Server layer is the entry point for all external communication with the framework: . | REST API: Endpoints for agent management, chat operations, and memory interactions | WebSocket Server: Real-time, bidirectional communication for streaming responses | Web App: Frontend interface for visual interaction | CLI: Command-line interface for text-based interaction | . 2. Orchestrator . The Orchestrator is the central coordinator that: . | Manages the lifecycle of all agents in the system | Routes messages to the appropriate agent | Handles agent creation, configuration, and removal | Provides a unified interface for all client applications | . 3. Agents . Agents are the intelligent entities that process information and produce responses: . | Integrate with a specific LLM provider | Maintain their own memory systems | Access MCP servers for extended capabilities | Process messages according to their system instructions | . 4. Model Context Protocol (MCP) . The MCP is a standardized communication layer between agents and external services: . | Provides a consistent interface for integrating external functionality | Handles specialized message formatting | Manages request/response parsing and serialization | Supports function execution and result handling | . 5. Memory Systems . MUXI includes a sophisticated memory architecture: . | Buffer Memory: Short-term contextual memory for conversation flow | Long-Term Memory: Persistent storage of important information | Memobase: Multi-user aware memory system that partitions by user ID | . 6. LLM Providers . The framework supports multiple LLM providers: . | OpenAI (GPT models) | Anthropic (Claude models) | Local models via Ollama | Expandable to additional providers | . ",
    "url": "/muxi/intro/overview#key-components",
    
    "relUrl": "/intro/overview#key-components"
  },"229": {
    "doc": "Overview & Key Concepts",
    "title": "How Everything Works Together",
    "content": ". | Client Requests: Enter through one of the interfaces (REST, WebSocket, CLI, Web App) | Server Processing: The server layer validates and routes requests to the Orchestrator | Orchestration: The Orchestrator identifies the target agent and forwards the message | Agent Processing: . | The agent retrieves relevant context from memory | Formulates a prompt for the LLM | Sends the prompt to the LLM provider | . | LLM Interaction: . | The LLM processes the prompt and generates a response | If MCP requests are needed, they are identified and extracted | . | MCP Server Execution: . | MCP requests are routed to the appropriate servers | Servers execute with the provided parameters | Results are returned to the agent | . | Response Formulation: . | The agent incorporates results if applicable | Formulates the final response | . | Memory Updates: . | The conversation is stored in buffer memory | Important information is persisted to long-term memory | . | Client Response: The response is returned to the client through the original interface | . ",
    "url": "/muxi/intro/overview#how-everything-works-together",
    
    "relUrl": "/intro/overview#how-everything-works-together"
  },"230": {
    "doc": "Overview & Key Concepts",
    "title": "What Makes MUXI Different?",
    "content": "MUXI sets itself apart from other frameworks by: . | Simplicity First: MUXI abstracts away the complexity of text splitting, embeddings, and prompt engineering, letting you focus on building great agents | Truly Multi-Agent: Built from the ground up with multi-agent orchestration in mind | Standardized External Services: The MCP provides a clean, standard way to integrate external services | Multi-User by Design: User-specific memory partitioning is built into the core architecture | Hybrid Communication: Support for both request-response and real-time communication patterns | . ",
    "url": "/muxi/intro/overview#what-makes-muxi-different",
    
    "relUrl": "/intro/overview#what-makes-muxi-different"
  },"231": {
    "doc": "Overview & Key Concepts",
    "title": "Advanced Topics",
    "content": "For a deeper understanding of each component, explore these technical deep dives: . | Agent Fundamentals | Memory Systems | MCP Fundamentals | Orchestration | . ",
    "url": "/muxi/intro/overview#advanced-topics",
    
    "relUrl": "/intro/overview#advanced-topics"
  },"232": {
    "doc": "Overview & Key Concepts",
    "title": "What’s Next",
    "content": ". | Why MUXI? - Learn why MUXI is the right choice for your AI projects | Quick Start Guide - Get up and running with MUXI | Architecture - Dive deeper into the framework’s architecture | . ",
    "url": "/muxi/intro/overview#whats-next",
    
    "relUrl": "/intro/overview#whats-next"
  },"233": {
    "doc": "Overview & Key Concepts",
    "title": "Overview & Key Concepts",
    "content": " ",
    "url": "/muxi/intro/overview",
    
    "relUrl": "/intro/overview"
  },"234": {
    "doc": "Package Structure",
    "title": "Package Structure",
    "content": "This page provides a detailed overview of the MUXI Framework’s package organization and internal structure. ",
    "url": "/muxi/reference/package",
    
    "relUrl": "/reference/package"
  },"235": {
    "doc": "Package Structure",
    "title": "Overview",
    "content": "MUXI is organized as a modular monorepo with multiple packages that can be used independently or together. This approach provides several advantages: . | Separation of Concerns: Each package has a clear, focused responsibility | Independent Versioning: Packages can evolve at different rates | Reduced Dependencies: Users can install only what they need | Clearer Boundaries: Interfaces between components are well-defined | Focused Testing: Each package can be tested in isolation | . ",
    "url": "/muxi/reference/package#overview",
    
    "relUrl": "/reference/package#overview"
  },"236": {
    "doc": "Package Structure",
    "title": "Package Organization",
    "content": "The MUXI framework is structured as follows: . muxi-framework/ ├── packages/ │ ├── core/ # Core components: agents, memory, MCP interface │ │ └── src/muxi/core/ │ │ ├── agent/ # Agent implementation │ │ ├── memory/ # Memory subsystems │ │ ├── models/ # LLM provider interfaces │ │ ├── mcp/ # Model Context Protocol │ │ ├── orchestrator/ # Multi-agent coordination │ │ └── tools/ # Built-in tools │ │ │ ├── server/ # REST API and WebSocket server │ │ └── src/muxi/server/ │ │ ├── api/ # REST API endpoints │ │ ├── websocket/ # WebSocket implementation │ │ ├── auth/ # Authentication │ │ └── middleware/ # Server middleware │ │ │ ├── cli/ # Command-line interface │ │ └── src/muxi/cli/ │ │ ├── commands/ # CLI commands │ │ ├── terminal/ # Terminal UI │ │ └── mcp_generator/ # MCP server template generator │ │ │ ├── web/ # Web user interface │ │ ├── src/muxi/web/ │ │ │ ├── api/ # Web-specific API │ │ │ └── server/ # Web server │ │ └── frontend/ # React-based frontend │ │ │ └── muxi/ # Meta-package that integrates all components │ └── src/muxi/ │ ├── __init__.py # Main entry point │ └── client.py # Client implementation │ ├── examples/ # Example scripts and applications ├── docs/ # Documentation └── tests/ # Test suite for all components . ",
    "url": "/muxi/reference/package#package-organization",
    
    "relUrl": "/reference/package#package-organization"
  },"237": {
    "doc": "Package Structure",
    "title": "Package Descriptions",
    "content": "Core Package (muxi-core) . The foundation of the MUXI framework, containing all essential components: . | Agent: Implements the agent architecture and LLM integration | Memory: Buffer memory, long-term memory, and Memobase implementations | Models: Interfaces to LLM providers like OpenAI, Anthropic, and Ollama | MCP: The Model Context Protocol client implementation | Orchestrator: Multi-agent coordination system | Tools: Built-in tool implementations for common tasks | . Key features: . | Minimal dependencies for lightweight usage | Can be used without the server, CLI, or web UI | Provides programmatic API for integration into other applications | . Server Package (muxi-server) . Implements the server components for exposing MUXI functionality via APIs: . | API: REST API endpoints for agent management, chat, memory, etc. | WebSocket: Real-time, bidirectional communication | Authentication: JWT-based auth system | Middleware: Request validation, error handling, rate limiting | . Key features: . | FastAPI-based implementation | WebSocket support for streaming responses | Server-Sent Events (SSE) for one-way streaming | Comprehensive API for all MUXI functionality | . CLI Package (muxi-cli) . Command-line interface for interacting with MUXI: . | Commands: Implementation of CLI commands like chat, run, mcp | Terminal: Rich terminal UI for interactive sessions | MCP Generator: Utilities for creating new MCP server templates | . Key features: . | Rich terminal UI with syntax highlighting | Interactive chat mode with history | Command completion and help documentation | MCP server scaffolding | . Web Package (muxi-web) . Web-based interface for MUXI: . | API: Web-specific API endpoints | Server: Web server implementation | Frontend: React-based UI with streaming support | . Key features: . | Modern React-based interface | Real-time communication via WebSockets | Agent configuration UI | Chat history visualization | . Meta Package (muxi) . The main package that integrates all components: . | Provides a unified API for the entire framework | Handles package coordination and initialization | Simplifies installation and usage | . This is the recommended package for most users who want the full MUXI experience. ",
    "url": "/muxi/reference/package#package-descriptions",
    
    "relUrl": "/reference/package#package-descriptions"
  },"238": {
    "doc": "Package Structure",
    "title": "Import Structure",
    "content": "MUXI uses a consistent import structure across all packages: . # Core imports from muxi.core.agent import Agent from muxi.core.memory import BufferMemory, LongTermMemory from muxi.core.models.openai import OpenAIModel from muxi.core.mcp import MCPHandler from muxi.core.orchestrator import Orchestrator from muxi.core.tools.weather import WeatherTool # Server imports from muxi.server.api import create_app from muxi.server.websocket import WebSocketManager # CLI imports from muxi.cli.commands import chat_command # Meta-package imports (includes all of the above) from muxi import muxi # Main entry point . ",
    "url": "/muxi/reference/package#import-structure",
    
    "relUrl": "/reference/package#import-structure"
  },"239": {
    "doc": "Package Structure",
    "title": "Dependency Graph",
    "content": "The packages have the following dependency relationships: . muxi (meta-package) ├── muxi-core # No external package dependencies ├── muxi-server # Depends on muxi-core ├── muxi-cli # Depends on muxi-core └── muxi-web # Depends on muxi-core and muxi-server . This structure ensures that: . | muxi-core can be used independently without installing server, CLI, or web components | Each higher-level package only depends on what it needs | . ",
    "url": "/muxi/reference/package#dependency-graph",
    
    "relUrl": "/reference/package#dependency-graph"
  },"240": {
    "doc": "Package Structure",
    "title": "Installation Options",
    "content": "Users can install packages based on their needs: . # Full installation (recommended) pip install muxi # Core functionality only pip install muxi-core # Server functionality pip install muxi-server # CLI functionality pip install muxi-cli # Web UI pip install muxi-web # Development installation git clone https://github.com/yourusername/muxi-framework.git cd muxi-framework ./install_dev.sh . ",
    "url": "/muxi/reference/package#installation-options",
    
    "relUrl": "/reference/package#installation-options"
  },"241": {
    "doc": "Package Structure",
    "title": "Development Guidelines",
    "content": "When contributing to MUXI, consider these package-related guidelines: . | Respect Package Boundaries: Don’t create circular dependencies between packages | Minimize Dependencies: Each package should only depend on what it absolutely needs | Consistent Interfaces: Public APIs should be consistent across packages | Proper Re-exporting: The meta-package should re-export all important interfaces | Version Compatibility: Be mindful of version compatibility between packages | . ",
    "url": "/muxi/reference/package#development-guidelines",
    
    "relUrl": "/reference/package#development-guidelines"
  },"242": {
    "doc": "Package Structure",
    "title": "Testing Structure",
    "content": "Tests are organized to match the package structure: . tests/ ├── core/ # Tests for the core package ├── server/ # Tests for the server package ├── cli/ # Tests for the CLI package ├── web/ # Tests for the web package └── integration/ # Cross-package integration tests . Each package has its own test suite that can be run independently: . # Run core tests pytest tests/core # Run all tests pytest . ",
    "url": "/muxi/reference/package#testing-structure",
    
    "relUrl": "/reference/package#testing-structure"
  },"243": {
    "doc": "Package Structure",
    "title": "Related Resources",
    "content": ". | API Documentation - Detailed API reference | Configuration Options - Configuration parameters | Codebase Organization - Further details on code organization | . ",
    "url": "/muxi/reference/package#related-resources",
    
    "relUrl": "/reference/package#related-resources"
  },"244": {
    "doc": "Quick Start Guide",
    "title": "Quick Start Guide",
    "content": " ",
    "url": "/muxi/intro/quick-start",
    
    "relUrl": "/intro/quick-start"
  },"245": {
    "doc": "Quick Start Guide",
    "title": "What You’ll Learn",
    "content": ". | How to install MUXI | How to create agents using configuration files | How to build a simple multi-agent application | How to interact with agents and MCP servers | How to support multiple users | . ",
    "url": "/muxi/intro/quick-start#what-youll-learn",
    
    "relUrl": "/intro/quick-start#what-youll-learn"
  },"246": {
    "doc": "Quick Start Guide",
    "title": "Prerequisites",
    "content": ". | Python 3.10 or later | An OpenAI API key (for the examples in this guide) | Basic Python knowledge | . ",
    "url": "/muxi/intro/quick-start#prerequisites",
    
    "relUrl": "/intro/quick-start#prerequisites"
  },"247": {
    "doc": "Quick Start Guide",
    "title": "Installation",
    "content": "Install the MUXI Framework using pip: . pip install muxi . For development installations, you can clone the repository and install in development mode: . git clone https://github.com/yourusername/muxi-framework.git cd muxi-framework ./install_dev.sh . ",
    "url": "/muxi/intro/quick-start#installation",
    
    "relUrl": "/intro/quick-start#installation"
  },"248": {
    "doc": "Quick Start Guide",
    "title": "Set Up Environment Variables",
    "content": "Create a .env file with your API keys: . OPENAI_API_KEY=your-openai-key POSTGRES_DATABASE_URL=your-database-connection-string WEATHER_API_KEY=your-weather-api-key . ",
    "url": "/muxi/intro/quick-start#set-up-environment-variables",
    
    "relUrl": "/intro/quick-start#set-up-environment-variables"
  },"249": {
    "doc": "Quick Start Guide",
    "title": "Creating Your First Agent",
    "content": "The easiest way to get started with MUXI is to use declarative configuration files. These can be in YAML or JSON format. YAML Configuration Example . Create a file configs/muxi_config.yaml: . agents: - agent_id: weather_assistant description: \"Specialized in providing weather forecasts and current conditions.\" system_message: You are a helpful assistant that can check the weather. model: provider: openai api_key: \"${OPENAI_API_KEY}\" model: gpt-4o temperature: 0.7 mcp_servers: - name: weather_api url: http://localhost:5001 api_key: \"${WEATHER_API_KEY}\" - agent_id: finance_assistant description: \"Expert in financial analysis, investments, and market trends.\" system_message: You are a helpful finance assistant. model: provider: openai api_key: \"${OPENAI_API_KEY}\" model: gpt-4o temperature: 0.2 mcp_servers: - name: finance_api url: http://localhost:5002 api_key: \"${FINANCE_API_KEY}\" . JSON Configuration Example . Alternatively, create configs/muxi_config.json: . { \"agents\": [ { \"agent_id\": \"weather_assistant\", \"description\": \"Specialized in providing weather forecasts and current conditions.\", \"system_message\": \"You are a helpful assistant that can check the weather.\", \"model\": { \"provider\": \"openai\", \"api_key\": \"${OPENAI_API_KEY}\", \"model\": \"gpt-4o\", \"temperature\": 0.7 }, \"mcp_servers\": [ { \"name\": \"weather_api\", \"url\": \"http://localhost:5001\", \"api_key\": \"${WEATHER_API_KEY}\" } ] }, { \"agent_id\": \"finance_assistant\", \"description\": \"Expert in financial analysis, investments, and market trends.\", \"system_message\": \"You are a helpful finance assistant.\", \"model\": { \"provider\": \"openai\", \"api_key\": \"${OPENAI_API_KEY}\", \"model\": \"gpt-4o\", \"temperature\": 0.2 }, \"mcp_servers\": [ { \"name\": \"finance_api\", \"url\": \"http://localhost:5002\", \"api_key\": \"${FINANCE_API_KEY}\" } ] } ] } . ",
    "url": "/muxi/intro/quick-start#creating-your-first-agent",
    
    "relUrl": "/intro/quick-start#creating-your-first-agent"
  },"250": {
    "doc": "Quick Start Guide",
    "title": "Create a Multi-Agent Application",
    "content": "Create a new Python file with minimal code: . from dotenv import load_dotenv from muxi import muxi # Load environment variables load_dotenv() # Initialize MUXI with memory configuration app = muxi( buffer_memory=10, # Sets buffer window size to 10 long_term_memory=\"postgresql://user:pass@localhost/db\", # Enables long-term memory config_file=\"configs/muxi_config.yaml\" # Load agent configurations from file ) # Chat with a specific agent response = app.chat(\"What's the weather in New York?\", agent_name=\"weather_assistant\") print(response) # Let the orchestrator automatically select the appropriate agent response = app.chat(\"What's the current stock market trend?\") print(response) # Will be handled by the finance_assistant # Start the server app.run() . ",
    "url": "/muxi/intro/quick-start#create-a-multi-agent-application",
    
    "relUrl": "/intro/quick-start#create-a-multi-agent-application"
  },"251": {
    "doc": "Quick Start Guide",
    "title": "Automatic Agent Selection",
    "content": "When you add multiple agents to your application, MUXI will automatically route messages to the most appropriate agent based on their descriptions: . # Let the orchestrator automatically select the appropriate agent response = app.chat(\"What's the current stock market trend?\") print(response) # Will likely be handled by the finance_assistant response = app.chat(\"What's the weather in New York?\") print(response) # Will likely be handled by the weather_assistant . The routing system uses an LLM to analyze the message content and agent descriptions to determine the best match. ",
    "url": "/muxi/intro/quick-start#automatic-agent-selection",
    
    "relUrl": "/intro/quick-start#automatic-agent-selection"
  },"252": {
    "doc": "Quick Start Guide",
    "title": "Adding Context Memory",
    "content": "You can enhance your agents with context memory: . # Add context knowledge for the agent app.add_context_knowledge(\"geography.txt\", agent_id=\"weather_assistant\") # Add user-specific context memory app.add_user_context_memory( user_id=\"user123\", knowledge={\"name\": \"John\", \"location\": \"New York\"} ) . ",
    "url": "/muxi/intro/quick-start#adding-context-memory",
    
    "relUrl": "/intro/quick-start#adding-context-memory"
  },"253": {
    "doc": "Quick Start Guide",
    "title": "Multi-User Support",
    "content": "For multi-user applications: . # Initialize MUXI with multi-user memory support app = muxi( buffer_memory=10, long_term_memory=\"postgresql://user:pass@localhost/db\", # PostgreSQL recommended for multi-user config_file=\"configs/muxi_config.yaml\" ) # Chat with user-specific context response = app.chat( \"What's the weather in my city?\", agent_name=\"weather_assistant\", user_id=\"user123\" ) print(response) # Will use user123's location data # Another user with different context response = app.chat( \"What's the weather in my city?\", agent_name=\"weather_assistant\", user_id=\"user456\" ) print(response) # Will use user456's location data if available . ",
    "url": "/muxi/intro/quick-start#multi-user-support",
    
    "relUrl": "/intro/quick-start#multi-user-support"
  },"254": {
    "doc": "Quick Start Guide",
    "title": "Using the CLI",
    "content": "MUXI provides a convenient command-line interface: . # Start a chat session with the default agent muxi chat # Send a one-off message muxi send \"What is the capital of France?\" # Run the server muxi run . ",
    "url": "/muxi/intro/quick-start#using-the-cli",
    
    "relUrl": "/intro/quick-start#using-the-cli"
  },"255": {
    "doc": "Quick Start Guide",
    "title": "Using the REST API",
    "content": "After starting the server: . muxi run . You can interact with the API: . # Send a message to an agent curl -X POST http://localhost:5050/agents/weather_assistant/messages \\ -H \"Content-Type: application/json\" \\ -d '{\"content\": \"What is the capital of France?\"}' . ",
    "url": "/muxi/intro/quick-start#using-the-rest-api",
    
    "relUrl": "/intro/quick-start#using-the-rest-api"
  },"256": {
    "doc": "Quick Start Guide",
    "title": "Using WebSockets",
    "content": "For real-time applications, you can use the WebSocket interface: . import asyncio import websockets import json async def chat_with_agent(): async with websockets.connect(\"ws://localhost:5050/ws\") as websocket: # Send a message await websocket.send(json.dumps({ \"type\": \"message\", \"content\": \"Tell me about the weather in Paris\", \"agent\": \"weather_assistant\" })) # Receive streaming response while True: response = await websocket.recv() response_data = json.loads(response) if response_data[\"type\"] == \"chunk\": # Process streaming chunk print(response_data[\"content\"], end=\"\") elif response_data[\"type\"] == \"done\": # Response complete break asyncio.run(chat_with_agent()) . ",
    "url": "/muxi/intro/quick-start#using-websockets",
    
    "relUrl": "/intro/quick-start#using-websockets"
  },"257": {
    "doc": "Quick Start Guide",
    "title": "Using MCP Servers",
    "content": "MCP servers extend agent capabilities by providing specialized functionality. To use them: . | Add them to your agent configuration as shown in the examples above | The agent will automatically use the appropriate server based on the query | . Creating Your Own MCP Server . You can create your own MCP server to extend agent capabilities: . # Generate a new MCP server template muxi mcp create my_custom_server cd my_custom_server # Install dependencies and start the server pip install -r requirements.txt python server.py . Once your MCP server is running, add it to your agent configuration: . mcp_servers: - name: custom_server url: http://localhost:5010 api_key: \"${CUSTOM_API_KEY}\" . ",
    "url": "/muxi/intro/quick-start#using-mcp-servers",
    
    "relUrl": "/intro/quick-start#using-mcp-servers"
  },"258": {
    "doc": "Quick Start Guide",
    "title": "Advanced Topics",
    "content": "For more detailed information: . | Creating MCP Servers | Multi-Agent Systems | Memory Systems | . ",
    "url": "/muxi/intro/quick-start#advanced-topics",
    
    "relUrl": "/intro/quick-start#advanced-topics"
  },"259": {
    "doc": "Quick Start Guide",
    "title": "What’s Next",
    "content": ". | Architecture - Understand the framework’s architecture | Simple Agents - Learn more about creating agents | Server Deployment - Deploy your application as a server | . ",
    "url": "/muxi/intro/quick-start#whats-next",
    
    "relUrl": "/intro/quick-start#whats-next"
  },"260": {
    "doc": "Release Notes",
    "title": "MUXI Framework Release Notes",
    "content": "This document provides a summary of changes, new features, and fixes in each release of the MUXI Framework. ",
    "url": "/muxi/release-notes#muxi-framework-release-notes",
    
    "relUrl": "/release-notes#muxi-framework-release-notes"
  },"261": {
    "doc": "Release Notes",
    "title": "Upcoming Releases",
    "content": "v0.5.0 (Planned Q2 2025) - Enhanced Communication and Advanced Features . The MUXI Framework v0.5.0 will focus on advanced communication capabilities, expanded LLM provider support, and performance optimizations. Major Features . | Advanced Agent-to-Agent (A2A) Communication: . | Capability discovery mechanism | Task delegation between agents | Context sharing with proper isolation | Conversation lifecycle management | External agent integration | Security and authentication | . | Multi-Modal Support: . | File attachment support in WebSocket API | Image processing capabilities | Document handling (PDF, Office documents) | Audio processing integration | . | MCP Server Enhancements: . | SSE-based MCP server implementation | Automatic tool discovery from agent capabilities | NPX bridge package for non-SSE clients | Streaming response handling | Authentication shared with REST API | . | LLM Provider Expansion: . | Anthropic LLM provider implementation | Gemini LLM provider implementation | Grok LLM provider implementation | Support for local models (Llama, Mistral, DeepSeek) | Model router for fallback and cost optimization | . | . v0.4.0 (Planned Q1 2025) - API-First Framework . The MUXI Framework v0.4.0 will introduce comprehensive API implementations as outlined in the API specification document, with a focus on making the framework accessible through multiple interfaces. Major Features . | REST API Implementation: . | Standard REST API endpoints (agent, conversation, memory management) | Authentication with API keys | Streaming support for chat endpoints with SSE | Proper error handling with standardized format | API versioning support | Rate limiting and throttling | API documentation using OpenAPI/Swagger | . | WebSocket API Implementation: . | WebSocket protocol for real-time communication | Support for multi-modal messages (text, images, audio) | Proper error handling and recovery mechanisms | Reconnection logic with exponential backoff | Support for attachments as specified in API documentation | . | MCP Server Implementation: . | HTTP+SSE-based MCP server implementation | Simplified credential management | Authentication that integrates with API keys | Tool discovery mechanism | Robust error handling and recovery | . | CLI Enhancements: . | Support for all API operations | Improved user experience with better formatting | Configuration management commands | Multi-modal interaction support | . | Web UI Development: . | Responsive design for mobile and desktop | Real-time updates using WebSocket | Agent management dashboard | Configuration interface | . | . ",
    "url": "/muxi/release-notes#upcoming-releases",
    
    "relUrl": "/release-notes#upcoming-releases"
  },"262": {
    "doc": "Release Notes",
    "title": "Current Release",
    "content": "v0.3.0 (March 2025) - Context Knowledge &amp; Memory Modernization . The MUXI Framework v0.3.0 brought significant improvements to knowledge capabilities, enhancing agents with specialized context knowledge. It also included a major architectural change in how memory is managed throughout the framework. Major Features . | Memory Architecture Migration: . | Breaking Change: Moved memory management from agent level to orchestrator level | Consolidated memory initialization in the orchestrator constructor | Updated configuration format to specify memory at the top level, not per agent | Removed setup_memory() methods, memory is now provided during initialization | Memory is now shared efficiently between agents | Simplified multi-user memory management | Significantly reduced memory duplication and improved performance | Enabled more complex memory sharing patterns between agents | . | Agent-Level Knowledge Base: . | File-based knowledge sources with automatic embedding generation | Efficient in-memory vector storage using FAISS | Persistent caching of embeddings for cost optimization | Dynamic embedding dimension detection based on the agent’s model | . | Enhanced Knowledge API: . | Add and remove knowledge sources programmatically | Search knowledge with relevance controls | List and manage knowledge sources | . | Declarative Knowledge Configuration: . | Specify file paths and descriptions | Automatic loading and embedding on agent initialization | . | MCP Server Enhancements: . | Made credentials optional for MCP servers | Better documentation on MCP server configuration | Updated examples to demonstrate credential-optional usage patterns | . | . v0.2.0 (February 2025) - Architecture Migration . The MUXI Framework v0.2.0 marked a significant milestone with the completion of our architectural migration to a modular, package-based structure. Major Features . | Modular Package Structure: . | Reorganized from a monolithic structure to a modular, package-based architecture | Changed imports from src.* to muxi.core.*, muxi.cli.*, etc. | Created separately installable packages for core functionality, CLI, server, and web interface | Established well-defined interfaces between subsystems | . | . v0.1.0 (January 2025) - Foundation Release . The initial release of the MUXI Framework established the core architecture and essential functionality. Major Features . | Core Agent System: . | Basic agent functionality with LLM integration | System message handling | Message processing pipeline | . | Memory Systems: . | Buffer memory using FAISS for short-term context | Long-term memory using PostgreSQL with pgvector | Context memory for user-specific structured information | . | MCP Integration: . | MCP handler for communication with external services | Multiple transport types (HTTP+SSE, Command-line) | Tool call processing and response handling | . | Orchestrator: . | Multi-agent management | Intelligent message routing | Agent description handling | . | Command Line Interface: . | Terminal-based user interface | Agent interaction commands | Server management | . | . ",
    "url": "/muxi/release-notes#current-release",
    
    "relUrl": "/release-notes#current-release"
  },"263": {
    "doc": "Release Notes",
    "title": "Release Notes",
    "content": " ",
    "url": "/muxi/release-notes",
    
    "relUrl": "/release-notes"
  },"264": {
    "doc": "Roadmap",
    "title": "MUXI Framework Roadmap",
    "content": "Note: This roadmap is subject to change based on community feedback and project priorities. ",
    "url": "/muxi/intro/roadmap.html#muxi-framework-roadmap",
    
    "relUrl": "/intro/roadmap.html#muxi-framework-roadmap"
  },"265": {
    "doc": "Roadmap",
    "title": "Current State",
    "content": "MUXI Framework is currently in active development. The core feature roadmap is outlined below. ",
    "url": "/muxi/intro/roadmap.html#current-state",
    
    "relUrl": "/intro/roadmap.html#current-state"
  },"266": {
    "doc": "Roadmap",
    "title": "Version 0.1.0 (Released)",
    "content": ". | ✅ Core agent system | ✅ Basic memory systems (short-term buffer) | ✅ OpenAI integration | ✅ Command line interface | ✅ MCP Client integration (HTTP+SSE) | ✅ MCP Client integration (Command) | . ",
    "url": "/muxi/intro/roadmap.html#version-010-released",
    
    "relUrl": "/intro/roadmap.html#version-010-released"
  },"267": {
    "doc": "Roadmap",
    "title": "Version 0.2.0 (Released)",
    "content": ". | ✅ Modular package structure | ✅ Improved import paths | ✅ Enhanced CLI | ✅ Stability improvements | . ",
    "url": "/muxi/intro/roadmap.html#version-020-released",
    
    "relUrl": "/intro/roadmap.html#version-020-released"
  },"268": {
    "doc": "Roadmap",
    "title": "Version 0.3.0 (Released)",
    "content": ". | ✅ Memory architecture migration (agent memory ➔ orchestrator memory) [Breaking Change] . | ✅ Orchestrator-level memory management | ✅ Memory sharing between agents | ✅ Simplified configuration and usage | . | ✅ Agent-level knowledge base | ✅ Enhanced knowledge API | ✅ Long-term memory systems . | ✅ PostgreSQL with pgvector support | ✅ SQLite with sqlite-vec support | . | ✅ Multi-user memory support | ✅ User context memory | ✅ MCP server capabilities . | ✅ SSE-based server endpoint for MCP host integration | ✅ Tool discovery from agent capabilities | ✅ Authentication shared with REST API | . | . ",
    "url": "/muxi/intro/roadmap.html#version-030-released",
    
    "relUrl": "/intro/roadmap.html#version-030-released"
  },"269": {
    "doc": "Roadmap",
    "title": "Version 0.4.0 (In Development)",
    "content": ". | 🔄 API Implementations . | 🔄 REST API for agent interactions | 🔄 WebSocket API for streaming responses | . | 🔄 CLI Enhancements . | 🔄 Interactive mode improvements | 🔄 Configuration management | . | 🔄 Web UI (Basic implementation) . | 🔄 Chat interface | 🔄 Agent management | . | . ",
    "url": "/muxi/intro/roadmap.html#version-040-in-development",
    
    "relUrl": "/intro/roadmap.html#version-040-in-development"
  },"270": {
    "doc": "Roadmap",
    "title": "Version 0.5.0 (Planned)",
    "content": ". | 📅 A2A (Agent-to-Agent) Communication . | 📅 Structured message format | 📅 Capability registration and discovery | 📅 Task delegation | 📅 Context sharing | 📅 Security and authentication | . | 📅 Multi-modal support . | 📅 Image understanding | 📅 Audio processing | . | 📅 MCP Server Enhancements . | 📅 Non-SSE client compatibility bridge | 📅 Enhanced security | . | 📅 LLM Provider Expansion . | 📅 Claude/Anthropic | 📅 LLama models | 📅 Google Gemini | 📅 Local models | . | . ",
    "url": "/muxi/intro/roadmap.html#version-050-planned",
    
    "relUrl": "/intro/roadmap.html#version-050-planned"
  },"271": {
    "doc": "Roadmap",
    "title": "Future Roadmap",
    "content": ". | 📅 Language-Specific SDKs . | 📅 TypeScript/JavaScript | 📅 Go | 📅 Python | 📅 Java/Kotlin | . | 📅 Enhanced tools and capabilities . | 📅 Advanced task delegation | 📅 Autonomous planning | 📅 Advanced RAG techniques | . | 📅 Integration with external systems . | 📅 Database connectors | 📅 Web API integrations | 📅 Enterprise systems | . | 📅 Advanced Multi-Agent Systems . | 📅 Agent swarms | 📅 Custom agent roles | 📅 Hierarchical agent structures | 📅 Collaborative problem-solving | . | 📅 Observability and monitoring . | 📅 Telemetry | 📅 Performance metrics | 📅 Debugging tools | . | 📅 Community plugins . | 📅 Plugin architecture | 📅 Plugin marketplace | 📅 Plugin management | . | . ",
    "url": "/muxi/intro/roadmap.html#future-roadmap",
    
    "relUrl": "/intro/roadmap.html#future-roadmap"
  },"272": {
    "doc": "Roadmap",
    "title": "Legend",
    "content": ". | ✅ Completed | 🔄 In Progress | 📅 Planned | . ",
    "url": "/muxi/intro/roadmap.html#legend",
    
    "relUrl": "/intro/roadmap.html#legend"
  },"273": {
    "doc": "Roadmap",
    "title": "Roadmap",
    "content": " ",
    "url": "/muxi/intro/roadmap.html",
    
    "relUrl": "/intro/roadmap.html"
  },"274": {
    "doc": "Project Roadmap",
    "title": "MUXI Framework Roadmap",
    "content": "This document outlines the development roadmap for the MUXI Framework, including completed releases, current development status, and planned future enhancements. The roadmap is organized by version milestones and development phases. ",
    "url": "/muxi/roadmap#muxi-framework-roadmap",
    
    "relUrl": "/roadmap#muxi-framework-roadmap"
  },"275": {
    "doc": "Project Roadmap",
    "title": "Overview",
    "content": "The MUXI Framework is being developed in a phased approach, with each phase building upon the previous one to create a comprehensive framework for AI agent development. Our development philosophy emphasizes: . | Solid Foundations: Building reliable core components before adding advanced features | API-First Design: Designing with API compatibility and extensibility in mind | Modular Architecture: Creating clean, loosely-coupled subsystems | Progressive Enhancement: Adding capabilities iteratively based on user feedback | . ",
    "url": "/muxi/roadmap#overview",
    
    "relUrl": "/roadmap#overview"
  },"276": {
    "doc": "Project Roadmap",
    "title": "Development Phases",
    "content": "Our overall development is structured into distinct phases: . Phase 1: Core Framework (v0.1.0 - v0.3.0) ✅ . This phase established the foundational architecture and core components of the framework: . | Basic agent functionality with LLM integration | Memory systems (buffer and long-term) | MCP client integration for external tools | Multi-agent support with orchestration | Configuration system | Basic CLI interface | Basic REST API foundations | . Phase 2: Advanced Features (v0.4.0) 🛠️ . This phase focuses on enhancing the framework with advanced communication capabilities: . | Complete REST API implementation | Complete WebSocket API implementation | Enhanced CLI interface | Web UI development | Basic MCP server interface implementation | Initial Agent-to-Agent (A2A) communication protocol | Additional LLM providers | Enhanced documentation | Basic multi-modal support | . Phase 3: Scaling &amp; Monitoring (v0.5.0) 📅 . This phase will prepare the framework for production deployment at scale: . | Advanced A2A communication with capability discovery | Vector database optimizations and additional integrations | Full MCP Server interface with streaming response support | Comprehensive testing and documentation | Deployment solutions and containerization | Language-specific SDKs | Full multi-modal support | Performance monitoring and metrics | . … . Phase 10: Enterprise Ready (v1.0.0) 🔮 . This phase will complete the framework’s feature set for enterprise use: . | Comprehensive security features | Advanced deployment options | Extended LLM provider support | Full production readiness | Complete documentation and examples | Stable, backward-compatible API | . ",
    "url": "/muxi/roadmap#development-phases",
    
    "relUrl": "/roadmap#development-phases"
  },"277": {
    "doc": "Project Roadmap",
    "title": "Completed Releases",
    "content": "v0.3.0 (March 2025) - Context Knowledge Expansion . The MUXI Framework v0.3.0 brought significant improvements to knowledge capabilities, enhancing agents with specialized context knowledge and improved contextual awareness. Major Features . | Agent-Level Knowledge Base: . | File-based knowledge sources with automatic embedding generation | Efficient in-memory vector storage using FAISS | Persistent caching of embeddings for cost optimization | Dynamic embedding dimension detection based on the agent’s model | . | Enhanced Knowledge API: . | Add and remove knowledge sources programmatically | Search knowledge with relevance controls | List and manage knowledge sources | . | Declarative Knowledge Configuration: . | Specify file paths and descriptions | Automatic loading and embedding on agent initialization | . | MCP Server Enhancements: . | Made credentials optional for MCP servers | Better documentation on MCP server configuration | Updated examples to demonstrate credential-optional usage patterns | . | . v0.2.0 (March 2025) - Architecture Migration . The MUXI Framework v0.2.0 marked a significant milestone with the completion of our architectural migration to a modular, package-based structure. Major Features . | Modular Package Structure: . | Reorganized from a monolithic structure to a modular, package-based architecture | Changed imports from src.* to muxi.core.*, muxi.cli.*, etc. | Created separately installable packages for core functionality, CLI, server, and web interface | Established well-defined interfaces between subsystems | . | . v0.1.0 (January 2025) - Foundation Release . The initial release of the MUXI Framework established the core architecture and essential functionality. Major Features . | Core Agent System: . | Basic agent functionality with LLM integration | System message handling | Message processing pipeline | . | Memory Systems: . | Buffer memory using FAISS for short-term context | Long-term memory using PostgreSQL with pgvector | Context memory for user-specific structured information | . | MCP Integration: . | MCP handler for communication with external services | Multiple transport types (HTTP+SSE, Command-line) | Tool call processing and response handling | . | Orchestrator: . | Multi-agent management | Intelligent message routing | Agent description handling | . | Command Line Interface: . | Terminal-based user interface | Agent interaction commands | Server management | . | . ",
    "url": "/muxi/roadmap#completed-releases",
    
    "relUrl": "/roadmap#completed-releases"
  },"278": {
    "doc": "Project Roadmap",
    "title": "Current Development (v0.4.0)",
    "content": "The MUXI Framework v0.4.0 will introduce several advanced features with a focus on comprehensive API implementation and enhanced communication capabilities, reflecting our updated development priorities. Key Features in Development . | REST API &amp; MCP Server Implementation: . | Standard REST API endpoints (agent, conversation, memory management) | Authentication with API keys | Streaming support for chat endpoints with SSE | Proper error handling with standardized format | API versioning support | Rate limiting and throttling | API documentation using OpenAPI/Swagger | SSE-based MCP server implementation | . | WebSocket API Implementation: . | WebSocket protocol for real-time communication | Support for multi-modal messages (text, images, audio) | Proper error handling and recovery mechanisms | Reconnection logic with exponential backoff | Support for attachments as specified in api.md | . | CLI Interfaces &amp; Web UI: . | Enhanced CLI interface with support for all API operations | Web interface with responsive design for mobile and desktop | Real-time updates using WebSocket | Multi-modal interaction support | User-friendly configuration interface | . | Agent-to-Agent (A2A) Communication: . | Standardized message format for inter-agent communication | Basic agent capability registration and discovery | Task delegation between agents | Context sharing with proper isolation | Security and authentication foundation | . | . ",
    "url": "/muxi/roadmap#current-development-v040",
    
    "relUrl": "/roadmap#current-development-v040"
  },"279": {
    "doc": "Project Roadmap",
    "title": "Upcoming Releases",
    "content": "v0.5.0 (Planned Q2 2025) - Scaling &amp; Integration . The MUXI Framework v0.5.0 will focus on advanced integration capabilities, vector database enhancements, and expanding LLM provider support. Planned Features . | Vector Database Enhancements: . | Optimized vector operations for improved performance | Support for additional vector databases (e.g., Milvus, Qdrant) | Migration tools for transferring between database types | Performance benchmarks for different database options | Support for vector database clustering and sharding | . | LLM Provider Expansion: . | Anthropic LLM provider implementation | Gemini LLM provider implementation | Grok LLM provider implementation | Support for local models (Llama, Mistral, DeepSeek) | Model router for fallback and cost optimization | . | Testing and Documentation: . | Comprehensive unit and integration tests | Performance benchmarks for API endpoints | Complete API and CLI documentation | User guides for advanced use cases | Example projects showcasing API usage | . | Language-Specific SDKs: . | TypeScript/JavaScript SDK for web and Node.js | Go SDK for backend integration | Initial SDKs for Java/Kotlin, Rust, and C#/.NET | SDK Development Tools for consistent interfaces | . | . v0.6.0 (Planned Q2 2025) - Multi-Modal &amp; Deployment . The v0.6.0 release will focus on enhancing multi-modal capabilities and deployment solutions. Planned Features . | Multi-Modal Capabilities: . | Document processing (PDF, Office documents, OCR) | Image attachment support and preprocessing pipeline | Audio file handling with speech-to-text integration | Streaming audio capabilities | Vision-capable model integrations | . | Deployment &amp; Package Distribution: . | Docker containerization and Kubernetes deployment | Cloud deployment guides (AWS, GCP, Azure) | Monitoring and logging integration | CI/CD workflows with GitHub Actions | SQLite deployment guides for serverless environments | . | . … . v1.0.0 (Planned Q3 2025) - Stable Release . The v1.0.0 release will represent the first stable, production-ready version of the MUXI Framework with comprehensive security enhancements. Planned Features . | Security Enhancements: . | Enhanced API security (rate limiting, input validation) | Advanced authentication methods (OAuth, OIDC) | Role-based access control | Data encryption at rest and in transit | Security auditing and vulnerability scanning | Privacy controls and data protection mechanisms | . | API Stabilization: . | Complete API documentation | Backward compatibility guarantees | Standardized error handling across all components | . | Extended Model Support: . | Support for all major LLM providers | Robust local model integration | Model fallback and routing options | Performance optimization for different model types | . | Developer Experience: . | Comprehensive documentation | Interactive tutorials | Extensive example projects | Plugin/extension system | . | . ",
    "url": "/muxi/roadmap#upcoming-releases",
    
    "relUrl": "/roadmap#upcoming-releases"
  },"280": {
    "doc": "Project Roadmap",
    "title": "Feature Completion Status",
    "content": "| Feature | Status | Target Version | . | Core Agent System | ✅ Complete | v0.1.0 | . | Memory Systems | ✅ Complete | v0.1.0 | . | MCP Client Integration | ✅ Complete | v0.1.0 | . | Orchestrator | ✅ Complete | v0.1.0 | . | Basic CLI Interface | ✅ Complete | v0.1.0 | . | Knowledge Base | ✅ Complete | v0.3.0 | . | SQLite Vector Support | ✅ Complete | v0.3.0 | . | PostgreSQL Vector Support | ✅ Complete | v0.3.0 | . | Multi-user Support | ✅ Complete | v0.3.0 | . | Modular Package Architecture | ✅ Complete | v0.2.0 | . | REST API Implementation | 🛠️ In Development | v0.4.0 | . | WebSocket API Implementation | 🛠️ In Development | v0.4.0 | . | Enhanced CLI Interface | 🛠️ In Development | v0.4.0 | . | Web UI Development | 🛠️ In Development | v0.4.0 | . | MCP Server Implementation | 🛠️ In Development | v0.4.0 | . | A2A Communication | 🛠️ In Development | v0.4.0 | . | Additional LLM Providers | 🛠️ In Development | v0.4.0 | . | Vector Database Enhancements | 📅 Planned | v0.5.0 | . | Testing &amp; Documentation | 📅 Planned | v0.5.0 | . | Language SDKs (TS/JS, Go, etc.) | 📅 Planned | v0.5.0 | . | Multi-Modal Support | 📅 Planned | v0.6.0 | . | Deployment Solutions | 📅 Planned | v0.6.0 | . | Security Enhancements | 🔮 Future | v1.0.0 | . | API Stabilization | 🔮 Future | v1.0.0 | . | Extended Model Support | 🔮 Future | v1.0.0 | . ",
    "url": "/muxi/roadmap#feature-completion-status",
    
    "relUrl": "/roadmap#feature-completion-status"
  },"281": {
    "doc": "Project Roadmap",
    "title": "Long-Term Vision",
    "content": "Beyond the current roadmap, the MUXI Framework has several exciting directions for future development: . | Autonomous Agent Collectives: Advanced multi-agent systems that can work together autonomously | Agent Specialization Marketplace: Library of pre-trained specialized agents for different domains | Enhanced Learning Capabilities: Agents that improve over time through user feedback and interactions | Hardware Integration: Support for robotics and IoT device control through standardized interfaces | Enterprise IAM Integration: Integration with enterprise identity and access management systems | Cross-Platform Support: Mobile and edge device deployment options | . ",
    "url": "/muxi/roadmap#long-term-vision",
    
    "relUrl": "/roadmap#long-term-vision"
  },"282": {
    "doc": "Project Roadmap",
    "title": "Contributing",
    "content": "We welcome contributions to the MUXI Framework! Please see our contribution guidelines for details on how to get involved with the development process. ",
    "url": "/muxi/roadmap#contributing",
    
    "relUrl": "/roadmap#contributing"
  },"283": {
    "doc": "Project Roadmap",
    "title": "Project Roadmap",
    "content": " ",
    "url": "/muxi/roadmap",
    
    "relUrl": "/roadmap"
  },"284": {
    "doc": "Simple Agent",
    "title": "Creating a Simple Agent",
    "content": "This guide walks you through creating a basic agent using the MUXI Framework. ",
    "url": "/muxi/agents/simple#creating-a-simple-agent",
    
    "relUrl": "/agents/simple#creating-a-simple-agent"
  },"285": {
    "doc": "Simple Agent",
    "title": "Basic Agent Creation",
    "content": "Declarative way . # configs/assistant.yaml --- agent_id: assistant description: A helpful assistant that answers questions and performs tasks. model: provider: openai api_key: \"${OPENAI_API_KEY}\" model: gpt-4o system_message: You are a helpful AI assistant. # app.py from muxi import muxi from dotenv import load_dotenv # Load environment variables load_dotenv() # Initialize MUXI app = muxi() # Add an agent from a configuration file app.add_agent(\"assistant\", \"configs/assistant.yaml\") # Chat with the agent response = await app.chat(\"Hello, who are you?\") print(response) . Programmatic way . import os from muxi.core.orchestrator import Orchestrator from muxi.core.models.openai import OpenAIModel # Initialize the orchestrator orchestrator = Orchestrator() # Create an OpenAI model model = OpenAIModel( api_key=os.getenv(\"OPENAI_API_KEY\"), model=\"gpt-4o\" ) # Create an agent orchestrator.create_agent( agent_id=\"assistant\", description=\"A helpful assistant that answers questions and performs tasks.\", model=model, system_message=\"You are a helpful AI assistant.\" ) # Chat with the agent response = orchestrator.chat(\"Hello, who are you?\") print(response) . ",
    "url": "/muxi/agents/simple#basic-agent-creation",
    
    "relUrl": "/agents/simple#basic-agent-creation"
  },"286": {
    "doc": "Simple Agent",
    "title": "Customizing Agent Settings",
    "content": "Declarative way . --- agent_id: creative_writer description: A creative assistant that can help with writing and generating creative content. model: provider: openai api_key: \"${OPENAI_API_KEY}\" model: gpt-4o temperature: 0.8 top_p: 0.9 max_tokens: 1000 system_message: You are a creative assistant specializing in fiction writing. Help users craft stories, characters, and engaging narratives. Programmatic way . # ... # Create a model with custom parameters model = OpenAIModel( api_key=os.getenv(\"OPENAI_API_KEY\"), model=\"gpt-4o\", temperature=0.8, top_p=0.9, max_tokens=1000 ) # Create a creative agent orchestrator.create_agent( agent_id=\"creative_writer\", description=\"...\", model=model, system_message=\"...\" ) # ... ",
    "url": "/muxi/agents/simple#customizing-agent-settings",
    
    "relUrl": "/agents/simple#customizing-agent-settings"
  },"287": {
    "doc": "Simple Agent",
    "title": "Using Different Model Providers",
    "content": "MUXI supports multiple model providers including OpenAI, Anthropic, Google, and more. Anthropic Agent Example . Declarative way . --- agent_id: claude description: An intelligent assistant powered by Claude. model: provider: anthropic api_key: \"${ANTHROPIC_API_KEY}\" model: claude-3-opus-20240229 system_message: You are Claude, a helpful AI assistant created by Anthropic. Programmatic way . # Create an Anthropic model model = AnthropicModel( api_key=os.getenv(\"ANTHROPIC_API_KEY\"), model=\"claude-3-opus-20240229\" ) # Create a Claude agent orchestrator.create_agent( agent_id=\"claude\", description=\"...\", model=model, system_message=\"...\" ) . Google Agent Example . Declarative way . --- agent_id: gemini description: An intelligent assistant powered by Google's Gemini model. model: provider: google api_key: \"${GOOGLE_API_KEY}\" model: gemini-1.5-pro system_message: You are Gemini, a helpful AI assistant created by Google. Programmatic way . # Create a Google model model = GoogleModel( api_key=os.getenv(\"GOOGLE_API_KEY\"), model=\"gemini-1.5-pro\" ) # Create a Gemini agent orchestrator.create_agent( agent_id=\"gemini\", description=\"...\", model=model, system_message=\"...\" ) . ",
    "url": "/muxi/agents/simple#using-different-model-providers",
    
    "relUrl": "/agents/simple#using-different-model-providers"
  },"288": {
    "doc": "Simple Agent",
    "title": "Azure OpenAI Support",
    "content": "MUXI also supports Azure OpenAI services: . Declarative way . --- agent_id: azure_assistant description: A helpful assistant using Azure-hosted OpenAI models. model: provider: azure_openai api_key: \"${AZURE_OPENAI_API_KEY}\" api_version: 2023-12-01-preview api_base: \"${AZURE_OPENAI_ENDPOINT}\" deployment_name: gpt-4 system_message: You are a helpful AI assistant running on Azure infrastructure. Programmatic way . # Create an Azure OpenAI model model = AzureOpenAIModel( api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"), api_version=\"2023-12-01-preview\", api_base=os.getenv(\"AZURE_OPENAI_ENDPOINT\"), deployment_name=\"gpt-4\" ) # Create an Azure agent orchestrator.create_agent( agent_id=\"azure_assistant\", description=\"...\", model=model, system_message=\"...\" ) . ",
    "url": "/muxi/agents/simple#azure-openai-support",
    
    "relUrl": "/agents/simple#azure-openai-support"
  },"289": {
    "doc": "Simple Agent",
    "title": "Local Models",
    "content": "MUXI supports running models locally using the local provider: . Declarative way . --- agent_id: local_assistant description: A locally-hosted AI assistant running on your own hardware. model: provider: local model_path: \"/path/to/local/model\" model_type: llama2 context_window: 4096 system_message: You are a locally-hosted AI assistant. Programmatic way . # Create a local model model = LocalModel( model_path=\"/path/to/local/model\", model_type=\"llama2\", context_window=4096 ) # Create a local agent orchestrator.create_agent( agent_id=\"local_assistant\", description=\"...\", model=model, system_message=\"...\" ) . ",
    "url": "/muxi/agents/simple#local-models",
    
    "relUrl": "/agents/simple#local-models"
  },"290": {
    "doc": "Simple Agent",
    "title": "Next Steps",
    "content": "Now that you’ve created a simple agent, you can: . | Learn how to configure agent settings in detail - see Agent Configuration | Add memory capabilities to your agent - see Adding Memory | Create multi-agent systems - see Multi-Agent Systems | . ",
    "url": "/muxi/agents/simple#next-steps",
    
    "relUrl": "/agents/simple#next-steps"
  },"291": {
    "doc": "Simple Agent",
    "title": "Troubleshooting",
    "content": "Common Issues . | API Key Issues: If you receive authentication errors, check that your API key is correct and properly set. | Model Availability: Ensure you have access to the model you’re trying to use (e.g., GPT-4o might require special access). | Rate Limiting: If you encounter rate limiting, consider adding delays between requests or using a different API key. | . Getting Help . If you run into issues, check the GitHub Issues or create a new issue with detailed information about your problem. ",
    "url": "/muxi/agents/simple#troubleshooting",
    
    "relUrl": "/agents/simple#troubleshooting"
  },"292": {
    "doc": "Simple Agent",
    "title": "Simple Agent",
    "content": " ",
    "url": "/muxi/agents/simple",
    
    "relUrl": "/agents/simple"
  },"293": {
    "doc": "Why MUXI?",
    "title": "Why MUXI?",
    "content": " ",
    "url": "/muxi/intro/why-muxi",
    
    "relUrl": "/intro/why-muxi"
  },"294": {
    "doc": "Why MUXI?",
    "title": "What You’ll Learn",
    "content": ". | The advantages of MUXI compared to other frameworks | How MUXI simplifies AI agent development | Where MUXI excels and what problems it best solves | Why you might choose MUXI for your next project | . ",
    "url": "/muxi/intro/why-muxi#what-youll-learn",
    
    "relUrl": "/intro/why-muxi#what-youll-learn"
  },"295": {
    "doc": "Why MUXI?",
    "title": "Prerequisites",
    "content": ". | Basic understanding of AI agent frameworks (optional) | . ",
    "url": "/muxi/intro/why-muxi#prerequisites",
    
    "relUrl": "/intro/why-muxi#prerequisites"
  },"296": {
    "doc": "Why MUXI?",
    "title": "The AI Agent Framework Landscape",
    "content": "The landscape of AI agent frameworks is becoming increasingly crowded. There are many options available for building LLM-powered applications. With so many choices, why should you consider MUXI? . ",
    "url": "/muxi/intro/why-muxi#the-ai-agent-framework-landscape",
    
    "relUrl": "/intro/why-muxi#the-ai-agent-framework-landscape"
  },"297": {
    "doc": "Why MUXI?",
    "title": "MUXI’s Core Advantages",
    "content": "1. Simplicity Without Sacrifice . The Challenge: Many frameworks require complex manual implementation and management of various components. MUXI’s Solution: MUXI handles these complexities automatically: . # Traditional approach (pseudo-code) from other_framework.text_splitter import TextSplitter from other_framework.embeddings import EmbeddingGenerator from other_framework.vector_store import VectorDatabase from other_framework.llm import LanguageModel from other_framework.memory import ConversationMemory # Manual text splitting splitter = TextSplitter(chunk_size=1000, chunk_overlap=100) chunks = splitter.split_documents(documents) # Manual embedding creation embedding_generator = EmbeddingGenerator(api_key=\"YOUR_API_KEY\") embeddings = embedding_generator.generate(chunks) vector_db = VectorDatabase.create(embeddings) # Manual memory setup memory = ConversationMemory(history_key=\"chat_history\", return_as_messages=True) # Manual chain setup llm = LanguageModel(model_name=\"large-model\", api_key=\"YOUR_API_KEY\") retriever = vector_db.as_retriever(search_type=\"similarity\") chain = QueryChain.from_components( llm=llm, retriever=retriever, memory=memory ) response = chain.run(query=\"What is the capital of France?\") . # MUXI approach from muxi.core.agent import Agent from muxi.core.models.openai import OpenAIModel # Create an agent - memory and embeddings are handled automatically agent = Agent( model=OpenAIModel(\"gpt-4o\"), system_message=\"You are a helpful assistant.\" ) # Simple conversation with memory automatically managed response = agent.chat(\"What is the capital of France?\") . 2. Truly Multi-Agent by Design . The Challenge: Coordinating multiple specialized agents can be complex. MUXI’s Solution: Multi-agent orchestration is a core feature: . # MUXI multi-agent approach from muxi.core.orchestrator import Orchestrator from muxi.core.agent import Agent from muxi.core.models.openai import OpenAIModel # Create orchestrator orchestrator = Orchestrator() # Add specialized agents orchestrator.add_agent( Agent( name=\"travel_agent\", model=OpenAIModel(\"gpt-4o\"), system_message=\"You specialize in travel recommendations.\" ) ) orchestrator.add_agent( Agent( name=\"finance_agent\", model=OpenAIModel(\"gpt-4o\"), system_message=\"You specialize in financial advice.\" ) ) # Automatic message routing to the right agent response = orchestrator.chat(\"What's the best way to budget for a trip to Paris?\") . 3. Modern, Hybrid Communication . The Challenge: Most frameworks support limited communication protocols. MUXI’s Solution: Support for both REST API and WebSocket: . # WebSocket client example (simplified) import asyncio import websockets import json async def chat_with_agent(): async with websockets.connect(\"ws://localhost:5050/ws\") as websocket: # Send a message await websocket.send(json.dumps({ \"type\": \"message\", \"content\": \"Tell me about the weather in Paris\", \"agent\": \"weather_agent\" })) # Receive streaming response while True: response = await websocket.recv() response_data = json.loads(response) if response_data[\"type\"] == \"chunk\": # Process streaming chunk print(response_data[\"content\"], end=\"\") elif response_data[\"type\"] == \"done\": # Response complete break elif response_data[\"type\"] == \"mcp_call\": # MCP server being called print(f\"\\nFetching data from: {response_data['name']}\") asyncio.run(chat_with_agent()) . 4. Multi-User Support Built-In . The Challenge: Adding multi-user support to LLM applications often requires extensive custom code. MUXI’s Solution: Multi-user memory partitioning is built into the framework: . # Multi-user support in MUXI from muxi.core.agent import Agent from muxi.core.models.openai import OpenAIModel from muxi.core.memory.memobase import Memobase # Create a multi-user memory system memobase = Memobase(connection_string=\"postgresql://user:pass@localhost/db\") # Create an agent with multi-user memory agent = Agent( model=OpenAIModel(\"gpt-4o\"), long_term_memory=memobase, system_message=\"You are a personal assistant.\" ) # Chat with user-specific context response1 = agent.chat(\"Tell me about my upcoming trip\", user_id=\"user123\") response2 = agent.chat(\"What meetings do I have tomorrow?\", user_id=\"user456\") . 5. Declarative Configuration . The Challenge: Many frameworks require extensive code for even simple agent configurations. MUXI’s Solution: Declarative configuration with YAML or JSON: . # agent_config.yaml name: travel_assistant description: An agent specializing in travel advice and recommendations system_message: | You are a travel assistant that specializes in providing travel advice, destination recommendations, itinerary planning, and information about tourist attractions worldwide. model: provider: openai model: gpt-4o temperature: 0.7 api_key: ${OPENAI_API_KEY} mcp_servers: - name: travel_api url: http://localhost:5003 api_key: ${TRAVEL_API_KEY} . # Load agent from configuration from muxi.core.orchestrator import Orchestrator orchestrator = Orchestrator( buffer_memory=10, long_term_memory=\"postgresql://user:pass@localhost/db\" ) orchestrator.add_agent_from_config(\"agent_config.yaml\") . ",
    "url": "/muxi/intro/why-muxi#muxis-core-advantages",
    
    "relUrl": "/intro/why-muxi#muxis-core-advantages"
  },"298": {
    "doc": "Why MUXI?",
    "title": "Where MUXI Excels",
    "content": "MUXI is particularly well-suited for: . | Multi-Agent Applications: Systems where specialized agents handle different domains or tasks | Real-Time AI Interfaces: Applications requiring streaming responses and immediate feedback | Multi-User Platforms: Services where each user needs personalized, private context | Extending LLM Capabilities: Projects requiring integration with external services and APIs | Rapid Prototyping: Getting from concept to working prototype with minimal boilerplate | . ",
    "url": "/muxi/intro/why-muxi#where-muxi-excels",
    
    "relUrl": "/intro/why-muxi#where-muxi-excels"
  },"299": {
    "doc": "Why MUXI?",
    "title": "MUXI’s Key Capabilities",
    "content": "MUXI offers a comprehensive set of features that make it stand out: . | Automatic Text Processing: Handles text chunking, embedding generation, and vector storage automatically | Multi-Agent Orchestration: Built-in support for creating and coordinating specialized agents | Real-Time Communication: Supports WebSocket and Server-Sent Events (SSE) for real-time interactions | Multi-User Memory Management: Automatic partitioning of memory by user ID | Declarative Configuration: Define agents using YAML or JSON configuration files | Standardized External Service Integration: MCP (Model Context Protocol) for consistent service access | Automatic Memory Management: Buffer and long-term memory with automatic summarization | Multi-Modal Support: Handle images, audio, and other modalities alongside text input | Streaming Response Processing: Process token-by-token responses for real-time applications | PostgreSQL/pgvector Integration: Built-in support for industry-standard vector storage | Hybrid Deployment Options: Use as a server, CLI tool, or Python library | . ",
    "url": "/muxi/intro/why-muxi#muxis-key-capabilities",
    
    "relUrl": "/intro/why-muxi#muxis-key-capabilities"
  },"300": {
    "doc": "Why MUXI?",
    "title": "When to Consider Alternatives",
    "content": "While MUXI is powerful and flexible, it might not be the best choice for: . | Simple, One-Off Scripts: For quick scripts with minimal requirements, lighter libraries might be more appropriate | Highly Specialized Use Cases: If you need very specific functionality that MUXI doesn’t address | Production-Critical Systems: As MUXI is still in active development, very critical systems might need more mature frameworks | . ",
    "url": "/muxi/intro/why-muxi#when-to-consider-alternatives",
    
    "relUrl": "/intro/why-muxi#when-to-consider-alternatives"
  },"301": {
    "doc": "Why MUXI?",
    "title": "Advanced Topics",
    "content": "For a deeper look at how MUXI compares to other frameworks: . | Framework Comparisons | . ",
    "url": "/muxi/intro/why-muxi#advanced-topics",
    
    "relUrl": "/intro/why-muxi#advanced-topics"
  },"302": {
    "doc": "Why MUXI?",
    "title": "What’s Next",
    "content": ". | Quick Start Guide - Get up and running with MUXI | Simple Agents - Learn how to create your first agent | Using MCP Servers - Extend your agents with external capabilities | . ",
    "url": "/muxi/intro/why-muxi#whats-next",
    
    "relUrl": "/intro/why-muxi#whats-next"
  }
}
